<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Shardy Dialect | Reactant.jl</title>
    <meta name="description" content="Documentation for Reactant.jl">
    <meta name="generator" content="VitePress v1.6.3">
    <link rel="preload stylesheet" href="/Reactant.jl/previews/PR1331/assets/style.Fp7yQoG4.css" as="style">
    <link rel="preload stylesheet" href="/Reactant.jl/previews/PR1331/vp-icons.css" as="style">
    
    <script type="module" src="/Reactant.jl/previews/PR1331/assets/app.ClFIA5RZ.js"></script>
    <link rel="preload" href="/Reactant.jl/previews/PR1331/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/Reactant.jl/previews/PR1331/assets/chunks/theme.d9UG5DJM.js">
    <link rel="modulepreload" href="/Reactant.jl/previews/PR1331/assets/chunks/framework.CHz71bn3.js">
    <link rel="modulepreload" href="/Reactant.jl/previews/PR1331/assets/api_dialects_shardy.md.xpIypoCs.lean.js">
    <link rel="icon" href="/Reactant.jl/previews/PR1331/favicon.ico">
    <script src="/versions.js"></script>
    <script src="/Reactant.jl/previews/PR1331/siteinfo.js"></script>
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-a9a9e638><!--[--><!--]--><!--[--><span tabindex="-1" data-v-492508fc></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-492508fc>Skip to content</a><!--]--><!----><header class="VPNav" data-v-a9a9e638 data-v-f1e365da><div class="VPNavBar" data-v-f1e365da data-v-822684d1><div class="wrapper" data-v-822684d1><div class="container" data-v-822684d1><div class="title" data-v-822684d1><div class="VPNavBarTitle has-sidebar" data-v-822684d1 data-v-0f4f798b><a class="title" href="/Reactant.jl/previews/PR1331/" data-v-0f4f798b><!--[--><!--]--><!--[--><!--[--><!--[--><img class="VPImage dark logo" src="/Reactant.jl/previews/PR1331/logo.svg" alt data-v-35a7d0b8><!--]--><!--[--><img class="VPImage light logo" src="/Reactant.jl/previews/PR1331/logo.svg" alt data-v-35a7d0b8><!--]--><!--]--><!--]--><span data-v-0f4f798b>Reactant.jl</span><!--[--><!--]--></a></div></div><div class="content" data-v-822684d1><div class="content-body" data-v-822684d1><!--[--><!--]--><div class="VPNavBarSearch search" data-v-822684d1><!--[--><!----><div id="local-search"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><span class="vp-icon DocSearch-Search-Icon"></span><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-822684d1 data-v-e6d46098><span id="main-nav-aria-label" class="visually-hidden" data-v-e6d46098> Main Navigation </span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/Reactant.jl/previews/PR1331/" tabindex="0" data-v-e6d46098 data-v-956ec74c><!--[--><span data-v-956ec74c>Home</span><!--]--></a><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-e6d46098 data-v-04f5c5e9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-04f5c5e9><span class="text" data-v-04f5c5e9><!----><span data-v-04f5c5e9>Getting Started</span><span class="vpi-chevron-down text-icon" data-v-04f5c5e9></span></span></button><div class="menu" data-v-04f5c5e9><div class="VPMenu" data-v-04f5c5e9 data-v-7dd3104a><div class="items" data-v-7dd3104a><!--[--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR1331/introduction" data-v-acbfed09><!--[--><span data-v-acbfed09>Introduction</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR1331/introduction/configuration" data-v-acbfed09><!--[--><span data-v-acbfed09>Configuration</span><!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><a class="VPLink link vp-external-link-icon VPNavBarMenuLink" href="https://enzymead.github.io/Reactant.jl/benchmarks/" target="_blank" rel="noreferrer" tabindex="0" data-v-e6d46098 data-v-956ec74c><!--[--><span data-v-956ec74c>Benchmarks</span><!--]--></a><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-e6d46098 data-v-04f5c5e9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-04f5c5e9><span class="text" data-v-04f5c5e9><!----><span data-v-04f5c5e9>Tutorials</span><span class="vpi-chevron-down text-icon" data-v-04f5c5e9></span></span></button><div class="menu" data-v-04f5c5e9><div class="VPMenu" data-v-04f5c5e9 data-v-7dd3104a><div class="items" data-v-7dd3104a><!--[--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR1331/tutorials/" data-v-acbfed09><!--[--><span data-v-acbfed09>Overview</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR1331/tutorials/profiling" data-v-acbfed09><!--[--><span data-v-acbfed09>Profiling</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR1331/tutorials/multihost" data-v-acbfed09><!--[--><span data-v-acbfed09>Distributed</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR1331/tutorials/local-build" data-v-acbfed09><!--[--><span data-v-acbfed09>Local build</span><!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup active" data-v-e6d46098 data-v-04f5c5e9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-04f5c5e9><span class="text" data-v-04f5c5e9><!----><span data-v-04f5c5e9>API</span><span class="vpi-chevron-down text-icon" data-v-04f5c5e9></span></span></button><div class="menu" data-v-04f5c5e9><div class="VPMenu" data-v-04f5c5e9 data-v-7dd3104a><div class="items" data-v-7dd3104a><!--[--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR1331/api/api" data-v-acbfed09><!--[--><span data-v-acbfed09>Core Reactant API</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR1331/api/sharding" data-v-acbfed09><!--[--><span data-v-acbfed09>Sharding</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR1331/api/ops" data-v-acbfed09><!--[--><span data-v-acbfed09>Ops</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR1331/api/config" data-v-acbfed09><!--[--><span data-v-acbfed09>Configuration</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuGroup" data-v-7dd3104a data-v-48c802d0><p class="title" data-v-48c802d0>MLIR Dialects</p><!--[--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR1331/api/dialects/arith" data-v-acbfed09><!--[--><span data-v-acbfed09>ArithOps</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR1331/api/dialects/affine" data-v-acbfed09><!--[--><span data-v-acbfed09>Affine</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR1331/api/dialects/builtin" data-v-acbfed09><!--[--><span data-v-acbfed09>Builtin</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR1331/api/dialects/chlo" data-v-acbfed09><!--[--><span data-v-acbfed09>Chlo</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR1331/api/dialects/enzyme" data-v-acbfed09><!--[--><span data-v-acbfed09>Enzyme</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR1331/api/dialects/enzymexla" data-v-acbfed09><!--[--><span data-v-acbfed09>EnzymeXLA</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR1331/api/dialects/func" data-v-acbfed09><!--[--><span data-v-acbfed09>Func</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR1331/api/dialects/gpu" data-v-acbfed09><!--[--><span data-v-acbfed09>GPU</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR1331/api/dialects/llvm" data-v-acbfed09><!--[--><span data-v-acbfed09>LLVM</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR1331/api/dialects/mpi" data-v-acbfed09><!--[--><span data-v-acbfed09>MPI</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR1331/api/dialects/memref" data-v-acbfed09><!--[--><span data-v-acbfed09>MemRef</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR1331/api/dialects/nvvm" data-v-acbfed09><!--[--><span data-v-acbfed09>NVVM</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link active" href="/Reactant.jl/previews/PR1331/api/dialects/shardy" data-v-acbfed09><!--[--><span data-v-acbfed09>Shardy</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR1331/api/dialects/sparsetensor" data-v-acbfed09><!--[--><span data-v-acbfed09>SparseTensor</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR1331/api/dialects/stablehlo" data-v-acbfed09><!--[--><span data-v-acbfed09>StableHLO</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR1331/api/dialects/triton" data-v-acbfed09><!--[--><span data-v-acbfed09>Triton</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR1331/api/dialects/tpu" data-v-acbfed09><!--[--><span data-v-acbfed09>TPU</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR1331/api/dialects/vhlo" data-v-acbfed09><!--[--><span data-v-acbfed09>VHLO</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-7dd3104a data-v-48c802d0><p class="title" data-v-48c802d0>Low-Level API</p><!--[--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR1331/api/mlirc" data-v-acbfed09><!--[--><span data-v-acbfed09>MLIR API</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR1331/api/xla" data-v-acbfed09><!--[--><span data-v-acbfed09>XLA</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR1331/api/internal" data-v-acbfed09><!--[--><span data-v-acbfed09>Internal API</span><!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><!----><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-822684d1 data-v-af096f4a><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-af096f4a data-v-e40a8bb6 data-v-4a1c76db><span class="check" data-v-4a1c76db><span class="icon" data-v-4a1c76db><!--[--><span class="vpi-sun sun" data-v-e40a8bb6></span><span class="vpi-moon moon" data-v-e40a8bb6></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-822684d1 data-v-164c457f data-v-ee7a9424><!--[--><a class="VPSocialLink no-icon" href="https://julialang.org/slack/" aria-label="slack" target="_blank" rel="noopener" data-v-ee7a9424 data-v-d26d30cb><span class="vpi-social-slack"></span></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-822684d1 data-v-925effce data-v-04f5c5e9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-04f5c5e9><span class="vpi-more-horizontal icon" data-v-04f5c5e9></span></button><div class="menu" data-v-04f5c5e9><div class="VPMenu" data-v-04f5c5e9 data-v-7dd3104a><!----><!--[--><!--[--><!----><div class="group" data-v-925effce><div class="item appearance" data-v-925effce><p class="label" data-v-925effce>Appearance</p><div class="appearance-action" data-v-925effce><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-925effce data-v-e40a8bb6 data-v-4a1c76db><span class="check" data-v-4a1c76db><span class="icon" data-v-4a1c76db><!--[--><span class="vpi-sun sun" data-v-e40a8bb6></span><span class="vpi-moon moon" data-v-e40a8bb6></span><!--]--></span></span></button></div></div></div><div class="group" data-v-925effce><div class="item social-links" data-v-925effce><div class="VPSocialLinks social-links-list" data-v-925effce data-v-ee7a9424><!--[--><a class="VPSocialLink no-icon" href="https://julialang.org/slack/" aria-label="slack" target="_blank" rel="noopener" data-v-ee7a9424 data-v-d26d30cb><span class="vpi-social-slack"></span></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--[--><!--[--><!--[--><a target="_blank" data-decoration="★" title="172 GitHub stars" href="https://github.com/EnzymeAD/Reactant.jl" data-v-b4d08338><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="20" height="20" fill="currentColor" style="vertical-align:middle;margin-right:0.25rem;margin-left:0.5rem;" data-v-b4d08338><path d="M12 .297C5.375.297 0 5.673 0 12.3c0 5.292 3.438 9.8 8.207 11.387.6.11.793-.26.793-.577 0-.285-.01-1.04-.015-2.04-3.338.727-4.042-1.61-4.042-1.61-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.807 1.305 3.493.997.107-.774.42-1.305.762-1.605-2.665-.3-5.467-1.333-5.467-5.931 0-1.31.47-2.382 1.236-3.222-.123-.303-.535-1.52.117-3.166 0 0 1.01-.323 3.31 1.23.96-.267 1.98-.4 3-.405 1.02.005 2.04.138 3 .405 2.3-1.553 3.31-1.23 3.31-1.23.653 1.646.24 2.863.117 3.166.765.84 1.236 1.912 1.236 3.222 0 4.61-2.807 5.625-5.477 5.921.43.372.823 1.102.823 2.222 0 1.606-.015 2.902-.015 3.293 0 .32.192.693.8.577C20.565 22.1 24 17.588 24 12.297 24 5.673 18.627.297 12 .297z" data-v-b4d08338></path></svg><span data-v-b4d08338>0.2k</span></a><a class="mobile" target="_blank" title="172 GitHub stars" href="https://github.com/EnzymeAD/Reactant.jl" data-v-b4d08338><svg xmlns="http://www.w3.org/2000/svg" width="21" height="21" viewBox="0 0 21 21" fill="none" data-v-b4d08338><path d="M19.625 5.60534C18.7083 4.03477 17.4649 2.79135 15.8945 1.87479C14.3238 0.958185 12.6091 0.5 10.7492 0.5C8.88947 0.5 7.17422 0.958325 5.60388 1.87479C4.0333 2.7913 2.78997 4.03477 1.87332 5.60534C0.956814 7.17587 0.498535 8.89089 0.498535 10.7504C0.498535 12.984 1.15021 14.9926 2.4539 16.7766C3.75744 18.5607 5.44142 19.7952 7.50571 20.4803C7.746 20.5249 7.92388 20.4936 8.03954 20.387C8.15524 20.2804 8.21302 20.1467 8.21302 19.9868C8.21302 19.9601 8.21073 19.7199 8.20629 19.266C8.20171 18.8122 8.19956 18.4162 8.19956 18.0783L7.89256 18.1315C7.69682 18.1673 7.44989 18.1825 7.15178 18.1782C6.8538 18.174 6.54446 18.1428 6.22419 18.0847C5.90377 18.0272 5.60575 17.8937 5.32988 17.6846C5.05416 17.4755 4.85842 17.2018 4.74272 16.8639L4.60925 16.5568C4.52029 16.3523 4.38023 16.1251 4.18888 15.8761C3.99754 15.6269 3.80405 15.458 3.60831 15.369L3.51486 15.3021C3.45259 15.2577 3.39481 15.204 3.34138 15.1418C3.28799 15.0796 3.24802 15.0173 3.22132 14.955C3.19458 14.8926 3.21674 14.8414 3.28804 14.8012C3.35933 14.761 3.48817 14.7416 3.67512 14.7416L3.94196 14.7814C4.11993 14.8171 4.34007 14.9236 4.60266 15.1017C4.86511 15.2796 5.08085 15.5109 5.24994 15.7956C5.4547 16.1605 5.7014 16.4385 5.99072 16.6299C6.27982 16.8212 6.5713 16.9167 6.86488 16.9167C7.15846 16.9167 7.41203 16.8945 7.62567 16.8502C7.83908 16.8057 8.0393 16.7388 8.22625 16.6499C8.30633 16.0535 8.52437 15.5953 8.88017 15.275C8.37304 15.2217 7.9171 15.1414 7.51212 15.0347C7.10736 14.9278 6.6891 14.7544 6.25761 14.5139C5.82589 14.2738 5.46774 13.9756 5.18309 13.6198C4.89839 13.2639 4.66474 12.7966 4.48247 12.2183C4.3001 11.6399 4.20889 10.9726 4.20889 10.2163C4.20889 9.13941 4.56044 8.22304 5.26341 7.46665C4.93411 6.65705 4.96519 5.74947 5.35676 4.744C5.61482 4.66382 5.9975 4.72399 6.50463 4.92412C7.01186 5.12434 7.38323 5.29587 7.61912 5.43808C7.85502 5.58024 8.04402 5.70071 8.18642 5.79842C9.01411 5.56715 9.86825 5.45149 10.7491 5.45149C11.6299 5.45149 12.4843 5.56715 13.312 5.79842L13.8192 5.47823C14.166 5.26459 14.5756 5.06881 15.0469 4.89083C15.5185 4.71295 15.8791 4.66396 16.1284 4.74414C16.5286 5.74966 16.5643 6.65719 16.2349 7.46679C16.9378 8.22318 17.2895 9.13978 17.2895 10.2164C17.2895 10.9727 17.198 11.6421 17.0159 12.225C16.8336 12.808 16.5979 13.2749 16.3088 13.6265C16.0194 13.9781 15.659 14.274 15.2275 14.5141C14.7959 14.7544 14.3775 14.9278 13.9728 15.0347C13.5678 15.1415 13.1119 15.2219 12.6047 15.2752C13.0673 15.6755 13.2986 16.3073 13.2986 17.1704V19.9864C13.2986 20.1464 13.3542 20.2799 13.4656 20.3867C13.5768 20.4932 13.7524 20.5246 13.9927 20.4799C16.0573 19.7949 17.7413 18.5603 19.0448 16.7762C20.3481 14.9922 21 12.9837 21 10.75C20.9996 8.89075 20.541 7.17587 19.625 5.60534Z" fill="currentColor" data-v-b4d08338></path></svg></a><!--]--><div class="VPFlyout VPNolebaseEnhancedReadabilitiesMenu VPNolebaseEnhancedReadabilitiesMenuFlyout" aria-label="Enhanced Readability" role="menuitem" data-v-04f5c5e9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-04f5c5e9><span class="text" data-v-04f5c5e9><span class="i-icon-park-outline:book-open option-icon" data-v-04f5c5e9></span><!----><span class="vpi-chevron-down text-icon" data-v-04f5c5e9></span></span></button><div class="menu" data-v-04f5c5e9><div class="VPMenu" data-v-04f5c5e9 data-v-7dd3104a><!----><!--[--><!--]--></div></div></div><!--]--><!--]--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-822684d1 data-v-5dea55bf><span class="container" data-v-5dea55bf><span class="top" data-v-5dea55bf></span><span class="middle" data-v-5dea55bf></span><span class="bottom" data-v-5dea55bf></span></span></button></div></div></div></div><div class="divider" data-v-822684d1><div class="divider-line" data-v-822684d1></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-a9a9e638 data-v-070ab83d><div class="container" data-v-070ab83d><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-070ab83d><span class="vpi-align-left menu-icon" data-v-070ab83d></span><span class="menu-text" data-v-070ab83d>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-070ab83d data-v-168ddf5d><button data-v-168ddf5d>Return to top</button><!----></div></div></div><aside class="VPSidebar" data-v-a9a9e638 data-v-18756405><div class="curtain" data-v-18756405></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-18756405><span class="visually-hidden" id="sidebar-aria-label" data-v-18756405> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-9e426adc><section class="VPSidebarItem level-0 collapsible has-active" data-v-9e426adc data-v-a4b0d9bf><div class="item" role="button" tabindex="0" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><h2 class="text" data-v-a4b0d9bf>API Reference</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-a4b0d9bf><span class="vpi-chevron-right caret-icon" data-v-a4b0d9bf></span></div></div><div class="items" data-v-a4b0d9bf><!--[--><div class="VPSidebarItem level-1 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/Reactant.jl/previews/PR1331/api/api" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Reactant API</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/Reactant.jl/previews/PR1331/api/sharding" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Sharding</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/Reactant.jl/previews/PR1331/api/ops" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Ops</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/Reactant.jl/previews/PR1331/api/config" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Configuration</p><!--]--></a><!----></div><!----></div><section class="VPSidebarItem level-1 collapsible has-active" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" role="button" tabindex="0" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><h3 class="text" data-v-a4b0d9bf>MLIR Dialects</h3><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-a4b0d9bf><span class="vpi-chevron-right caret-icon" data-v-a4b0d9bf></span></div></div><div class="items" data-v-a4b0d9bf><!--[--><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/Reactant.jl/previews/PR1331/api/dialects/arith" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>ArithOps</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/Reactant.jl/previews/PR1331/api/dialects/affine" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Affine</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/Reactant.jl/previews/PR1331/api/dialects/builtin" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Builtin</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/Reactant.jl/previews/PR1331/api/dialects/chlo" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Chlo</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/Reactant.jl/previews/PR1331/api/dialects/enzyme" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Enzyme</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/Reactant.jl/previews/PR1331/api/dialects/enzymexla" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>EnzymeXLA</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/Reactant.jl/previews/PR1331/api/dialects/func" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Func</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/Reactant.jl/previews/PR1331/api/dialects/gpu" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>GPU</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/Reactant.jl/previews/PR1331/api/dialects/llvm" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>LLVM</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/Reactant.jl/previews/PR1331/api/dialects/mpi" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>MPI</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/Reactant.jl/previews/PR1331/api/dialects/memref" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>MemRef</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/Reactant.jl/previews/PR1331/api/dialects/nvvm" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>NVVM</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/Reactant.jl/previews/PR1331/api/dialects/shardy" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Shardy</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/Reactant.jl/previews/PR1331/api/dialects/sparsetensor" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>SparseTensor</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/Reactant.jl/previews/PR1331/api/dialects/stablehlo" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>StableHLO</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/Reactant.jl/previews/PR1331/api/dialects/triton" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Triton</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/Reactant.jl/previews/PR1331/api/dialects/tpu" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>TPU</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/Reactant.jl/previews/PR1331/api/dialects/vhlo" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>VHLO</p><!--]--></a><!----></div><!----></div><!--]--></div></section><section class="VPSidebarItem level-1 collapsible" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" role="button" tabindex="0" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><h3 class="text" data-v-a4b0d9bf>Low-Level API</h3><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-a4b0d9bf><span class="vpi-chevron-right caret-icon" data-v-a4b0d9bf></span></div></div><div class="items" data-v-a4b0d9bf><!--[--><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/Reactant.jl/previews/PR1331/api/mlirc" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>MLIR API</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/Reactant.jl/previews/PR1331/api/xla" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>XLA</p><!--]--></a><!----></div><!----></div><!--]--></div></section><div class="VPSidebarItem level-1 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/Reactant.jl/previews/PR1331/api/internal" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Internal API</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-a9a9e638 data-v-91765379><div class="VPDoc has-sidebar has-aside" data-v-91765379 data-v-83890dd9><!--[--><!--]--><div class="container" data-v-83890dd9><div class="aside" data-v-83890dd9><div class="aside-curtain" data-v-83890dd9></div><div class="aside-container" data-v-83890dd9><div class="aside-content" data-v-83890dd9><div class="VPDocAside" data-v-83890dd9 data-v-6d7b3c46><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-6d7b3c46 data-v-b38bf2ff><div class="content" data-v-b38bf2ff><div class="outline-marker" data-v-b38bf2ff></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-b38bf2ff>On this page</div><ul class="VPDocOutlineItem root" data-v-b38bf2ff data-v-3f927ebe><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-6d7b3c46></div><!--[--><!--[--><!--[--><!--[--><!--[--><br><h2> Trusted by </h2><a class="enjoyer" href="https://lux.csail.mit.edu/" target="_blank"><img width="32" height="32" src="https://raw.githubusercontent.com/LuxDL/Lux.jl/refs/heads/main/assets/lux-logo.svg"><span><p class="extra-info">Scientific Computing</p><p class="heading">Lux.jl</p><p class="extra-info">Machine Learning</p></span></a><a class="enjoyer" href="https://bsc-quantic.github.io/Tenet.jl/stable/" target="_blank"><img width="32" height="32" src="https://raw.githubusercontent.com/bsc-quantic/Tenet.jl/refs/heads/master/docs/src/assets/logo.svg"><span><p class="extra-info">Quantum Simulation</p><p class="heading">Tenet.jl</p><p class="extra-info">Tensor Networks</p></span></a><!--]--><!--]--><!--]--><!--]--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-83890dd9><div class="content-container" data-v-83890dd9><!--[--><!--]--><main class="main" data-v-83890dd9><div style="position:relative;" class="vp-doc _Reactant_jl_previews_PR1331_api_dialects_shardy" data-v-83890dd9><div><h1 id="Shardy-Dialect" tabindex="-1">Shardy Dialect <a class="header-anchor" href="#Shardy-Dialect" aria-label="Permalink to &quot;Shardy Dialect {#Shardy-Dialect}&quot;">​</a></h1><p>Refer to the <a href="https://openxla.org/shardy" target="_blank" rel="noreferrer">official documentation</a> for more details.</p><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.sdy.all_gather-Tuple{Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.sdy.all_gather-Tuple{Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.sdy.all_gather</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>all_gather</code></p><p>Gathers chunks of a tensor along axes specified in <code>gathering_axes</code>.</p><p>The <code>gathering_axes</code> is a list of lists of axes. The outer list is over the dimensions of the tensor. Each inner list specifies the axes along which a separate gather should be performed on the respective dimension. It will be applied to the sharding of the operand (<code>tensor</code>) to obtain the sharding of the result (<code>out_sharding</code>).</p><p>Note that <code>out_sharding</code> is not used to determine the sharding of the result. Instead, the sharding of the result is determined by the sharding of the operand and the <code>gathering_axes</code>, and <code>out_sharding</code> must match this inferred sharding.</p><p><strong>Example</strong></p><div class="language-mlir vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">mlir</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>%1 = stablehlo.tanh(%0) {sdy.sharding = #sdy.sharding_per_value&lt;[&lt;@mesh, [{&quot;a&quot;, &quot;b&quot;, &quot;c&quot;}, {}, {&quot;d&quot;}\]&gt;]&gt;} : tensor&lt;8x8x8xf32&gt;</span></span>
<span class="line"><span>%2 = sdy.all_gather [{&quot;b&quot;, &quot;c&quot;}, {}, {&quot;d&quot;}\] %1 out_sharding=&lt;@mesh, [{&quot;a&quot;}, {}, {}\]&gt; : tensor&lt;8x8x8xf32&gt;</span></span></code></pre></div><p><strong>Constraints:</strong></p><ul><li><p>Must satisfy the constraints listed in <code>Sdy_CollectiveOpInterface</code>.</p></li><li><p>Elements in <code>gathering_axes</code> must satisfy the constraints listed in <code>AxisRefListAttr</code>.</p></li><li><p>Applying <code>gathering_axes</code> to the operand sharding gets <code>out_sharding</code>.</p></li></ul><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/bf0f4c05867e33e3bf23bed29c063d2340ddb421/src/mlir/Dialects/Shardy.jl#L16-L43" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.sdy.all_reduce-Tuple{Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.sdy.all_reduce-Tuple{Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.sdy.all_reduce</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>all_reduce</code></p><p>Reduces chunks of a tensor along axes specified in <code>reduction_axes</code>. The order of <code>reduction_axes</code> is not important for the result, but can affect the order of the corresponding replica groups.</p><p><strong>Constraints:</strong></p><ul><li><p>Must satisfy the constraints listed in <code>Sdy_CollectiveOpInterface</code>.</p></li><li><p><code>reduction_axes</code> must satisfy the constraints listed in <code>AxisRefListAttr</code>;</p></li><li><p><code>reduction_axes</code> must not overlap with the operand sharding axes;</p></li></ul><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/bf0f4c05867e33e3bf23bed29c063d2340ddb421/src/mlir/Dialects/Shardy.jl#L73-L84" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.sdy.all_slice-Tuple{Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.sdy.all_slice-Tuple{Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.sdy.all_slice</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>all_slice</code></p><p>Slices chunks of a tensor along axes specified in <code>slicing_axes</code>. There is an algebric duality between <code>sdy.all_slice</code> and <code>sdy.all_gather</code>.</p><p>The <code>slicing_axes</code> is a list of lists of axes. The outer list is over the dimensions of the tensor. Each inner list specifies the axes along which a slice should be performed on the respective dimension. It will be applied to the sharding of the operand (<code>tensor</code>) to obtain the sharding of the result (<code>out_sharding</code>).</p><p>Note that <code>out_sharding</code> is not used to determine the sharding of the result. Instead, the sharding of the result is determined by the sharding of the operand and the <code>slicing_axes</code>, and <code>out_sharding</code> must match this inferred sharding.</p><p><strong>Example</strong></p><div class="language-mlir vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">mlir</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>%1 = stablehlo.tanh(%0) {sdy.sharding = #sdy.sharding_per_value&lt;[&lt;@mesh, [{&quot;a&quot;}, {}, {}\]&gt;]&gt;} : tensor&lt;8x8x8xf32&gt;</span></span>
<span class="line"><span>%2 = sdy.all_slice [{&quot;b&quot;, &quot;c&quot;}, {}, {&quot;d&quot;}\] %1 out_sharding=&lt;@mesh, [{&quot;a&quot;, &quot;b&quot;, &quot;c&quot;}, {}, {&quot;d&quot;}\]&gt; : tensor&lt;8x8x8xf32&gt;</span></span></code></pre></div><p><strong>Constraints:</strong></p><ul><li><p>Elements in <code>slicing_axes</code> must satisfy the constraints listed in <code>AxisRefListAttr</code>.</p></li><li><p>Must satisfy the constraints listed in <code>Sdy_CollectiveOpInterface</code>.</p></li><li><p>Applying <code>slicing_axes</code> to the operand sharding gets <code>out_sharding</code>.</p></li></ul><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/bf0f4c05867e33e3bf23bed29c063d2340ddb421/src/mlir/Dialects/Shardy.jl#L114-L142" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.sdy.all_to_all-Tuple{Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.sdy.all_to_all-Tuple{Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.sdy.all_to_all</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>all_to_all</code></p><p>For each (axes, src_dim, tgt_dim) tuple in the parameter list, this operation slices chunks of a tensor along dimension <code>tgt_dim</code> and axes specified in <code>axes</code>, scatteres those chunks along the axes, and concatenates them along dimension <code>src_dim</code>.</p><p>This operation is essentially a combination of an all-gather along <code>src_dim</code> and <code>axes</code>, followed by an all-slice along <code>tgt_dim</code> and <code>axes</code>, i.e., a suffix of the axes sharding dimension <code>src_dim</code> on the input tensor is appended to the axes sharding dimension <code>tgt_dim</code> on the output tensor.</p><p>The all-to-all will be applied to the sharding of the operand (<code>tensor</code>) to obtain the sharding of the result (<code>out_sharding</code>).</p><p>Note that <code>out_sharding</code> is not used to determine the sharding of the result. Instead, the sharding of the result is determined by the sharding of the operand, <code>src_dim</code>, <code>tgt_dim</code>, and <code>axes</code>, and <code>out_sharding</code> must match this inferred sharding.</p><p><strong>Example</strong></p><div class="language-mlir vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">mlir</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>%1 = stablehlo.tanh(%0) {sdy.sharding = #sdy.sharding_per_value&lt;[&lt;@mesh, [{&quot;a&quot;, &quot;b&quot;}, {&quot;c&quot;}, {}, {}\]&gt;]&gt;} : tensor&lt;8x8x4x4x32&gt;</span></span>
<span class="line"><span>%2 = sdy.all_to_all [{&quot;b&quot;}: 0-&gt;2, {&quot;c&quot;}: 1-&gt;3] %1 out_sharding=&lt;@mesh, [{&quot;a&quot;}, {}, {&quot;b&quot;}, {&quot;c&quot;}\]&gt; : tensor&lt;8x8x4x4x32&gt;</span></span></code></pre></div><p><strong>Constraints:</strong></p><ul><li><p>Must satisfy the constraints listed in <code>Sdy_CollectiveOpInterface</code>.</p></li><li><p>The parameter list must not be empty.</p></li><li><p>For each parameter in <code>params</code>:</p><ul><li><p>Elements in <code>axes</code> must satisfy the constraints of <code>AxisRefAttr</code>.</p></li><li><p><code>src_dim</code> and <code>tgt_dim</code> must be valid dimensions (non-negative and less</p></li></ul><p>than rank of tensor).</p><ul><li><p>Any <code>src_dim</code> or <code>tgt_dim</code> must be unique across all parameters.</p></li><li><p><code>src_dim</code> must be sorted in ascending order across all parameters.</p></li></ul></li><li><p>Moving <code>axes</code> from <code>src_dim</code> to <code>tgt_dim</code> in the operand sharding gets <code>out_sharding</code>.</p></li></ul><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/bf0f4c05867e33e3bf23bed29c063d2340ddb421/src/mlir/Dialects/Shardy.jl#L172-L210" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.sdy.collective_permute-Tuple{Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.sdy.collective_permute-Tuple{Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.sdy.collective_permute</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>collective_permute</code></p><p>Sends a chunk of the input tensor from each device to another to reorder/replace the axes that shard the tensor.</p><p>A collective permute can transform the input sharding such that each dimension must be as sharded as it was before, i.e., it must be sharded along axes whose product of sizes matches that of the axes that previously sharded the tensor.</p><p>This is useful for reordering axes in a single dimension or across different dimensions, and swapping sharded axes with replicated ones.</p><p>In the below example, the sharded tensor size is <code>tensor&lt;1x4x2xf32&gt;</code>, and that is preserved by the collective permute.</p><p><strong>Example</strong></p><div class="language-mlir vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">mlir</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>sdy.mesh @mesh = &lt;[&quot;a&quot;=2, &quot;b&quot;=2, &quot;c&quot;=4, &quot;d&quot;=2, &quot;e&quot;=2, &quot;f&quot;=2]&gt;</span></span>
<span class="line"><span>%1 = stablehlo.tanh(%0) {sdy.sharding = #sdy.sharding_per_value&lt;[&lt;@mesh, [{&quot;a&quot;, &quot;c&quot;}, {&quot;f&quot;}, {&quot;d&quot;, &quot;e&quot;}\]&gt;]&gt;} : tensor&lt;8x8x8xf32&gt;</span></span>
<span class="line"><span>%2 = sdy.collective_permute %1 out_sharding=&lt;@mesh, [{&quot;c&quot;:(1)2, &quot;b&quot;, &quot;f&quot;}, {&quot;a&quot;}, {&quot;e&quot;, &quot;d&quot;}\]&gt; : tensor&lt;8x8x8xf32&gt;</span></span></code></pre></div><p><strong>Constraints:</strong></p><ul><li><p>Must satisfy the constraints listed in <code>Sdy_CollectiveOpInterface</code>.</p></li><li><p>If input and output sharding have different meshes, then those meshes must have exactly the same axes and different order of device ids.</p></li><li><p>For each dimension, the product of sharding axis sizes in <code>out_sharding</code> must match that of the corresponding operand dimension sharding.</p></li></ul><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/bf0f4c05867e33e3bf23bed29c063d2340ddb421/src/mlir/Dialects/Shardy.jl#L239-L269" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.sdy.constant-Tuple{}" href="#Reactant.MLIR.Dialects.sdy.constant-Tuple{}"><span class="jlbinding">Reactant.MLIR.Dialects.sdy.constant</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>constant</code></p><p>Produces an <code>output</code> tensor from a constant <code>value</code>.</p><p>See: <a href="https://github.com/openxla/stablehlo/blob/main/docs/spec.md#constant" target="_blank" rel="noreferrer">https://github.com/openxla/stablehlo/blob/main/docs/spec.md#constant</a></p><p>NOTE: SDY defines its own constant op that isn&#39;t ConstantLike and doesn&#39;t have a folder, so that we&#39;ll be able to duplicate constants without any greedy pattern rewriter folding them back into a single constant. In this way, constants can be sharded differently for every use, and no propagation is done between constants (or constant expressions).</p><p><strong>Example</strong></p><div class="language-mlir vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">mlir</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>%output = sdy.constant dense&lt;[[0.0, 1.0], [2.0, 3.0]]&gt; : tensor&lt;2x2xf32&gt;</span></span></code></pre></div><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/bf0f4c05867e33e3bf23bed29c063d2340ddb421/src/mlir/Dialects/Shardy.jl#L292-L310" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.sdy.data_flow_edge-Tuple{Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.sdy.data_flow_edge-Tuple{Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.sdy.data_flow_edge</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>data_flow_edge</code></p><p>A data flow edge of some op X defines a bridge between a set of sources (each is either an operand of X or an operand of X&#39;s block terminator) and a set of targets (each is either a result of X or a block argument of X), such that all sources and targets should be sharded in the same way.</p><p>An op can have multiple data flow edges that are orthogonal to one another.</p><p>For example:</p><div class="language-mlir vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">mlir</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>  y_0, ..., y_n = while (x_0, ..., x_n)</span></span>
<span class="line"><span>                  ((pred_arg_0,... , pred_arg_n) { ... })</span></span>
<span class="line"><span>                  ((body_arg_0,..., body_arg_n) {</span></span>
<span class="line"><span>                    ...</span></span>
<span class="line"><span>                    return return_value_0, ..., return_value_n</span></span>
<span class="line"><span>                  })</span></span></code></pre></div><p>This while op has n data flow edges, the i-th data flow edges is between sources <code>x_i</code>, <code>return_value_i</code> and targets <code>y_i</code>, <code>pred_arg_i</code>, <code>body_arg_i</code>.</p><p>An <code>sdy.data_flow_edge</code> takes as input the owner of an edge (can be any of the targets, but preferably an op result rather than a block argument), which shouldn&#39;t have any other uses. This op isn&#39;t pure because it can take an input that originally didn&#39;t have any uses.</p><p>The <code>sdy.data_flow_edge</code> also holds an optional sharding for all targets of the edge, and that sharding should be updated instead of the targets&#39; sharding (if can be attached) during propagation. This is useful when an op has many edges, as it&#39;s much more efficient to:</p><ul><li><p>propagate through each edge separately.</p></li><li><p>update the sharding of each edge separately instead of all targets at once (e.g. an op has a single immutable <code>TensorShardingPerValueAttr</code> for result shardings).</p></li><li><p>add each edge to the worklist separately when the sharding of a source has changed.</p></li></ul><p>Propagation will propagate shardings between all sources and targets of a <code>sdy.data_flow_edge</code> as if it was a regular op with the sources as operands and targets as results, and an identity <code>sdy.op_sharding_rule</code>. That means that forward propagation is from sources to targets and backwards propagation is from targets to sources.</p><p>We don&#39;t allow the input of a <code>sdy.data_flow_edge</code> to be defined by an <code>SdyDialect</code> op, so we can assume that it&#39;s defined by an op that has unregistered <code>sdy.sharding</code> attribute.</p><p>NOTE: it&#39;s NOT the responsibility of the <code>sdy.data_flow_edge</code> to link between sources and targets, it&#39;s simply attached to the owner of the edge. The op that this edge is bound to (while in the example above) is responsible for providing this information.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/bf0f4c05867e33e3bf23bed29c063d2340ddb421/src/mlir/Dialects/Shardy.jl#L331-L386" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.sdy.manual_computation-Tuple{Vector{Reactant.MLIR.IR.Value}}" href="#Reactant.MLIR.Dialects.sdy.manual_computation-Tuple{Vector{Reactant.MLIR.IR.Value}}"><span class="jlbinding">Reactant.MLIR.Dialects.sdy.manual_computation</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>manual_computation</code></p><p>Jump into a region written in terms of per-device local code with explicit collectives, where logical shapes match local per-device physical buffer shapes and collectives correspond exactly to physical cross-device communication.</p><p>The body is local wrt the manual_axes. Propagation will occur through the body on any free axes - those not in the manual_axes list.</p><p><strong>Constraints:</strong></p><ul><li><p>Elements in <code>in_shardings</code> and <code>out_shardings</code> must satisfy the constraints listed in <code>TensorShardingAttr</code>.</p></li><li><p>The number of global and local tensor inputs/outputs of the op region must match.</p></li><li><p>The manual axes must come before any free axes in each dim sharding.</p></li><li><p>The manual axes cannot introduce padding. Namely, the dimension size must be divisible by the corresponding manual axes size.</p></li><li><p>The global and local shapes of the op regions arguments/results must match.</p></li><li><p>No manual axes are split.</p></li></ul><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/bf0f4c05867e33e3bf23bed29c063d2340ddb421/src/mlir/Dialects/Shardy.jl#L413-L431" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.sdy.mesh-Tuple{}" href="#Reactant.MLIR.Dialects.sdy.mesh-Tuple{}"><span class="jlbinding">Reactant.MLIR.Dialects.sdy.mesh</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>mesh</code></p><p>Defines a new named mesh. All meshes in a module must have the same number of devices (except for meshes with a single device_id). The mesh is a <code>Symbol</code> operation that appears in the module&#39;s <code>SymbolTable</code> and can be referenced by its <code>name</code>.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/bf0f4c05867e33e3bf23bed29c063d2340ddb421/src/mlir/Dialects/Shardy.jl#L463-L470" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.sdy.named_computation-Tuple{Vector{Reactant.MLIR.IR.Value}}" href="#Reactant.MLIR.Dialects.sdy.named_computation-Tuple{Vector{Reactant.MLIR.IR.Value}}"><span class="jlbinding">Reactant.MLIR.Dialects.sdy.named_computation</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>named_computation</code></p><p>Groups a computation, i.e. a block of operations, and gives it a name. Propagation will flow in/out of the region as if everything was inlined.</p><p>This can be used to handle propagating through call instructions to other functions. Any users of Shardy should write an import/export pass that converts their call ops to <code>sdy.named_computation</code> ops, duplicating/copying the body of the called function into the body of the <code>named_computation</code>.</p><p>The type of each block arguments and returned values in the region must be the same as the type of the operands and results type of the op.</p><p><strong>Example</strong></p><div class="language-mlir vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">mlir</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>%1 = sdy.named_computation&lt;&quot;foo&quot;&gt;(%0) (%arg1: tensor&lt;16x32xf32&gt;) {</span></span>
<span class="line"><span>  sdy.return %arg1 : tensor&lt;16x32xf32&gt;</span></span>
<span class="line"><span>} : (tensor&lt;16x32xf32&gt;) -&gt; tensor&lt;16x32xf32&gt;</span></span></code></pre></div><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/bf0f4c05867e33e3bf23bed29c063d2340ddb421/src/mlir/Dialects/Shardy.jl#L492-L513" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.sdy.propagation_barrier-Tuple{Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.sdy.propagation_barrier-Tuple{Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.sdy.propagation_barrier</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>propagation_barrier</code></p><p>This op operates like an identity op, outputting the same value it took as input. But in terms of propagation, this will only allow propagation to flow through it in a certain direction.</p><p>This prevents shardings from being propagated between the uses of the result of the barrier op and its operand.</p><ul><li><p><code>FORWARD</code> means shardings can only flow from the operand to the result.</p></li><li><p><code>BACKWARD</code> means shardings can only flow from the result to the operand.</p></li><li><p><code>NONE</code> means no sharding can propagate through this op.</p></li><li><p>Cannot specify <code>BOTH</code>, as this op would be redundant.</p></li></ul><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/bf0f4c05867e33e3bf23bed29c063d2340ddb421/src/mlir/Dialects/Shardy.jl#L545-L559" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.sdy.reshard-Tuple{Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.sdy.reshard-Tuple{Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.sdy.reshard</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>reshard</code></p><p>Reshards the input tensor with the specified sharding, which is different from the input tensor&#39;s existing sharding.</p><p>Both ShardingConstraintOp and ReshardOp attach a sharding to a tensor. Their lifespan is:</p><ol><li><p>Before sharding propagation, ShardingConstraintOp is added by users.</p></li><li><p>Sharding propagation consumes ShardingConstraintOp. There is no ShardingConstraintOp in the results of sharding propagation. Instead, ReshardOp may be added if needed.</p></li><li><p>A partitioner converts a ReshardOp into a collective op (or an identity op). There should be no ReshardOp in the results of the partitioner.</p></li></ol><p>// TODO(b/331680067). Add a canonicalization pattern to remove redundant // reshard ops.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/bf0f4c05867e33e3bf23bed29c063d2340ddb421/src/mlir/Dialects/Shardy.jl#L585-L602" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.sdy.sharding_constraint-Tuple{Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.sdy.sharding_constraint-Tuple{Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.sdy.sharding_constraint</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>sharding_constraint</code></p><p>Attaches a sharding to an intermediate tensor (e.g. the result of a matmul) to indicate that this is how that tensor, or a subset of its uses, should be sharded.</p><p>If the sharding has open dimensions and unconstraint axes, it means the tensor can be further sharded along the open dimensions.</p><p>This op can either:</p><ul><li><p>Have no uses (dangling) - which means the attached sharding is how the input tensor itself should be sharded.</p></li><li><p>Have uses - which means the attached sharding is how the uses of the sharding constraint op should be sharded, while other uses of the input tensor might have a different sharding (if the input tensor has no other uses then the behavior is the same as the no uses case).</p></li></ul><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/bf0f4c05867e33e3bf23bed29c063d2340ddb421/src/mlir/Dialects/Shardy.jl#L644-L661" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.sdy.sharding_group-Tuple{Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.sdy.sharding_group-Tuple{Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.sdy.sharding_group</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>sharding_group</code></p><p>This op provides an interface to assign tensors to sharding groups ( groups of tensors that will be enforced to have identical shardings). During propagation, as soon as one group element is sharded, all other members will be sharded in exactly the same way. This operation takes the argument group ID and returns no result, but instead modifies the internal sharding group representation to add the input tensor to the group with the given ID.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/bf0f4c05867e33e3bf23bed29c063d2340ddb421/src/mlir/Dialects/Shardy.jl#L684-L694" target="_blank" rel="noreferrer">source</a><!--]--></span></details></div></div></main><footer class="VPDocFooter" data-v-83890dd9 data-v-4f9813fa><!--[--><!--]--><div class="edit-info" data-v-4f9813fa><div class="edit-link" data-v-4f9813fa><a class="VPLink link vp-external-link-icon no-icon edit-link-button" href="https://github.com/EnzymeAD/Reactant.jl/edit/main/docs/src/api/dialects/shardy.md" target="_blank" rel="noreferrer" data-v-4f9813fa><!--[--><span class="vpi-square-pen edit-link-icon" data-v-4f9813fa></span> Edit this page on GitHub<!--]--></a></div><!----></div><nav class="prev-next" aria-labelledby="doc-footer-aria-label" data-v-4f9813fa><span class="visually-hidden" id="doc-footer-aria-label" data-v-4f9813fa>Pager</span><div class="pager" data-v-4f9813fa><a class="VPLink link pager-link prev" href="/Reactant.jl/previews/PR1331/api/dialects/nvvm" data-v-4f9813fa><!--[--><span class="desc" data-v-4f9813fa>Previous page</span><span class="title" data-v-4f9813fa>NVVM</span><!--]--></a></div><div class="pager" data-v-4f9813fa><a class="VPLink link pager-link next" href="/Reactant.jl/previews/PR1331/api/dialects/sparsetensor" data-v-4f9813fa><!--[--><span class="desc" data-v-4f9813fa>Next page</span><span class="title" data-v-4f9813fa>SparseTensor</span><!--]--></a></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><footer class="VPFooter has-sidebar" data-v-a9a9e638 data-v-c970a860><div class="container" data-v-c970a860><p class="message" data-v-c970a860>Made with <a href="https://documenter.juliadocs.org/stable/" target="_blank"><strong>Documenter.jl</strong></a>, <a href="https://vitepress.dev" target="_blank"><strong>VitePress</strong></a> and <a href="https://luxdl.github.io/DocumenterVitepress.jl/stable" target="_blank"><strong>DocumenterVitepress.jl</strong></a><br>Released under the MIT License. Powered by the <a href="https://www.julialang.org">Julia Programming Language</a>.<br></p><p class="copyright" data-v-c970a860>© Copyright 2025 Reactant Development Team.</p></div></footer><!--[--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"api_api.md\":\"C5ZUdKa9\",\"api_config.md\":\"B_83c3o2\",\"api_dialects_affine.md\":\"Crxaq06c\",\"api_dialects_arith.md\":\"DdqGrys5\",\"api_dialects_builtin.md\":\"7-_2vijs\",\"api_dialects_chlo.md\":\"CSUIJG1E\",\"api_dialects_enzyme.md\":\"D9CZ7Zy1\",\"api_dialects_enzymexla.md\":\"DfGl1W4R\",\"api_dialects_func.md\":\"FlGbanmh\",\"api_dialects_gpu.md\":\"c7dmunN5\",\"api_dialects_llvm.md\":\"BlS1lS_N\",\"api_dialects_memref.md\":\"CqTI7tyE\",\"api_dialects_mpi.md\":\"daKZA0Ud\",\"api_dialects_nvvm.md\":\"BV-10TGO\",\"api_dialects_shardy.md\":\"xpIypoCs\",\"api_dialects_sparsetensor.md\":\"CIwpzub_\",\"api_dialects_stablehlo.md\":\"CzFabWZ-\",\"api_dialects_tpu.md\":\"Ctv46XlH\",\"api_dialects_triton.md\":\"CNZUMvrz\",\"api_dialects_vhlo.md\":\"DzyLIAcD\",\"api_internal.md\":\"CEu2vRN_\",\"api_mlirc.md\":\"DbYjF5I2\",\"api_ops.md\":\"B0roh-cI\",\"api_sharding.md\":\"ttfLiLEb\",\"api_xla.md\":\"CDJmEGpB\",\"index.md\":\"DLILHBpg\",\"introduction_configuration.md\":\"NfW2wq-N\",\"introduction_index.md\":\"aJOwFxnz\",\"tutorials_index.md\":\"jIpyM0FD\",\"tutorials_local-build.md\":\"4vuJMZNW\",\"tutorials_multihost.md\":\"D8QEAY-m\",\"tutorials_profiling.md\":\"nN8kkU9C\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"en-US\",\"dir\":\"ltr\",\"title\":\"Reactant.jl\",\"description\":\"Documentation for Reactant.jl\",\"base\":\"/Reactant.jl/previews/PR1331/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"outline\":\"deep\",\"logo\":{\"light\":\"/logo.svg\",\"dark\":\"/logo.svg\"},\"search\":{\"provider\":\"local\",\"options\":{\"detailedView\":true}},\"nav\":[{\"text\":\"Home\",\"link\":\"/\"},{\"text\":\"Getting Started\",\"items\":[{\"text\":\"Introduction\",\"link\":\"/introduction\"},{\"text\":\"Configuration\",\"link\":\"/introduction/configuration\"}]},{\"text\":\"Benchmarks\",\"link\":\"https://enzymead.github.io/Reactant.jl/benchmarks/\"},{\"text\":\"Tutorials\",\"items\":[{\"text\":\"Overview\",\"link\":\"/tutorials/\"},{\"text\":\"Profiling\",\"link\":\"/tutorials/profiling\"},{\"text\":\"Distributed\",\"link\":\"/tutorials/multihost\"},{\"text\":\"Local build\",\"link\":\"/tutorials/local-build\"}]},{\"text\":\"API\",\"items\":[{\"text\":\"Core Reactant API\",\"link\":\"/api/api\"},{\"text\":\"Sharding\",\"link\":\"/api/sharding\"},{\"text\":\"Ops\",\"link\":\"/api/ops\"},{\"text\":\"Configuration\",\"link\":\"/api/config\"},{\"text\":\"MLIR Dialects\",\"items\":[{\"text\":\"ArithOps\",\"link\":\"/api/dialects/arith\"},{\"text\":\"Affine\",\"link\":\"/api/dialects/affine\"},{\"text\":\"Builtin\",\"link\":\"/api/dialects/builtin\"},{\"text\":\"Chlo\",\"link\":\"/api/dialects/chlo\"},{\"text\":\"Enzyme\",\"link\":\"/api/dialects/enzyme\"},{\"text\":\"EnzymeXLA\",\"link\":\"/api/dialects/enzymexla\"},{\"text\":\"Func\",\"link\":\"/api/dialects/func\"},{\"text\":\"GPU\",\"link\":\"/api/dialects/gpu\"},{\"text\":\"LLVM\",\"link\":\"/api/dialects/llvm\"},{\"text\":\"MPI\",\"link\":\"/api/dialects/mpi\"},{\"text\":\"MemRef\",\"link\":\"/api/dialects/memref\"},{\"text\":\"NVVM\",\"link\":\"/api/dialects/nvvm\"},{\"text\":\"Shardy\",\"link\":\"/api/dialects/shardy\"},{\"text\":\"SparseTensor\",\"link\":\"/api/dialects/sparsetensor\"},{\"text\":\"StableHLO\",\"link\":\"/api/dialects/stablehlo\"},{\"text\":\"Triton\",\"link\":\"/api/dialects/triton\"},{\"text\":\"TPU\",\"link\":\"/api/dialects/tpu\"},{\"text\":\"VHLO\",\"link\":\"/api/dialects/vhlo\"}]},{\"text\":\"Low-Level API\",\"items\":[{\"text\":\"MLIR API\",\"link\":\"/api/mlirc\"},{\"text\":\"XLA\",\"link\":\"/api/xla\"}]},{\"text\":\"Internal API\",\"link\":\"/api/internal\"}]},{\"component\":\"VersionPicker\"}],\"sidebar\":{\"/introduction/\":[{\"text\":\"Getting Started\",\"collapsed\":false,\"items\":[{\"text\":\"Introduction\",\"link\":\"/introduction\"},{\"text\":\"Configuration\",\"link\":\"/introduction/configuration\"}]}],\"/tutorials/\":[{\"text\":\"Tutorials\",\"collapsed\":false,\"items\":[{\"text\":\"Overview\",\"link\":\"/tutorials/\"},{\"text\":\"Profiling\",\"link\":\"/tutorials/profiling\"},{\"text\":\"Distributed\",\"link\":\"/tutorials/multihost\"},{\"text\":\"Local build\",\"link\":\"/tutorials/local-build\"}]}],\"/api/\":[{\"text\":\"API Reference\",\"collapsed\":false,\"items\":[{\"text\":\"Reactant API\",\"link\":\"/api/api\"},{\"text\":\"Sharding\",\"link\":\"/api/sharding\"},{\"text\":\"Ops\",\"link\":\"/api/ops\"},{\"text\":\"Configuration\",\"link\":\"/api/config\"},{\"text\":\"MLIR Dialects\",\"collapsed\":false,\"items\":[{\"text\":\"ArithOps\",\"link\":\"/api/dialects/arith\"},{\"text\":\"Affine\",\"link\":\"/api/dialects/affine\"},{\"text\":\"Builtin\",\"link\":\"/api/dialects/builtin\"},{\"text\":\"Chlo\",\"link\":\"/api/dialects/chlo\"},{\"text\":\"Enzyme\",\"link\":\"/api/dialects/enzyme\"},{\"text\":\"EnzymeXLA\",\"link\":\"/api/dialects/enzymexla\"},{\"text\":\"Func\",\"link\":\"/api/dialects/func\"},{\"text\":\"GPU\",\"link\":\"/api/dialects/gpu\"},{\"text\":\"LLVM\",\"link\":\"/api/dialects/llvm\"},{\"text\":\"MPI\",\"link\":\"/api/dialects/mpi\"},{\"text\":\"MemRef\",\"link\":\"/api/dialects/memref\"},{\"text\":\"NVVM\",\"link\":\"/api/dialects/nvvm\"},{\"text\":\"Shardy\",\"link\":\"/api/dialects/shardy\"},{\"text\":\"SparseTensor\",\"link\":\"/api/dialects/sparsetensor\"},{\"text\":\"StableHLO\",\"link\":\"/api/dialects/stablehlo\"},{\"text\":\"Triton\",\"link\":\"/api/dialects/triton\"},{\"text\":\"TPU\",\"link\":\"/api/dialects/tpu\"},{\"text\":\"VHLO\",\"link\":\"/api/dialects/vhlo\"}]},{\"text\":\"Low-Level API\",\"collapsed\":false,\"items\":[{\"text\":\"MLIR API\",\"link\":\"/api/mlirc\"},{\"text\":\"XLA\",\"link\":\"/api/xla\"}]},{\"text\":\"Internal API\",\"link\":\"/api/internal\"}]}]},\"editLink\":{\"pattern\":\"https://github.com/EnzymeAD/Reactant.jl/edit/main/docs/src/:path\",\"text\":\"Edit this page on GitHub\"},\"socialLinks\":[{\"icon\":\"slack\",\"link\":\"https://julialang.org/slack/\"}],\"footer\":{\"message\":\"Made with <a href=\\\"https://documenter.juliadocs.org/stable/\\\" target=\\\"_blank\\\"><strong>Documenter.jl</strong></a>, <a href=\\\"https://vitepress.dev\\\" target=\\\"_blank\\\"><strong>VitePress</strong></a> and <a href=\\\"https://luxdl.github.io/DocumenterVitepress.jl/stable\\\" target=\\\"_blank\\\"><strong>DocumenterVitepress.jl</strong></a><br>Released under the MIT License. Powered by the <a href=\\\"https://www.julialang.org\\\">Julia Programming Language</a>.<br>\",\"copyright\":\"© Copyright 2025 Reactant Development Team.\"},\"lastUpdated\":{\"text\":\"Updated at\",\"formatOptions\":{\"dateStyle\":\"full\",\"timeStyle\":\"medium\"}}},\"locales\":{},\"scrollOffset\":134,\"cleanUrls\":true}");</script>
    
  </body>
</html>