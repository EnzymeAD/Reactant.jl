import{_ as n,C as c,c as r,o as d,j as t,a,al as i,G as s,w as l}from"./chunks/framework.DnC7HlQj.js";const A=JSON.parse('{"title":"Mosaic GPU Dialect","description":"","frontmatter":{},"headers":[],"relativePath":"api/dialects/mosaicgpu.md","filePath":"api/dialects/mosaicgpu.md","lastUpdated":null}'),u={name:"api/dialects/mosaicgpu.md"},p={class:"jldocstring custom-block"},m={class:"jldocstring custom-block"},b={class:"jldocstring custom-block"},h={class:"jldocstring custom-block"},f={class:"jldocstring custom-block"},M={class:"jldocstring custom-block"},g={class:"jldocstring custom-block"},R={class:"jldocstring custom-block"},y={class:"jldocstring custom-block"},_={class:"jldocstring custom-block"},T={class:"jldocstring custom-block"},I={class:"jldocstring custom-block"},j={class:"jldocstring custom-block"};function L(w,e,D,v,k,x){const o=c("Badge");return d(),r("div",null,[e[65]||(e[65]=t("h1",{id:"Mosaic-GPU-Dialect",tabindex:"-1"},[a("Mosaic GPU Dialect "),t("a",{class:"header-anchor",href:"#Mosaic-GPU-Dialect","aria-label":'Permalink to "Mosaic GPU Dialect {#Mosaic-GPU-Dialect}"'},"â€‹")],-1)),t("details",p,[t("summary",null,[e[0]||(e[0]=t("a",{id:"Reactant.MLIR.Dialects.mosaic_gpu.async_load",href:"#Reactant.MLIR.Dialects.mosaic_gpu.async_load"},[t("span",{class:"jlbinding"},"Reactant.MLIR.Dialects.mosaic_gpu.async_load")],-1)),e[1]||(e[1]=a()),s(o,{type:"info",class:"jlObjectType jlFunction",text:"Function"})]),e[3]||(e[3]=i("<p><code>async_load</code></p><p>Schedules an async copy of the contents of the <code>source</code> MemRef in GMEM to the <code>destination</code> MemRef in SMEM. The <code>destination</code> MemRef in SMEM must be contiguous.</p><p>Upon completion of the copy, the <code>complete-tx(complete-count)</code> operation will always be executed on the provided <code>barrier</code>.</p><p>The <code>indices</code> and <code>slice_lengths</code> inputs define what slice of the GMEM <code>source</code> corresponds to the SMEM <code>destination</code>. Both <code>indices</code> and <code>slice_lengths</code> must have a length equal to the rank of the <code>source</code>. The values in <code>indices</code> are the starting indices of each dimension and the values in <code>slice_lengths</code> are the lengths. Providing -1 in <code>slice_lengths</code> indicates that the slice length is 1 and that the corresponding dimension should be collapsed and does not appear in the <code>destination</code> MemRef.</p><p>The data is written in row-major order to the contiguous SMEM <code>destination</code>. The <code>source</code> data does not need to be contiguous, except for the last (and minor-most) dimension.</p><p>The <code>collective</code> attribute can be provided to use TMA multicast to more efficiently load the GMEM data in cases where multiple thread blocks are grouped together in a cluster and need to load the same data. Each block in a cluster will first load a slice from GMEM to SMEM and then the slices will be multicast to all other blocks in the cluster. In this way TMA multicast guarantees L2 cache hits. The <code>collective</code> attribute is the list of cluster dimensions along which to partition the input data loads.</p><p>The <code>predicate</code> allows scheduling the transfer conditionally. The async copy is always scheduled by at most a single lane in the warpgroup.</p>",7)),s(o,{type:"info",class:"source-link",text:"source"},{default:l(()=>[...e[2]||(e[2]=[t("a",{href:"https://github.com/EnzymeAD/Reactant.jl/blob/9157cbb4efd4ab80bd0b3f8e3903f81a9b0679e0/src/mlir/Dialects/MosaicGPU.jl#L35-L67",target:"_blank",rel:"noreferrer"},"source",-1)])]),_:1})]),t("details",m,[t("summary",null,[e[4]||(e[4]=t("a",{id:"Reactant.MLIR.Dialects.mosaic_gpu.async_store",href:"#Reactant.MLIR.Dialects.mosaic_gpu.async_store"},[t("span",{class:"jlbinding"},"Reactant.MLIR.Dialects.mosaic_gpu.async_store")],-1)),e[5]||(e[5]=a()),s(o,{type:"info",class:"jlObjectType jlFunction",text:"Function"})]),e[7]||(e[7]=i("<p><code>async_store</code></p><p>Schedules an async store of the contents of the <code>source</code> MemRef in SMEM to the <code>destination</code> MemRef in GMEM. The <code>source</code> MemRef in SMEM must be contiguous.</p><p>The <code>indices</code> and <code>slice_lengths</code> inputs define what slice of the GMEM <code>destination</code> corresponds to the SMEM <code>source</code>. Both <code>indices</code> and <code>slice_lengths</code> must have a length equal to the rank of the <code>destination</code>. The values in <code>indices</code> are the starting indices of each dimension and the values in <code>slice_lengths</code> are the lengths. Providing -1 in <code>slice_lengths</code> indicates that this dimension is collapsed in the <code>source</code> and needs to be expanded to a slice of size 1 in the <code>destination</code>.</p><p>The data is written in row-major order to the GMEM <code>destination</code>. The <code>source</code> data in SMEM needs to be contiguous, but the <code>destination</code> GMEM does not.</p><p>The <code>predicate</code> allows scheduling the transfer conditionally. The async copy is always scheduled by at most a single lane in the warpgroup.</p>",5)),s(o,{type:"info",class:"source-link",text:"source"},{default:l(()=>[...e[6]||(e[6]=[t("a",{href:"https://github.com/EnzymeAD/Reactant.jl/blob/9157cbb4efd4ab80bd0b3f8e3903f81a9b0679e0/src/mlir/Dialects/MosaicGPU.jl#L126-L147",target:"_blank",rel:"noreferrer"},"source",-1)])]),_:1})]),t("details",b,[t("summary",null,[e[8]||(e[8]=t("a",{id:"Reactant.MLIR.Dialects.mosaic_gpu.broadcast_in_dim-Tuple{Reactant.MLIR.IR.Value}",href:"#Reactant.MLIR.Dialects.mosaic_gpu.broadcast_in_dim-Tuple{Reactant.MLIR.IR.Value}"},[t("span",{class:"jlbinding"},"Reactant.MLIR.Dialects.mosaic_gpu.broadcast_in_dim")],-1)),e[9]||(e[9]=a()),s(o,{type:"info",class:"jlObjectType jlMethod",text:"Method"})]),e[11]||(e[11]=t("p",null,[t("code",null,"broadcast_in_dim")],-1)),e[12]||(e[12]=t("p",null,[t("code",null,"broadcast_dimensions"),a(" must have the same size as the rank of the input vector and for each input dimension, specifies which output dimension it corresponds to.")],-1)),s(o,{type:"info",class:"source-link",text:"source"},{default:l(()=>[...e[10]||(e[10]=[t("a",{href:"https://github.com/EnzymeAD/Reactant.jl/blob/9157cbb4efd4ab80bd0b3f8e3903f81a9b0679e0/src/mlir/Dialects/MosaicGPU.jl#L201-L207",target:"_blank",rel:"noreferrer"},"source",-1)])]),_:1})]),t("details",h,[t("summary",null,[e[13]||(e[13]=t("a",{id:"Reactant.MLIR.Dialects.mosaic_gpu.custom_primitive-Tuple{Vector{Reactant.MLIR.IR.Value}}",href:"#Reactant.MLIR.Dialects.mosaic_gpu.custom_primitive-Tuple{Vector{Reactant.MLIR.IR.Value}}"},[t("span",{class:"jlbinding"},"Reactant.MLIR.Dialects.mosaic_gpu.custom_primitive")],-1)),e[14]||(e[14]=a()),s(o,{type:"info",class:"jlObjectType jlMethod",text:"Method"})]),e[16]||(e[16]=t("p",null,[t("code",null,"custom_primitive")],-1)),e[17]||(e[17]=t("p",null,"Allows defining a custom Mosaic GPU primitive.",-1)),e[18]||(e[18]=t("p",null,"Custom primitives should carry input and output layouts for each of their vector operands and outputs, and input transforms for each of their memref operands that live in SMEM.",-1)),e[19]||(e[19]=t("p",null,"Custom primitives can only return vectors.",-1)),s(o,{type:"info",class:"source-link",text:"source"},{default:l(()=>[...e[15]||(e[15]=[t("a",{href:"https://github.com/EnzymeAD/Reactant.jl/blob/9157cbb4efd4ab80bd0b3f8e3903f81a9b0679e0/src/mlir/Dialects/MosaicGPU.jl#L231-L241",target:"_blank",rel:"noreferrer"},"source",-1)])]),_:1})]),t("details",f,[t("summary",null,[e[20]||(e[20]=t("a",{id:"Reactant.MLIR.Dialects.mosaic_gpu.initialize_barrier-Tuple{Reactant.MLIR.IR.Value}",href:"#Reactant.MLIR.Dialects.mosaic_gpu.initialize_barrier-Tuple{Reactant.MLIR.IR.Value}"},[t("span",{class:"jlbinding"},"Reactant.MLIR.Dialects.mosaic_gpu.initialize_barrier")],-1)),e[21]||(e[21]=a()),s(o,{type:"info",class:"jlObjectType jlMethod",text:"Method"})]),e[23]||(e[23]=t("p",null,[t("code",null,"initialize_barrier")],-1)),e[24]||(e[24]=t("p",null,[a("Initializes a memref of barriers each meant to synchronize exactly "),t("code",null,"arrival_count"),a(" threads.")],-1)),e[25]||(e[25]=t("p",null,[a("The base pointer of the result memref corresponds to "),t("code",null,"base_pointer"),a(", which must be a pointer to a shared memory location.")],-1)),s(o,{type:"info",class:"source-link",text:"source"},{default:l(()=>[...e[22]||(e[22]=[t("a",{href:"https://github.com/EnzymeAD/Reactant.jl/blob/9157cbb4efd4ab80bd0b3f8e3903f81a9b0679e0/src/mlir/Dialects/MosaicGPU.jl#L273-L281",target:"_blank",rel:"noreferrer"},"source",-1)])]),_:1})]),t("details",M,[t("summary",null,[e[26]||(e[26]=t("a",{id:"Reactant.MLIR.Dialects.mosaic_gpu.layout_cast-Tuple{Reactant.MLIR.IR.Value}",href:"#Reactant.MLIR.Dialects.mosaic_gpu.layout_cast-Tuple{Reactant.MLIR.IR.Value}"},[t("span",{class:"jlbinding"},"Reactant.MLIR.Dialects.mosaic_gpu.layout_cast")],-1)),e[27]||(e[27]=a()),s(o,{type:"info",class:"jlObjectType jlMethod",text:"Method"})]),e[29]||(e[29]=t("p",null,[t("code",null,"layout_cast"),a(" Casts a vector value to a new strided or tiled layout.")],-1)),s(o,{type:"info",class:"source-link",text:"source"},{default:l(()=>[...e[28]||(e[28]=[t("a",{href:"https://github.com/EnzymeAD/Reactant.jl/blob/9157cbb4efd4ab80bd0b3f8e3903f81a9b0679e0/src/mlir/Dialects/MosaicGPU.jl#L303-L306",target:"_blank",rel:"noreferrer"},"source",-1)])]),_:1})]),t("details",g,[t("summary",null,[e[30]||(e[30]=t("a",{id:"Reactant.MLIR.Dialects.mosaic_gpu.return_-Tuple{Vector{Reactant.MLIR.IR.Value}}",href:"#Reactant.MLIR.Dialects.mosaic_gpu.return_-Tuple{Vector{Reactant.MLIR.IR.Value}}"},[t("span",{class:"jlbinding"},"Reactant.MLIR.Dialects.mosaic_gpu.return_")],-1)),e[31]||(e[31]=a()),s(o,{type:"info",class:"jlObjectType jlMethod",text:"Method"})]),e[33]||(e[33]=t("p",null,[t("code",null,"return_")],-1)),e[34]||(e[34]=t("p",null,[a("The "),t("code",null,"return"),a(" op is a terminator that indicates the end of execution within a "),t("code",null,"CustomPrimitiveOp"),a("'s region. It can optionally return some values, which become the results of the parent "),t("code",null,"CustomPrimitiveOp"),a(".")],-1)),e[35]||(e[35]=t("p",null,[a("The declared results of the parent "),t("code",null,"CustomPrimitiveOp"),a(" must match the operand types of this op.")],-1)),s(o,{type:"info",class:"source-link",text:"source"},{default:l(()=>[...e[32]||(e[32]=[t("a",{href:"https://github.com/EnzymeAD/Reactant.jl/blob/9157cbb4efd4ab80bd0b3f8e3903f81a9b0679e0/src/mlir/Dialects/MosaicGPU.jl#L353-L362",target:"_blank",rel:"noreferrer"},"source",-1)])]),_:1})]),t("details",R,[t("summary",null,[e[36]||(e[36]=t("a",{id:"Reactant.MLIR.Dialects.mosaic_gpu.tcgen05_mma",href:"#Reactant.MLIR.Dialects.mosaic_gpu.tcgen05_mma"},[t("span",{class:"jlbinding"},"Reactant.MLIR.Dialects.mosaic_gpu.tcgen05_mma")],-1)),e[37]||(e[37]=a()),s(o,{type:"info",class:"jlObjectType jlFunction",text:"Function"})]),e[39]||(e[39]=i('<p><code>tcgen05_mma</code></p><p>Schedules <code>tcgen05.mma</code> instructions that perform the following matrix multiply and accumulate:</p><p>accumulator += a * b</p><p>This operation supports larger inputs than the PTX-level MMA instruction and will schedule as many PTX-level MMA instructions as needed to accomplish the calculation.</p><p>The inputs should have the following shapes:</p><ul><li><p>a: [groups_m * m, groups_k * s]</p></li><li><p>b: [groups_k * s, groups_n * s]</p></li><li><p>accumulator: [groups_m * m, groups_n * s]</p></li></ul><p>where <code>s == swizzle / element_bytewidth</code> and <code>m</code> is specified according to <a href="https://docs.nvidia.com/cuda/parallel-thread-execution/#tcgen05-matrix-shape" target="_blank" rel="noreferrer">https://docs.nvidia.com/cuda/parallel-thread-execution/#tcgen05-matrix-shape</a>.</p><p>The <code>accumulator</code>, <code>a</code> and <code>b</code> matrices need to be provided as 2-dimensional memrefs. The <code>accumulator</code> is always in TMEM and <code>b</code> is always in SMEM. <code>a</code> can be in TMEM or SMEM. <code>a</code> and <code>b</code> must have the same element type and when <code>a</code> is in TMEM only F16 or BF16 are supported.</p><p><code>a_scale</code> and <code>b_scale</code> are optional scaling matrices that reside in TMEM. When set the operation is defined as:</p><p>accumulator += (a * a_scale) * (b * b_scale)</p><p><code>accumulate</code> is a boolean that indicates whether to perform the accumulate step.</p>',11)),s(o,{type:"info",class:"source-link",text:"source"},{default:l(()=>[...e[38]||(e[38]=[t("a",{href:"https://github.com/EnzymeAD/Reactant.jl/blob/9157cbb4efd4ab80bd0b3f8e3903f81a9b0679e0/src/mlir/Dialects/MosaicGPU.jl#L401-L432",target:"_blank",rel:"noreferrer"},"source",-1)])]),_:1})]),t("details",y,[t("summary",null,[e[40]||(e[40]=t("a",{id:"Reactant.MLIR.Dialects.mosaic_gpu.tmem_alloc-Tuple{Reactant.MLIR.IR.Value}",href:"#Reactant.MLIR.Dialects.mosaic_gpu.tmem_alloc-Tuple{Reactant.MLIR.IR.Value}"},[t("span",{class:"jlbinding"},"Reactant.MLIR.Dialects.mosaic_gpu.tmem_alloc")],-1)),e[41]||(e[41]=a()),s(o,{type:"info",class:"jlObjectType jlMethod",text:"Method"})]),e[43]||(e[43]=i(`<p><code>tmem_alloc</code></p><p>This op allocates a chunk of TMEM and stores the pointer to the memory in the provided SMEM memref.</p><p>The <code>smem_ptr</code> is a pointer in SMEM where a pointer to the allocated TMEM will be stored. The op returns a memref to the allocated TMEM. The result must have a shape with dimensions [rows, logical_columns]. If <code>packing</code> is 1, then the number of logical (unpacked) columns is equal to the number of allocated columns in TMEM. Otherwise, these equations must hold:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>packing = 32 / bitwidth(element type of result)</span></span>
<span class="line"><span>unpacked_columns = allocated_columns * packing</span></span></code></pre></div><p>The number of allocated columns in TMEM can be any power of two in the range [32, 512]. If <code>exact</code> is <code>true</code>, then the calculated number of allocated columns must match that restriction. If <code>exact</code> is <code>false</code> and the calculated number of allocated columns is less than 32 or not a power of two, then it will be rounded up to the nearest power of two larger or equal to 32.</p><p>If <code>collective</code> is <code>true</code> 2 CTAs will perform the allocation collectively, otherwise, only one CTA will perform the allocation.</p>`,6)),s(o,{type:"info",class:"source-link",text:"source"},{default:l(()=>[...e[42]||(e[42]=[t("a",{href:"https://github.com/EnzymeAD/Reactant.jl/blob/9157cbb4efd4ab80bd0b3f8e3903f81a9b0679e0/src/mlir/Dialects/MosaicGPU.jl#L477-L502",target:"_blank",rel:"noreferrer"},"source",-1)])]),_:1})]),t("details",_,[t("summary",null,[e[44]||(e[44]=t("a",{id:"Reactant.MLIR.Dialects.mosaic_gpu.tmem_relinquish_alloc_permit-Tuple{}",href:"#Reactant.MLIR.Dialects.mosaic_gpu.tmem_relinquish_alloc_permit-Tuple{}"},[t("span",{class:"jlbinding"},"Reactant.MLIR.Dialects.mosaic_gpu.tmem_relinquish_alloc_permit")],-1)),e[45]||(e[45]=a()),s(o,{type:"info",class:"jlObjectType jlMethod",text:"Method"})]),e[47]||(e[47]=t("p",null,[t("code",null,"tmem_relinquish_alloc_permit")],-1)),e[48]||(e[48]=t("p",null,[a("The instruction specifies that the CTA of the executing thread is relinquishing the right to allocate Tensor Memory. So, it is illegal for a CTA to perform "),t("code",null,"tmem_alloc"),a(" after any of its constituent threads execute "),t("code",null,"tmem_relinquish_alloc_permit"),a(".")],-1)),e[49]||(e[49]=t("p",null,[a("If "),t("code",null,"collective"),a(" is "),t("code",null,"true"),a(", applies to collective TMEM allocations.")],-1)),s(o,{type:"info",class:"source-link",text:"source"},{default:l(()=>[...e[46]||(e[46]=[t("a",{href:"https://github.com/EnzymeAD/Reactant.jl/blob/9157cbb4efd4ab80bd0b3f8e3903f81a9b0679e0/src/mlir/Dialects/MosaicGPU.jl#L551-L560",target:"_blank",rel:"noreferrer"},"source",-1)])]),_:1})]),t("details",T,[t("summary",null,[e[50]||(e[50]=t("a",{id:"Reactant.MLIR.Dialects.mosaic_gpu.wait-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}",href:"#Reactant.MLIR.Dialects.mosaic_gpu.wait-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}"},[t("span",{class:"jlbinding"},"Reactant.MLIR.Dialects.mosaic_gpu.wait")],-1)),e[51]||(e[51]=a()),s(o,{type:"info",class:"jlObjectType jlMethod",text:"Method"})]),e[53]||(e[53]=t("p",null,[t("code",null,"wait")],-1)),e[54]||(e[54]=t("p",null,"All threads in the warpgroup will block, waiting on the provided barrier until:",-1)),e[55]||(e[55]=t("ul",null,[t("li",null,[t("p",null,"all pending threads have arrived on the barrier")]),t("li",null,[t("p",null,"all expected byte transfers have been completed")]),t("li",null,[t("p",null,"the barrier's parity matches the provided parity")])],-1)),s(o,{type:"info",class:"source-link",text:"source"},{default:l(()=>[...e[52]||(e[52]=[t("a",{href:"https://github.com/EnzymeAD/Reactant.jl/blob/9157cbb4efd4ab80bd0b3f8e3903f81a9b0679e0/src/mlir/Dialects/MosaicGPU.jl#L641-L649",target:"_blank",rel:"noreferrer"},"source",-1)])]),_:1})]),t("details",I,[t("summary",null,[e[56]||(e[56]=t("a",{id:"Reactant.MLIR.Dialects.mosaic_gpu.wgmma-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}",href:"#Reactant.MLIR.Dialects.mosaic_gpu.wgmma-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}"},[t("span",{class:"jlbinding"},"Reactant.MLIR.Dialects.mosaic_gpu.wgmma")],-1)),e[57]||(e[57]=a()),s(o,{type:"info",class:"jlObjectType jlMethod",text:"Method"})]),e[59]||(e[59]=i("<p><code>wgmma</code></p><p>Schedules WGMMA operations that perform the following matrix multiply and accumulate:</p><p>accumulator = a * b + accumulator</p><p>This operation supports larger inputs than the PTX-level WGMMA operation and will schedule as many PTX-level WGMMA operations as needed to accomplish the calculation. The <code>b</code> matrix, and optionally <code>a</code>, need to be provided as a 2-dimensional memref.</p><p>The inputs should have the following shapes:</p><ul><li><p>a: [groups_m * 64, groups_k * s]</p></li><li><p>b: [groups_k * s, groups_n * s]</p></li><li><p>accumulator: [groups_m * 64, groups_n * s]</p></li></ul><p>where <code>s == swizzle / element_bytewidth</code>.</p><p>The output has an identical shape and type as the input accumulator.</p><p>The <code>accumulator</code> is always in registers and <code>b</code> is always in shared memory. <code>a</code> and <code>b</code> must have the same element type and when <code>a</code> is in registers only F16 or BF16 are supported.</p><p>The <code>accumulator</code> must be a vector with a FragmentedLayout. The WGMMA operation will be executed in the async proxy and any inputs in registers need to be synchronized with a memory fence.</p><p>Usually <code>a</code> is read from shared memory if it is used directly in the WGMMA operation. If <code>a</code> needs to be transformed before it is used in the WGMMA operation, it may be more convenient to read it directly form registers. This avoids the need to store the data and wait for a fence.</p>",11)),s(o,{type:"info",class:"source-link",text:"source"},{default:l(()=>[...e[58]||(e[58]=[t("a",{href:"https://github.com/EnzymeAD/Reactant.jl/blob/9157cbb4efd4ab80bd0b3f8e3903f81a9b0679e0/src/mlir/Dialects/MosaicGPU.jl#L581-L614",target:"_blank",rel:"noreferrer"},"source",-1)])]),_:1})]),t("details",j,[t("summary",null,[e[60]||(e[60]=t("a",{id:"Reactant.MLIR.Dialects.mosaic_gpu.with_transforms-Tuple{Reactant.MLIR.IR.Value}",href:"#Reactant.MLIR.Dialects.mosaic_gpu.with_transforms-Tuple{Reactant.MLIR.IR.Value}"},[t("span",{class:"jlbinding"},"Reactant.MLIR.Dialects.mosaic_gpu.with_transforms")],-1)),e[61]||(e[61]=a()),s(o,{type:"info",class:"jlObjectType jlMethod",text:"Method"})]),e[63]||(e[63]=t("p",null,[t("code",null,"with_transforms")],-1)),e[64]||(e[64]=t("p",null,"This op enforces the provided transforms on the parameter memref.",-1)),s(o,{type:"info",class:"source-link",text:"source"},{default:l(()=>[...e[62]||(e[62]=[t("a",{href:"https://github.com/EnzymeAD/Reactant.jl/blob/9157cbb4efd4ab80bd0b3f8e3903f81a9b0679e0/src/mlir/Dialects/MosaicGPU.jl#L669-L673",target:"_blank",rel:"noreferrer"},"source",-1)])]),_:1})])])}const P=n(u,[["render",L]]);export{A as __pageData,P as default};
