<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>CUDA Tile IR Dialect | Reactant.jl</title>
    <meta name="description" content="Documentation for Reactant.jl">
    <meta name="generator" content="VitePress v1.6.4">
    <link rel="preload stylesheet" href="/Reactant.jl/previews/PR2507/assets/style.2Y3_YJlv.css" as="style">
    <link rel="preload stylesheet" href="/Reactant.jl/previews/PR2507/vp-icons.css" as="style">
    
    <script type="module" src="/Reactant.jl/previews/PR2507/assets/app.BlXW0aJY.js"></script>
    <link rel="preload" href="/Reactant.jl/previews/PR2507/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/Reactant.jl/previews/PR2507/assets/chunks/theme.C8MC4nnG.js">
    <link rel="modulepreload" href="/Reactant.jl/previews/PR2507/assets/chunks/framework.pq84Pdzz.js">
    <link rel="modulepreload" href="/Reactant.jl/previews/PR2507/assets/api_dialects_cuda_tile.md.BfG7BXTs.lean.js">
    <link rel="icon" href="/Reactant.jl/previews/PR2507/favicon.ico">
    <script src="/versions.js"></script>
    <script src="/Reactant.jl/previews/PR2507/siteinfo.js"></script>
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-a9a9e638><!--[--><!--]--><!--[--><span tabindex="-1" data-v-492508fc></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-492508fc>Skip to content</a><!--]--><!----><header class="VPNav" data-v-a9a9e638 data-v-f1e365da><div class="VPNavBar" data-v-f1e365da data-v-822684d1><div class="wrapper" data-v-822684d1><div class="container" data-v-822684d1><div class="title" data-v-822684d1><div class="VPNavBarTitle has-sidebar" data-v-822684d1 data-v-0f4f798b><a class="title" href="/Reactant.jl/previews/PR2507/" data-v-0f4f798b><!--[--><!--]--><!--[--><!--[--><!--[--><img class="VPImage dark logo" src="/Reactant.jl/previews/PR2507/logo.svg" alt data-v-35a7d0b8><!--]--><!--[--><img class="VPImage light logo" src="/Reactant.jl/previews/PR2507/logo.svg" alt data-v-35a7d0b8><!--]--><!--]--><!--]--><span data-v-0f4f798b>Reactant.jl</span><!--[--><!--]--></a></div></div><div class="content" data-v-822684d1><div class="content-body" data-v-822684d1><!--[--><!--]--><div class="VPNavBarSearch search" data-v-822684d1><!--[--><!----><div id="local-search"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><span class="vp-icon DocSearch-Search-Icon"></span><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-822684d1 data-v-e6d46098><span id="main-nav-aria-label" class="visually-hidden" data-v-e6d46098> Main Navigation </span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/Reactant.jl/previews/PR2507/" tabindex="0" data-v-e6d46098 data-v-956ec74c><!--[--><span data-v-956ec74c>Home</span><!--]--></a><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-e6d46098 data-v-04f5c5e9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-04f5c5e9><span class="text" data-v-04f5c5e9><!----><span data-v-04f5c5e9>Getting Started</span><span class="vpi-chevron-down text-icon" data-v-04f5c5e9></span></span></button><div class="menu" data-v-04f5c5e9><div class="VPMenu" data-v-04f5c5e9 data-v-7dd3104a><div class="items" data-v-7dd3104a><!--[--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR2507/introduction" data-v-acbfed09><!--[--><span data-v-acbfed09>Introduction</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR2507/introduction/configuration" data-v-acbfed09><!--[--><span data-v-acbfed09>Configuration</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR2507/introduction/FAQs" data-v-acbfed09><!--[--><span data-v-acbfed09>FAQs</span><!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><a class="VPLink link vp-external-link-icon VPNavBarMenuLink" href="https://enzymead.github.io/Reactant.jl/benchmarks/" target="_blank" rel="noreferrer" tabindex="0" data-v-e6d46098 data-v-956ec74c><!--[--><span data-v-956ec74c>Benchmarks</span><!--]--></a><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-e6d46098 data-v-04f5c5e9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-04f5c5e9><span class="text" data-v-04f5c5e9><!----><span data-v-04f5c5e9>Tutorials</span><span class="vpi-chevron-down text-icon" data-v-04f5c5e9></span></span></button><div class="menu" data-v-04f5c5e9><div class="VPMenu" data-v-04f5c5e9 data-v-7dd3104a><div class="items" data-v-7dd3104a><!--[--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR2507/tutorials/" data-v-acbfed09><!--[--><span data-v-acbfed09>Overview</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR2507/tutorials/partial-evaluation" data-v-acbfed09><!--[--><span data-v-acbfed09>Partial Evaluation</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR2507/tutorials/control-flow" data-v-acbfed09><!--[--><span data-v-acbfed09>Control Flow</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR2507/tutorials/automatic-differentiation" data-v-acbfed09><!--[--><span data-v-acbfed09>Automatic Differentiation</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR2507/tutorials/sharding" data-v-acbfed09><!--[--><span data-v-acbfed09>Sharding</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR2507/tutorials/profiling" data-v-acbfed09><!--[--><span data-v-acbfed09>Profiling</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR2507/tutorials/multihost" data-v-acbfed09><!--[--><span data-v-acbfed09>Multi-Host Environments</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR2507/tutorials/local-build" data-v-acbfed09><!--[--><span data-v-acbfed09>Local build</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR2507/tutorials/persistent_compile_cache" data-v-acbfed09><!--[--><span data-v-acbfed09>Persistent Compilation Cache</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR2507/tutorials/raising" data-v-acbfed09><!--[--><span data-v-acbfed09>Raising</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR2507/tutorials/kernels" data-v-acbfed09><!--[--><span data-v-acbfed09>Computational kernels</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR2507/tutorials/debugging" data-v-acbfed09><!--[--><span data-v-acbfed09>Debugging compilation errors</span><!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup active" data-v-e6d46098 data-v-04f5c5e9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-04f5c5e9><span class="text" data-v-04f5c5e9><!----><span data-v-04f5c5e9>API</span><span class="vpi-chevron-down text-icon" data-v-04f5c5e9></span></span></button><div class="menu" data-v-04f5c5e9><div class="VPMenu" data-v-04f5c5e9 data-v-7dd3104a><div class="items" data-v-7dd3104a><!--[--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR2507/api/api" data-v-acbfed09><!--[--><span data-v-acbfed09>Core Reactant API</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR2507/api/sharding" data-v-acbfed09><!--[--><span data-v-acbfed09>Sharding</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR2507/api/serialization" data-v-acbfed09><!--[--><span data-v-acbfed09>Serialization</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR2507/api/ops" data-v-acbfed09><!--[--><span data-v-acbfed09>Ops</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR2507/api/config" data-v-acbfed09><!--[--><span data-v-acbfed09>Configuration</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuGroup" data-v-7dd3104a data-v-48c802d0><p class="title" data-v-48c802d0>MLIR Dialects</p><!--[--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR2507/api/dialects/arith" data-v-acbfed09><!--[--><span data-v-acbfed09>ArithOps</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR2507/api/dialects/affine" data-v-acbfed09><!--[--><span data-v-acbfed09>Affine</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR2507/api/dialects/builtin" data-v-acbfed09><!--[--><span data-v-acbfed09>Builtin</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR2507/api/dialects/chlo" data-v-acbfed09><!--[--><span data-v-acbfed09>Chlo</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR2507/api/dialects/complex" data-v-acbfed09><!--[--><span data-v-acbfed09>Complex</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link active" href="/Reactant.jl/previews/PR2507/api/dialects/cuda_tile" data-v-acbfed09><!--[--><span data-v-acbfed09>CUDA Tile</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR2507/api/dialects/enzyme" data-v-acbfed09><!--[--><span data-v-acbfed09>Enzyme</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR2507/api/dialects/enzymexla" data-v-acbfed09><!--[--><span data-v-acbfed09>EnzymeXLA</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR2507/api/dialects/func" data-v-acbfed09><!--[--><span data-v-acbfed09>Func</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR2507/api/dialects/gpu" data-v-acbfed09><!--[--><span data-v-acbfed09>GPU</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR2507/api/dialects/llvm" data-v-acbfed09><!--[--><span data-v-acbfed09>LLVM</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR2507/api/dialects/mpi" data-v-acbfed09><!--[--><span data-v-acbfed09>MPI</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR2507/api/dialects/memref" data-v-acbfed09><!--[--><span data-v-acbfed09>MemRef</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR2507/api/dialects/mosaicgpu" data-v-acbfed09><!--[--><span data-v-acbfed09>Mosaic GPU</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR2507/api/dialects/nvvm" data-v-acbfed09><!--[--><span data-v-acbfed09>NVVM</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR2507/api/dialects/shape" data-v-acbfed09><!--[--><span data-v-acbfed09>Shape</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR2507/api/dialects/shardy" data-v-acbfed09><!--[--><span data-v-acbfed09>Shardy</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR2507/api/dialects/sparsetensor" data-v-acbfed09><!--[--><span data-v-acbfed09>SparseTensor</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR2507/api/dialects/stablehlo" data-v-acbfed09><!--[--><span data-v-acbfed09>StableHLO</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR2507/api/dialects/tensor" data-v-acbfed09><!--[--><span data-v-acbfed09>Tensor</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR2507/api/dialects/triton" data-v-acbfed09><!--[--><span data-v-acbfed09>Triton</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR2507/api/dialects/tritonext" data-v-acbfed09><!--[--><span data-v-acbfed09>TritonExt</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR2507/api/dialects/tpu" data-v-acbfed09><!--[--><span data-v-acbfed09>TPU</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR2507/api/dialects/vhlo" data-v-acbfed09><!--[--><span data-v-acbfed09>VHLO</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-7dd3104a data-v-48c802d0><p class="title" data-v-48c802d0>Low-Level API</p><!--[--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR2507/api/mlirc" data-v-acbfed09><!--[--><span data-v-acbfed09>MLIR API</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR2507/api/xla" data-v-acbfed09><!--[--><span data-v-acbfed09>XLA</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/Reactant.jl/previews/PR2507/api/internal" data-v-acbfed09><!--[--><span data-v-acbfed09>Internal API</span><!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><!----><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-822684d1 data-v-af096f4a><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-af096f4a data-v-e40a8bb6 data-v-4a1c76db><span class="check" data-v-4a1c76db><span class="icon" data-v-4a1c76db><!--[--><span class="vpi-sun sun" data-v-e40a8bb6></span><span class="vpi-moon moon" data-v-e40a8bb6></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-822684d1 data-v-164c457f data-v-ee7a9424><!--[--><a class="VPSocialLink no-icon" href="https://julialang.org/slack/" aria-label="slack" target="_blank" rel="noopener" data-v-ee7a9424 data-v-d26d30cb><span class="vpi-social-slack"></span></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-822684d1 data-v-925effce data-v-04f5c5e9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-04f5c5e9><span class="vpi-more-horizontal icon" data-v-04f5c5e9></span></button><div class="menu" data-v-04f5c5e9><div class="VPMenu" data-v-04f5c5e9 data-v-7dd3104a><!----><!--[--><!--[--><!----><div class="group" data-v-925effce><div class="item appearance" data-v-925effce><p class="label" data-v-925effce>Appearance</p><div class="appearance-action" data-v-925effce><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-925effce data-v-e40a8bb6 data-v-4a1c76db><span class="check" data-v-4a1c76db><span class="icon" data-v-4a1c76db><!--[--><span class="vpi-sun sun" data-v-e40a8bb6></span><span class="vpi-moon moon" data-v-e40a8bb6></span><!--]--></span></span></button></div></div></div><div class="group" data-v-925effce><div class="item social-links" data-v-925effce><div class="VPSocialLinks social-links-list" data-v-925effce data-v-ee7a9424><!--[--><a class="VPSocialLink no-icon" href="https://julialang.org/slack/" aria-label="slack" target="_blank" rel="noopener" data-v-ee7a9424 data-v-d26d30cb><span class="vpi-social-slack"></span></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--[--><!--[--><!--[--><a target="_blank" data-decoration="★" title="305 GitHub stars" href="https://github.com/EnzymeAD/Reactant.jl" data-v-b4d08338><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="20" height="20" fill="currentColor" style="vertical-align:middle;margin-right:0.25rem;margin-left:0.5rem;" data-v-b4d08338><path d="M12 .297C5.375.297 0 5.673 0 12.3c0 5.292 3.438 9.8 8.207 11.387.6.11.793-.26.793-.577 0-.285-.01-1.04-.015-2.04-3.338.727-4.042-1.61-4.042-1.61-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.807 1.305 3.493.997.107-.774.42-1.305.762-1.605-2.665-.3-5.467-1.333-5.467-5.931 0-1.31.47-2.382 1.236-3.222-.123-.303-.535-1.52.117-3.166 0 0 1.01-.323 3.31 1.23.96-.267 1.98-.4 3-.405 1.02.005 2.04.138 3 .405 2.3-1.553 3.31-1.23 3.31-1.23.653 1.646.24 2.863.117 3.166.765.84 1.236 1.912 1.236 3.222 0 4.61-2.807 5.625-5.477 5.921.43.372.823 1.102.823 2.222 0 1.606-.015 2.902-.015 3.293 0 .32.192.693.8.577C20.565 22.1 24 17.588 24 12.297 24 5.673 18.627.297 12 .297z" data-v-b4d08338></path></svg><span data-v-b4d08338>0.3k</span></a><a class="mobile" target="_blank" title="305 GitHub stars" href="https://github.com/EnzymeAD/Reactant.jl" data-v-b4d08338><svg xmlns="http://www.w3.org/2000/svg" width="21" height="21" viewBox="0 0 21 21" fill="none" data-v-b4d08338><path d="M19.625 5.60534C18.7083 4.03477 17.4649 2.79135 15.8945 1.87479C14.3238 0.958185 12.6091 0.5 10.7492 0.5C8.88947 0.5 7.17422 0.958325 5.60388 1.87479C4.0333 2.7913 2.78997 4.03477 1.87332 5.60534C0.956814 7.17587 0.498535 8.89089 0.498535 10.7504C0.498535 12.984 1.15021 14.9926 2.4539 16.7766C3.75744 18.5607 5.44142 19.7952 7.50571 20.4803C7.746 20.5249 7.92388 20.4936 8.03954 20.387C8.15524 20.2804 8.21302 20.1467 8.21302 19.9868C8.21302 19.9601 8.21073 19.7199 8.20629 19.266C8.20171 18.8122 8.19956 18.4162 8.19956 18.0783L7.89256 18.1315C7.69682 18.1673 7.44989 18.1825 7.15178 18.1782C6.8538 18.174 6.54446 18.1428 6.22419 18.0847C5.90377 18.0272 5.60575 17.8937 5.32988 17.6846C5.05416 17.4755 4.85842 17.2018 4.74272 16.8639L4.60925 16.5568C4.52029 16.3523 4.38023 16.1251 4.18888 15.8761C3.99754 15.6269 3.80405 15.458 3.60831 15.369L3.51486 15.3021C3.45259 15.2577 3.39481 15.204 3.34138 15.1418C3.28799 15.0796 3.24802 15.0173 3.22132 14.955C3.19458 14.8926 3.21674 14.8414 3.28804 14.8012C3.35933 14.761 3.48817 14.7416 3.67512 14.7416L3.94196 14.7814C4.11993 14.8171 4.34007 14.9236 4.60266 15.1017C4.86511 15.2796 5.08085 15.5109 5.24994 15.7956C5.4547 16.1605 5.7014 16.4385 5.99072 16.6299C6.27982 16.8212 6.5713 16.9167 6.86488 16.9167C7.15846 16.9167 7.41203 16.8945 7.62567 16.8502C7.83908 16.8057 8.0393 16.7388 8.22625 16.6499C8.30633 16.0535 8.52437 15.5953 8.88017 15.275C8.37304 15.2217 7.9171 15.1414 7.51212 15.0347C7.10736 14.9278 6.6891 14.7544 6.25761 14.5139C5.82589 14.2738 5.46774 13.9756 5.18309 13.6198C4.89839 13.2639 4.66474 12.7966 4.48247 12.2183C4.3001 11.6399 4.20889 10.9726 4.20889 10.2163C4.20889 9.13941 4.56044 8.22304 5.26341 7.46665C4.93411 6.65705 4.96519 5.74947 5.35676 4.744C5.61482 4.66382 5.9975 4.72399 6.50463 4.92412C7.01186 5.12434 7.38323 5.29587 7.61912 5.43808C7.85502 5.58024 8.04402 5.70071 8.18642 5.79842C9.01411 5.56715 9.86825 5.45149 10.7491 5.45149C11.6299 5.45149 12.4843 5.56715 13.312 5.79842L13.8192 5.47823C14.166 5.26459 14.5756 5.06881 15.0469 4.89083C15.5185 4.71295 15.8791 4.66396 16.1284 4.74414C16.5286 5.74966 16.5643 6.65719 16.2349 7.46679C16.9378 8.22318 17.2895 9.13978 17.2895 10.2164C17.2895 10.9727 17.198 11.6421 17.0159 12.225C16.8336 12.808 16.5979 13.2749 16.3088 13.6265C16.0194 13.9781 15.659 14.274 15.2275 14.5141C14.7959 14.7544 14.3775 14.9278 13.9728 15.0347C13.5678 15.1415 13.1119 15.2219 12.6047 15.2752C13.0673 15.6755 13.2986 16.3073 13.2986 17.1704V19.9864C13.2986 20.1464 13.3542 20.2799 13.4656 20.3867C13.5768 20.4932 13.7524 20.5246 13.9927 20.4799C16.0573 19.7949 17.7413 18.5603 19.0448 16.7762C20.3481 14.9922 21 12.9837 21 10.75C20.9996 8.89075 20.541 7.17587 19.625 5.60534Z" fill="currentColor" data-v-b4d08338></path></svg></a><!--]--><div class="VPFlyout VPNolebaseEnhancedReadabilitiesMenu VPNolebaseEnhancedReadabilitiesMenuFlyout" aria-label="Enhanced Readability" role="menuitem" data-v-04f5c5e9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-04f5c5e9><span class="text" data-v-04f5c5e9><span class="i-icon-park-outline:book-open option-icon" data-v-04f5c5e9></span><!----><span class="vpi-chevron-down text-icon" data-v-04f5c5e9></span></span></button><div class="menu" data-v-04f5c5e9><div class="VPMenu" data-v-04f5c5e9 data-v-7dd3104a><!----><!--[--><!--]--></div></div></div><!--]--><!--]--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-822684d1 data-v-5dea55bf><span class="container" data-v-5dea55bf><span class="top" data-v-5dea55bf></span><span class="middle" data-v-5dea55bf></span><span class="bottom" data-v-5dea55bf></span></span></button></div></div></div></div><div class="divider" data-v-822684d1><div class="divider-line" data-v-822684d1></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-a9a9e638 data-v-070ab83d><div class="container" data-v-070ab83d><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-070ab83d><span class="vpi-align-left menu-icon" data-v-070ab83d></span><span class="menu-text" data-v-070ab83d>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-070ab83d data-v-168ddf5d><button data-v-168ddf5d>Return to top</button><!----></div></div></div><aside class="VPSidebar" data-v-a9a9e638 data-v-18756405><div class="curtain" data-v-18756405></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-18756405><span class="visually-hidden" id="sidebar-aria-label" data-v-18756405> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-9e426adc><section class="VPSidebarItem level-0 collapsible has-active" data-v-9e426adc data-v-a4b0d9bf><div class="item" role="button" tabindex="0" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><h2 class="text" data-v-a4b0d9bf>API Reference</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-a4b0d9bf><span class="vpi-chevron-right caret-icon" data-v-a4b0d9bf></span></div></div><div class="items" data-v-a4b0d9bf><!--[--><div class="VPSidebarItem level-1 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/Reactant.jl/previews/PR2507/api/api" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Reactant API</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/Reactant.jl/previews/PR2507/api/sharding" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Sharding</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/Reactant.jl/previews/PR2507/api/serialization" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Serialization</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/Reactant.jl/previews/PR2507/api/ops" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Ops</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/Reactant.jl/previews/PR2507/api/config" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Configuration</p><!--]--></a><!----></div><!----></div><section class="VPSidebarItem level-1 collapsible has-active" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" role="button" tabindex="0" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><h3 class="text" data-v-a4b0d9bf>MLIR Dialects</h3><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-a4b0d9bf><span class="vpi-chevron-right caret-icon" data-v-a4b0d9bf></span></div></div><div class="items" data-v-a4b0d9bf><!--[--><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/Reactant.jl/previews/PR2507/api/dialects/arith" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>ArithOps</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/Reactant.jl/previews/PR2507/api/dialects/affine" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Affine</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/Reactant.jl/previews/PR2507/api/dialects/builtin" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Builtin</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/Reactant.jl/previews/PR2507/api/dialects/chlo" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Chlo</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/Reactant.jl/previews/PR2507/api/dialects/complex" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Complex</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/Reactant.jl/previews/PR2507/api/dialects/cuda_tile" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>CUDA Tile</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/Reactant.jl/previews/PR2507/api/dialects/enzyme" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Enzyme</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/Reactant.jl/previews/PR2507/api/dialects/enzymexla" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>EnzymeXLA</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/Reactant.jl/previews/PR2507/api/dialects/func" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Func</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/Reactant.jl/previews/PR2507/api/dialects/gpu" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>GPU</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/Reactant.jl/previews/PR2507/api/dialects/llvm" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>LLVM</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/Reactant.jl/previews/PR2507/api/dialects/mpi" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>MPI</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/Reactant.jl/previews/PR2507/api/dialects/memref" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>MemRef</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/Reactant.jl/previews/PR2507/api/dialects/mosaicgpu" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Mosaic GPU</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/Reactant.jl/previews/PR2507/api/dialects/nvvm" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>NVVM</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/Reactant.jl/previews/PR2507/api/dialects/shape" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Shape</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/Reactant.jl/previews/PR2507/api/dialects/shardy" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Shardy</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/Reactant.jl/previews/PR2507/api/dialects/sparsetensor" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>SparseTensor</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/Reactant.jl/previews/PR2507/api/dialects/stablehlo" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>StableHLO</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/Reactant.jl/previews/PR2507/api/dialects/tensor" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Tensor</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/Reactant.jl/previews/PR2507/api/dialects/triton" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Triton</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/Reactant.jl/previews/PR2507/api/dialects/tritonext" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>TritonExt</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/Reactant.jl/previews/PR2507/api/dialects/tpu" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>TPU</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/Reactant.jl/previews/PR2507/api/dialects/vhlo" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>VHLO</p><!--]--></a><!----></div><!----></div><!--]--></div></section><section class="VPSidebarItem level-1 collapsible" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" role="button" tabindex="0" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><h3 class="text" data-v-a4b0d9bf>Low-Level API</h3><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-a4b0d9bf><span class="vpi-chevron-right caret-icon" data-v-a4b0d9bf></span></div></div><div class="items" data-v-a4b0d9bf><!--[--><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/Reactant.jl/previews/PR2507/api/mlirc" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>MLIR API</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/Reactant.jl/previews/PR2507/api/xla" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>XLA</p><!--]--></a><!----></div><!----></div><!--]--></div></section><div class="VPSidebarItem level-1 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/Reactant.jl/previews/PR2507/api/internal" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Internal API</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-a9a9e638 data-v-91765379><div class="VPDoc has-sidebar has-aside" data-v-91765379 data-v-83890dd9><!--[--><!--]--><div class="container" data-v-83890dd9><div class="aside" data-v-83890dd9><div class="aside-curtain" data-v-83890dd9></div><div class="aside-container" data-v-83890dd9><div class="aside-content" data-v-83890dd9><div class="VPDocAside" data-v-83890dd9 data-v-6d7b3c46><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-6d7b3c46 data-v-b38bf2ff><div class="content" data-v-b38bf2ff><div class="outline-marker" data-v-b38bf2ff></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-b38bf2ff>On this page</div><ul class="VPDocOutlineItem root" data-v-b38bf2ff data-v-3f927ebe><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-6d7b3c46></div><!--[--><!--[--><!--[--><!--[--><!--[--><br><h2> Trusted by </h2><a class="enjoyer" href="https://lux.csail.mit.edu/" target="_blank"><img width="32" height="32" src="https://raw.githubusercontent.com/LuxDL/Lux.jl/refs/heads/main/assets/lux-logo.svg"><span><p class="extra-info">Scientific Computing</p><p class="heading">Lux.jl</p><p class="extra-info">Machine Learning</p></span></a><!--]--><!--]--><!--]--><!--]--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-83890dd9><div class="content-container" data-v-83890dd9><!--[--><!--]--><main class="main" data-v-83890dd9><div style="position:relative;" class="vp-doc _Reactant_jl_previews_PR2507_api_dialects_cuda_tile" data-v-83890dd9><div><h1 id="CUDA-Tile-IR-Dialect" tabindex="-1">CUDA Tile IR Dialect <a class="header-anchor" href="#CUDA-Tile-IR-Dialect" aria-label="Permalink to &quot;CUDA Tile IR Dialect {#CUDA-Tile-IR-Dialect}&quot;">​</a></h1><p>Refer to the <a href="https://docs.nvidia.com/cuda/tile-ir/latest/" target="_blank" rel="noreferrer">official documentation</a> for more details.</p><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.absf-Tuple{Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.absf-Tuple{Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.absf</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>absf</code></p><p>The :code:<code>absf</code> operation computes the element-wise absolute value of the input float tile.</p><p>.. math:: \text{absf}(x)_i = |x|_i</p><p>:suffix: Element-wise floating-point arithmetic operations are performed by the target architecture&#39;s native floating-point instructions. If the :code:<code>rounding</code> modifier is specified, the particular rounding mode will be applied to each element of the result. See :ref:<code>op-group-floating-point</code> for more details.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L16-L25" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.absi-Tuple{Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.absi-Tuple{Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.absi</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>absi</code></p><p>The :code:<code>absi</code> operation computes the absolute value of the input integer tile.</p><p>The input tile is always interpreted as a signed integer. The output tile is always interpreted as an unsigned integer.</p><p>.. math:: \text{absi}(x) = |x|</p><p>:suffix: Element-wise integer arithmetic operations are performed by the target architecture&#39;s native integer instructions. The default semantics are wrap-around semantics on overflow or underflow. See :ref:<code>op-group-integer</code> for more details.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L46-L58" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.addf-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.addf-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.addf</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>addf</code></p><p>The :code:<code>addf</code> operation computes the element-wise addition of two tiles with floating-point element type.</p><p>.. math:: \text{addf}(x, y)_i = x_i + y_i</p><p>The addition of individual elements is performed by the target architecture&#39;s native floating-point addition for the given element type unless otherwise specified.</p><p>:suffix: Element-wise floating-point arithmetic operations are performed by the target architecture&#39;s native floating-point instructions. If the :code:<code>rounding</code> modifier is specified, the particular rounding mode will be applied to each element of the result. See :ref:<code>op-group-floating-point</code> for more details.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L79-L91" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.addi-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.addi-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.addi</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>addi</code></p><p>The :code:<code>addi</code> operation computes the element-wise addition of two tiles with integer element types.</p><p>.. math:: \text{addi}(x, y)_i = x_i + y_i</p><p>:suffix: Element-wise integer arithmetic operations are performed by the target architecture&#39;s native integer instructions. The default semantics are wrap-around semantics on overflow or underflow. See :ref:<code>op-group-integer</code> for more details.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L121-L130" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.andi-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.andi-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.andi</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>andi</code></p><p>The :code:<code>andi</code> operation produces a value that is the result of an element-wise, bitwise &quot;and&quot; of two tiles with integer element type.</p><p>:suffix: Element-wise integer arithmetic operations are performed by the target architecture&#39;s native integer instructions. The default semantics are wrap-around semantics on overflow or underflow. See :ref:<code>op-group-integer</code> for more details.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L158-L166" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.assert-Tuple{Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.assert-Tuple{Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.assert</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>assert</code></p><p>The :code:<code>assert</code> operation takes as :code:<code>condition</code> a tile of :code:<code>i1</code> values. For each value that is :code:<code>0</code>, it prints the given error message, along with the index of the value within the tile.</p><p>If at least one value is :code:<code>0</code>, an error is signalled to the host side. The kernel, including the tile block that failed the assertion, may keep running.</p><p>Assertions are for debugging purposes. They can affect performance and it is therefore recommended to remove them in production code.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L189-L202" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.assume-Tuple{Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.assume-Tuple{Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.assume</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>assume</code></p><p>The :code:<code>assume</code> operation passes through :code<code>value</code> as the result and attaches a predicate to it. The assumed predicate is a property of :code:<code>result</code>.</p><p>This operation can be used to inject static information into the compiler, potentially resulting in more efficient code generation.</p><p>:code:<code>predicate</code> must implement the :code:<code>AssumePredicateAttrInterface</code>.</p><p>.. note::</p><p>:code:<code>assume</code> does not check the correctness of the predicate. Incorrect predicates may inject incorrect static information and cause miscompilation. If an incorrect predicate is attached to an SSA value, the behavior of the program is undefined.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L222-L240" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.atomic_cas_tko" href="#Reactant.MLIR.Dialects.cuda_tile.atomic_cas_tko"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.atomic_cas_tko</span></a> <span class="VPBadge info jlObjectType jlFunction"><!--[-->Function<!--]--></span></summary><p><code>atomic_cas_tko</code></p><p>The :code:<code>atomic_cas</code> operation performs element-wise, atomic compare-and-swaps at the specified global memory :code:<code>pointers</code>. The data in memory is compared to :code:<code>cmp</code> and the data written to memory is specified by :code:<code>val</code>. The operation returns the original value that was stored in memory before the atomic operation was performed.</p><p>The shape (and the element type) of :code:<code>pointers</code>, :code:<code>cmp</code>, :code:<code>val</code> and :code:<code>result</code> must match. The :code:<code>atomic_cas</code> operation performs the following steps for every :code:<code>(pointer, cmp, val)</code> tuple in one atomic transaction. (One atomic transaction per tuple.)</p><p>.. code-block:: mlir</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>atomic() {</span></span>
<span class="line"><span>  x = *pointer</span></span>
<span class="line"><span>  if x == cmp {</span></span>
<span class="line"><span>  *pointer = val</span></span>
<span class="line"><span>}</span></span>
<span class="line"><span>return x</span></span></code></pre></div><p>}</p><p>An optional parameter, :code:<code>mask</code>, allows specifying which elements participate in the atomic operation. A false value at position i masks out the corresponding element in :code:<code>pointers</code>, excluding it from the operation. The returned value for a masked element at position i is :code:<code>cmp[i]</code>. If no mask is provided, all elements are included in the computation by default. The shape of mask must match that of pointers, cmp, and val.</p><p>A token-ordered atomic compare-and-swap is not constrained by program order. The compiler may reorder it (i.e. place them earlier or later in program order) unless constrained by tokens.</p><p>Supported data types:</p><ul><li><p>i32, i64: integer values</p></li><li><p>f32, f64: floating-point values</p></li></ul><p>For floating-point types, the comparison uses bitwise equality rather than IEEE-754 semantics. This means different :code:<code>NaN</code> bit patterns are treated as distinct values, and :code:<code>+0.0</code> and :code:<code>-0.0</code> are considered different if their bit representations differ.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L263-L306" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.atomic_rmw_tko" href="#Reactant.MLIR.Dialects.cuda_tile.atomic_rmw_tko"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.atomic_rmw_tko</span></a> <span class="VPBadge info jlObjectType jlFunction"><!--[-->Function<!--]--></span></summary><p><code>atomic_rmw_tko</code></p><p>The :code:<code>atomic_rmw_tko</code> operation performs element-wise, atomic read-modify-write operations at the global memory locations specified by :code:<code>pointers</code>. The values written to memory are determined by :code:<code>mode</code> and :code:<code>arg</code>. The operation returns the original value stored at each location before the atomic update.</p><p>The shapes of :code:<code>pointers</code>, :code:<code>arg</code>, and :code:<code>result</code> must match. The element type of the pointer type must match the element types of both :code:<code>arg</code> and :code:<code>result</code>. Each (pointer, arg) pair is processed in a single atomic transaction.</p><p>.. code-block:: mlir</p><p x="">atomic</p><p>An optional parameter, :code:<code>mask</code>, specifies which elements participate in the atomic operation. A <code>False</code> value at position :code:<code>i</code> excludes the corresponding element in :code:<code>pointers</code> from the operation. The value returned for a masked-out element is implementation-defined. The shape of :code:<code>mask</code> must match the shape of :code:<code>pointers</code>.</p><p>The :code:<code>atomic_addf</code> operation is defined to round to the nearest even value. .. note:: The current implementation of the compiler flushes denormals to zero. This behavior will be fixed in a future version of the compiler and users should not rely on it.</p><p>Token-ordered atomic read-modify-write operations are not constrained by program order. The compiler may reorder them (i.e., move them earlier or later in the program) unless further constrained by tokens.</p><p>Supported data types by :code:<code>mode</code>:</p><ul><li><p>ADD, AND, MAX, MIN, OR, UMAX, UMIN, XOR: i32, i64</p></li><li><p>ADDF: f16, f32, f64</p></li><li><p>XCHF: i32, i64, f32, f64</p></li></ul><p>The :code:<code>U</code> prefix in UMAX and UMIN distinguishes these from their signed counterparts (MAX and MIN) by interpreting the comparison as unsigned.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L348-L395" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.bitcast-Tuple{Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.bitcast-Tuple{Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.bitcast</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>bitcast</code></p><p>The :code:<code>bitcast</code> operation casts the input tile from one element type to another without modifying the underlying bits.</p><p>Only non-pointer types of the same bit width are allowed (e.g., :code:<code>i32</code> to :code:<code>f32</code>). Pointer types must use :ref:<code>op-cuda_tile.ptr_to_int</code> or :ref:<code>op-cuda_tile.int_to_ptr</code> instead.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L438-L446" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.break_-Tuple{Vector{Reactant.MLIR.IR.Value}}" href="#Reactant.MLIR.Dialects.cuda_tile.break_-Tuple{Vector{Reactant.MLIR.IR.Value}}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.break_</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>break_</code></p><p>The :code:<code>break</code> operation is a terminator operation of a :ref:<code>op-cuda_tile.loop</code>.</p><p>It may yield any number of :code:<code>$operands</code> to the parent loop upon termination. The number of values yielded and the execution semantics of how they are yielded are determined by the parent loop.</p><p>The :code:<code>break</code> operation always returns control to the innermost enclosing loop operation, even when it is nested within other control constructs such as :code:<code>if</code> or additional loops.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L466-L476" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.broadcast-Tuple{Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.broadcast-Tuple{Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.broadcast</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>broadcast</code></p><p>The :code:<code>broadcast</code> operation expands each unary (:code:<code>1</code>) dimension in the input tile by duplicating the data along that dimension.</p><p>Expansion happens only for dimensions of size one that are stretched or &quot;copied&quot; to match the size of the dimension implied by the result type of the operation. The operation does not change the rank of the source tile. Any change to the rank of the source tile must be made using reshape-like operations before broadcasting.</p><p>.. .. math:: .. broadcast(x, idim_n, odim_n) = x</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L496-L509" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.cat-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.cat-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.cat</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>cat</code></p><p>The :code:<code>cat</code> operation concatenates the two input tiles. The input tiles must have the same shape in all but the concatenating dimension. Concatenation happens along the dimension specified by the the attribute :code:<code>dim</code> the resulting dimension is the sum of the the two input tiles concatenating dimension.</p><p>.. math::</p><p cases="">\text{cat}(x, y, dim_{cat})[ \vec{i} ] = \begin{cases} x[..., i_{cat}, ..., i_n] &amp; \text{if } i_{cat} &lt; d_{cat} <br> y[..., i_{cat} - d_{cat}, ..., i_n] &amp; \text{if } i_{cat} \geq d_{cat} \end</p><p>.. \text{where } X \text{ has type tile}&lt;d_0 \times d_1 \times \cdots \times d_n&gt; .. \text{ and } Y \text{ has type tile}&lt;d_0 \times d_1 \times \cdots \times d_n&gt;</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L529-L547" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.ceil-Tuple{Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.ceil-Tuple{Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.ceil</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>ceil</code></p><p>The :code:<code>ceil</code> operation computes the element-wise ceiling on the input floating-point tile. The ceiling operation rounds each element up to the largest integer value that is greater than or equal to the input value.</p><p>.. math::</p><p>\text{ceil}(x)_i = \min{n \in \mathbb{Z} \mid n \geq x_i}</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L567-L578" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.cmpf-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.cmpf-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.cmpf</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>cmpf</code></p><p>The :code:<code>cmpf</code> operation is a generic comparison for float-like types. The operands must have the same shape and type, and this type must be a float type.</p><p>The result is :code:<code>1</code> if the comparison is true and :code:<code>0</code> otherwise. The comparison is performed element-wise and the element of the result indicates whether the comparison is true for the operand elements with the same indices as those of the result.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L599-L609" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.cmpi-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.cmpi-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.cmpi</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>cmpi</code></p><p>The :code:<code>cmpi</code> operation is a generic comparison for integer-like types. The operands must have the same shape and type, and this type must be an integer type. The result type has i1 element type and the same shape as the operands.</p><p>The result is :code:<code>1</code> if the comparison is true and :code:<code>0</code> otherwise. The comparison is performed element-wise and the element of the result indicates whether the comparison is true for the operand elements with the same indices as those of the result.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L640-L651" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.constant-Tuple{}" href="#Reactant.MLIR.Dialects.cuda_tile.constant-Tuple{}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.constant</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>constant</code></p><p>The :code:<code>constant</code> operation creates a tile initialized by :code:<code>$value</code>.</p><p>There are two main forms of using the operation:</p><ul><li><p>One where the value is a single constant specified by :code:<code>dense&lt;c&gt;</code> and the tile is filled with identical values for all elements.</p></li><li><p>One where the value is a list of constants specified by :code:<code>dense&lt;[c0, c1, c2, ...]&gt;</code> and the constant value&#39;s shape must match the tile&#39;s shape.</p></li></ul><p>The annotated type of the tile constrains its rank, shape, and element type.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L682-L696" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.continue_-Tuple{Vector{Reactant.MLIR.IR.Value}}" href="#Reactant.MLIR.Dialects.cuda_tile.continue_-Tuple{Vector{Reactant.MLIR.IR.Value}}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.continue_</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>continue_</code></p><p>The :code:<code>continue</code> operation represents a block terminator that returns control to a loop operation, such as :ref:<code>op-cuda_tile.for</code> and :ref:<code>op-cuda_tile.loop</code>. The operation may yield any number of :code:<code>$operands</code> to the parent loop upon termination.</p><p>The requirements and semantics of the :code:<code>continue</code> operation are defined by the parent loop operation, see the loop operation&#39;s description for particular semantics.</p><p>The :code:<code>continue</code> operation always returns control to the innermost enclosing loop operation, even when it is nested within other control constructs such as :code:<code>if</code> or additional loops.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L717-L729" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.cos-Tuple{Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.cos-Tuple{Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.cos</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>cos</code></p><p>The :code:<code>cos</code> operation computes the element-wise cosine of the input floating-point tile.</p><p>.. math::</p><p>\text{cos}(x)_i = \cos(x_i)</p><p>:suffix: This operation is emulated in :code:<code>f32</code> when executed on half-precision inputs (:code:<code>f16</code> and :code:<code>bf16</code>). See :ref:<code>op-group-floating-point</code> for more details.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L782-L793" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.cosh-Tuple{Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.cosh-Tuple{Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.cosh</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>cosh</code></p><p>The :code:<code>cosh</code> operation computes the element-wise hyperbolic cosine of the input tile with floating-point element type.</p><p>.. math::</p><p>\text{cosh}(x)_i = {\cosh x}_i</p><p>:suffix: This operation is emulated in :code:<code>f32</code> when executed on half-precision inputs (:code:<code>f16</code> and :code:<code>bf16</code>). See :ref:<code>op-group-floating-point</code> for more details.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L749-L761" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.divf-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.divf-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.divf</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>divf</code></p><p>The :code:<code>divf</code> operation computes the element-wise division of two input tiles with floating-point element types.</p><p>The :code:<code>approx</code> rounding mode implements a fast approximation of divide, computed as a multiplication by reciprocal. For :code:<code>|rhs|</code> in normalized range :code:<code>[2^(-126), 2^(126)]</code> the maximum ULP (Unit in the Last Place) error is :code:<code>2</code>. For :code:<code>2^(126) &lt; |rhs| &lt; 2^(128)</code>, if :code:<code>lhs</code> is infinity the operation returns :code:<code>NaN</code>, otherwise :code:<code>0</code>.</p><p>The :code:<code>full</code> rounding mode implements a relatively fast, full-range approximation that scales operands to achieve better accuracy, but is not fully IEEE 754 compliant. The maximum ulp error is 2 across the full range of inputs.</p><p>.. math:: \text{div(lhs, rhs)}_i = \text{lhs}_i / \text{rhs}_i</p><p>:suffix: Element-wise floating-point arithmetic operations are performed by the target architecture&#39;s native floating-point instructions. If the :code:<code>rounding</code> modifier is specified, the particular rounding mode will be applied to each element of the result. See :ref:<code>op-group-floating-point</code> for more details.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L814-L834" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.divi-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.divi-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.divi</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>divi</code></p><p>The :code:<code>divi</code> operation computes the element-wise division of two tile values with integer element type.</p><p>The default rounding is towards zero. The rounding mode can be set to <code>positive_inf</code> (&quot;ceil div&quot;), or <code>negative_inf</code> (&quot;floor div&quot;), other values are illegal.</p><p>The use of the rounding flag <code>negative_inf</code> with <code>unsigned</code> is not a valid combination.</p><p>If the <code>unsigned</code> flag is provided, the operands are treated as unsigned integers, otherwise they are treated as signed integers.</p><p>The behavior is undefined if the right hand side is zero. A signed division overflow (minimum value divided by -1) is undefined behavior.</p><p>.. math:: \text{div(lhs, rhs)}_i = \text{lhs}_i / \text{rhs}_i</p><p>:suffix: Element-wise integer arithmetic operations are performed by the target architecture&#39;s native integer instructions. The default semantics are wrap-around semantics on overflow or underflow. See :ref:<code>op-group-integer</code> for more details.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L864-L884" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.entry-Tuple{}" href="#Reactant.MLIR.Dialects.cuda_tile.entry-Tuple{}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.entry</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>entry</code></p><p>The :code:<code>entry</code> operation defines a tile kernel; a kernel is a function that can serve as the program entry point. It has a unique name per-module. A kernel can not return any value. It must be launched from the host side using :code:<code>cuLaunchKernel</code> or similar CUDA runtime API functions.</p><p>Tile kernels require that the user specifies the 3-d grid dimensions at launch which defines the number of tile blocks (or kernel instances) that will execute the kernel in parallel.</p><p>For detailed semantics of tile kernels see :ref:<code>sub_sec_tile_kernel</code>.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L913-L926" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.exp-Tuple{Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.exp-Tuple{Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.exp</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>exp</code></p><p>The :code:<code>exp</code> operation computes the element-wise exponential of the input floating-point tile.</p><p>.. math::</p><p x_i="">\text{exp}(x)_i = e^</p><p>:suffix: This operation is emulated in :code:<code>f32</code> when executed on half-precision inputs (:code:<code>f16</code> and :code:<code>bf16</code>). See :ref:<code>op-group-floating-point</code> for more details.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L999-L1011" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.exp2-Tuple{Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.exp2-Tuple{Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.exp2</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>exp2</code></p><p>The :code:<code>exp2</code> operation computes the element-wise power of two of the input floating-point tile.</p><p>.. math::</p><p x_i="">\text{exp2}(x)_i = 2^</p><p>:suffix: This operation is emulated in :code:<code>f32</code> when executed on half-precision inputs (:code:<code>f16</code> and :code:<code>bf16</code>). See :ref:<code>op-group-floating-point</code> for more details.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L960-L971" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.exti-Tuple{Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.exti-Tuple{Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.exti</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>exti</code></p><p>The :code:<code>exti</code> operation converts a tile of integers of a given width to a strictly larger width. Zero-extension is used for :code:<code>unsigned</code> integers and sign-extension is used for :code:<code>signed</code> integers.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L1032-L1039" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.extract-Tuple{Reactant.MLIR.IR.Value, Vector{Reactant.MLIR.IR.Value}}" href="#Reactant.MLIR.Dialects.cuda_tile.extract-Tuple{Reactant.MLIR.IR.Value, Vector{Reactant.MLIR.IR.Value}}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.extract</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>extract</code></p><p>The :code:<code>extract</code> operation extracts a subtile from the given source tile.</p><p>The shape of the result tile must divide the shape of the source tile evenly e.g., :code:<code>tile&lt;4xf32&gt;</code> is a valid extraction from :code:<code>tile&lt;8xf32&gt;</code>, but :code:<code>tile&lt;3xf32&gt;</code> is not.</p><p>The :code:<code>$indices</code> indicate the number of the slice to extract, but <em>importantly</em> not the offsets used to construct the subtile for extraction. The semantics of extract means that only full size slices can be extracted.</p><p>Slices of a source tile with the same shape are non-overlapping by definition for unique indices.</p><p>.. warning::</p><p>If the :code:<code>indices</code> specify a non-existent (i.e., out-of-bounds) slice, the behavior of the operation is undefined.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L1059-L1079" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.floor-Tuple{Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.floor-Tuple{Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.floor</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>floor</code></p><p>The :code:<code>floor</code> operation computes the element-wise floor on the input floating-point tile rounding each element down to the largest integer that is less than or equal to the element.</p><p>.. math:: \text{floor}_i(x_i) = \max{n \in \mathbb{Z} \mid n \leq x_i}</p><p>:suffix: Element-wise floating-point arithmetic operations are performed by the target architecture&#39;s native floating-point instructions. If the :code:<code>rounding</code> modifier is specified, the particular rounding mode will be applied to each element of the result. See :ref:<code>op-group-floating-point</code> for more details.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L1168-L1178" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.fma-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.fma-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.fma</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>fma</code></p><p>Takes three operands :code:<code>lhs</code>, :code:<code>rhs</code> and :code:<code>acc</code>, returns :code:<code>result = lhs * rhs + acc</code>.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L1199-L1203" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.for_-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value, Vector{Reactant.MLIR.IR.Value}}" href="#Reactant.MLIR.Dialects.cuda_tile.for_-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value, Vector{Reactant.MLIR.IR.Value}}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.for_</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>for_</code></p><p>The :code:<code>for</code> operation is a structured range-based sequential loop.</p><p>The loop operation consists of (1) a range formed by :code:<code>lowerBound</code>, :code:<code>upperBound</code>, and :code:<code>step</code>, (2) a set of loop-carried values which are initialized by :code:<code>initValues</code> and updated by each iteration of the loop, and (3) a region which represents the loop body.</p><p>The iteration space is defined by the interval :math:<code>[lowerBound, upperBound)</code> with each value seperated by :code:<code>step</code>.</p><p>.. math::</p><p>range(L_b, U_b, S) = { L_b + i \cdot S \mid i \in \mathbb{Z}, L_b + i \cdot S &lt; U_b }</p><p>:code:<code>lowerBound</code>, :code:<code>upperBound</code>, and :code:<code>step</code> must be of the same type. :code:<code>lowerBound</code> and :code:<code>upperBound</code> specify a half-open (or exclusive) range: the range includes the :code:<code>lowerBound</code> but does not include the :code:<code>upperBound</code>. :code:<code>step</code> must be positive but the bounds may be negative or zero.</p><p>The first iteration of the loop receives the induction variable initialized to the value of :code:<code>lowerBound</code> and the loop-carried values initialized to the values of :code:<code>initValues</code>.</p><p>The loop body is executed for each value in the range, receiving an integer induction variable incremented by :code:<code>step</code> on each iteration and the loop-carried values which correspond to the loop-carried values yielded by the previous loop iteration.</p><p>The loop terminates when the induction variable is greater than or equal to :code:<code>upperBound</code>. By default, signed comparison is used between the upperBound and the induction variable. To use unsigned comparison instead, specify the optional :code:<code>unsigned</code> unit attribute.</p><p>The body of the loop must be terminated by a :ref:<code>op-cuda_tile.continue</code> that yields the next iteration&#39;s value for each loop carried variable.</p><p>The for operation produces one return value for each loop carried variable. The type of the :math:<code>i</code>-th return value is that of the :math:<code>i</code>-th loop carried variable and its value is the final value of the :math:<code>i</code>-th loop carried variable.</p><p>.. warning::</p><ul><li><p>Loop carried variables can not be a :tileirty:<code>tensor_view</code> or view type.</p></li><li><p>:code:<code>for</code> operations cannot terminate early and must end in a :ref:<code>op-cuda_tile.continue</code>.</p></li></ul><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L1234-L1278" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.ftof-Tuple{Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.ftof-Tuple{Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.ftof</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>ftof</code></p><p>The :code:<code>ftof</code> operation converts a tile of a given floating-point element type into one of a different floating-point element type (for example, from :code:<code>f32</code> to :code:<code>f64</code>).</p><p>The source type and the result type must be different.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L1101-L1108" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.ftoi-Tuple{Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.ftoi-Tuple{Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.ftoi</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>ftoi</code></p><p>The :code:<code>ftoi</code> operation converts a floating-point tile into an integer tile.</p><p>In contrast to a :code:<code>bitcast</code> which is bits preserving, this preserves the numerical value of the tile, rounded towards zero to the nearest integer of the provided type.</p><p>.. warning::</p><p>If the input floating-point value, after being rounded, is outside the (signed or unsigned) range of the target integer type, the closest representable value is used instead. :code:<code>NaN</code> values are converted to 0. Input :code:<code>Inf</code> values are undefined behavior.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L1130-L1145" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.get_global-Tuple{}" href="#Reactant.MLIR.Dialects.cuda_tile.get_global-Tuple{}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.get_global</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>get_global</code></p><p>The :code:<code>get_global</code> operation returns a pointer to the specified :code:<code>global</code> variable. A global variable is a form of static global memory allocation that can be declared using the :ref:<code>op-cuda_tile.global</code> operation.</p><p>The element type of the returned pointer will be of the same type as the element type of the declared global variable.</p><p>For detailed semantics of global variables see :ref:<code>sub_sec_tile_global</code>.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L1306-L1317" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.get_index_space_shape-Tuple{Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.get_index_space_shape-Tuple{Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.get_index_space_shape</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>get_index_space_shape</code></p><p>The :code:<code>get_index_space_shape</code> operation returns the shape of the index space of :code:<code>src</code>.</p><p>The result types must be the same as the view&#39;s index type, and the number of results must be the same as the view&#39;s index rank.</p><p>If the index space shape sizes do not fit within the provided type, behavior is undefined.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L1337-L1348" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.get_num_tile_blocks-Tuple{}" href="#Reactant.MLIR.Dialects.cuda_tile.get_num_tile_blocks-Tuple{}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.get_num_tile_blocks</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>get_num_tile_blocks</code></p><p>The :code:<code>get_num_tile_blocks</code> operation queries the total number of tile blocks in the form of a 3-tuple specifying the extent of each grid dimension.</p><p>A tile :code:<code>id</code> is a coordinate in 3-space and therefore the must also be a 3-tuple containing the extent of each dimension: :code:<code>x</code>, :code:<code>y</code> and :code:<code>z</code>.</p><p>When launching 1- or 2-dimensional grids, the unspecified dimensions will have a cardinality of 1.</p><p>For example if the grid used to launch the kernel is :code:<code>(1024, 1024)</code> then the result of this operation will be :code:<code>(1024, 1024, 1)</code>.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L1368-L1381" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.get_tensor_shape-Tuple{Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.get_tensor_shape-Tuple{Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.get_tensor_shape</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>get_tensor_shape</code></p><p>The :code:<code>get_tensor_shape</code> operation returns the shape of the tensor backing the provided :code:<code>tensor_view</code>.</p><p>If the tensor shape sizes do not fit within the provided type, behavior is undefined.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L1409-L1417" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.get_tile_block_id-Tuple{}" href="#Reactant.MLIR.Dialects.cuda_tile.get_tile_block_id-Tuple{}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.get_tile_block_id</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>get_tile_block_id</code></p><p>:code:<code>get_tile_block_id</code> returns a 3-d tile block coordinates (or ID) of the currently executing tile block.</p><p>A tile ID has three dimensions: :code:<code>x</code>, :code:<code>y</code>, and :code:<code>z</code>. This operation returns all three of them simultaneously. The value of each dimension returned by this operation is between :code:<code>0</code> (including) and the value returned by :code:<code>get_num_tile_blocks</code> for the respective axis (excluding), represented by the inclusive interval :code:<code>[0, get_num_tile_blocks(dim) - 1]</code> . Grid dimensions unspecified at kernel launch (i.e., a 1-d or 2-d grid) will always be :code:<code>0</code> for all tile blocks.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L1437-L1449" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.global_-Tuple{}" href="#Reactant.MLIR.Dialects.cuda_tile.global_-Tuple{}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.global_</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>global_</code></p><p>The :code:<code>global</code> operation statically allocates a mutable 1-dimensional location in global memory and initializes it using :code:<code>value</code>. The initialization of the allocation is performed at <code>CUDA module &lt;https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__TYPES.html#group__CUDA__TYPES_1g9e4ef4dcfba4662b2299acb8d049a1ef&gt;</code>_ load time. The lifetime of the allocation is the same as the lifetime of the module.</p><p>The allocation may be read or written to by first using :ref:<code>op-cuda_tile.get_global</code> to obtain a pointer to the the memory and then read using :ref:<code>op-cuda_tile.load_ptr_tko</code> or written to using :ref:<code>op-cuda_tile.store_ptr_tko</code>.</p><p>The initial values are stored in memory in linear order, so the pointer returned by :ref:<code>op-cuda_tile.get_global</code> points to the first element, and offsetting the pointer by <code>x</code> would allow to load element at position <code>x</code>.</p><p>:code:<code>global</code> operations must be directly nested within the |cuda_tile| module. They cannot be defined inside functions. As globals are defined at the module scope their names are globally unique symbols and must not collide with any other symbol in the module.</p><p>For more detailed semantics of global variables see :ref:<code>sub_sec_tile_global</code>.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L1477-L1496" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.if_-Tuple{Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.if_-Tuple{Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.if_</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>if_</code></p><p>The :code:<code>if</code> operation represents an if-then-else construct.</p><p>The <code>if</code> operation consists of (1) a control operand which is a :code:<code>tile&lt;i1&gt;</code> value, (2) a true branch :code:<code>thenRegion</code> and (3) an optional false branch :code:<code>elseRegion</code>.</p><p>The :code:<code>if</code> operation may produce results by yielding values in each branch using :ref:<code>op-cuda_tile.yield</code>.</p><p>If yielding value(s) the types of yielded values must match and the result result type of the :code:<code>if</code> operation will be the same as the yielded values.</p><p>If yielding values the else branch is required and must also yield a value.</p><p>The values returned will be dependent on which branch is taken.</p><p>.. warning::</p><p>The :code:<code>if</code> operation has a set of additional restrictions today:</p><ul><li>Results of :code:<code>if</code> must not be a :tileirty:<code>tensor_view</code> or view type.</li></ul><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L1554-L1576" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.int_to_ptr-Tuple{Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.int_to_ptr-Tuple{Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.int_to_ptr</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>int_to_ptr</code></p><p>The :code:<code>int_to_ptr</code> operation converts a tile of integers to a tile of pointers.</p><p>The inverse of this operation is :ref:<code>op-cuda_tile.ptr_to_int</code>.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L1602-L1608" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.iota-Tuple{}" href="#Reactant.MLIR.Dialects.cuda_tile.iota-Tuple{}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.iota</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>iota</code></p><p>The :code:<code>iota</code> operation generates a 1-d tile with a sequence of integer values. The starting value is :code:<code>0</code> and the stride is :code:<code>1</code>. If the shape of the result tile is :code:<code>(n)</code>, then the generated values are :code:<code>[0, n - 1]</code>.</p><p>.. note::</p><p>The number of elements in the result tile must not exceed the maximum value that the element type can express.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L1628-L1639" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.itof-Tuple{Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.itof-Tuple{Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.itof</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>itof</code></p><p>The :code:<code>itof</code> operation converts an integer tile into a float tile. In contrast to a bitcast, this preserves the numerical value of the tile, rounded to the nearest floating-point number of the provided type.</p><p>.. warning::</p><p>If the input integer value, after being rounded, is outside the range of the target floating-point type, it is converted to :code:<code>Inf</code> for types that support that value, and :code:<code>NaN</code> otherwise.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L1519-L1531" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.join_tokens-Tuple{Vector{Reactant.MLIR.IR.Value}}" href="#Reactant.MLIR.Dialects.cuda_tile.join_tokens-Tuple{Vector{Reactant.MLIR.IR.Value}}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.join_tokens</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>join_tokens</code></p><p>The :code:<code>join_tokens</code> operation produces a fresh token which depends on all input tokens. Token-ordered operations which consume the new token will then be ordered with respect to all joined tokens.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L1659-L1665" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.load_ptr_tko" href="#Reactant.MLIR.Dialects.cuda_tile.load_ptr_tko"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.load_ptr_tko</span></a> <span class="VPBadge info jlObjectType jlFunction"><!--[-->Function<!--]--></span></summary><p><code>load_ptr_tko</code></p><p>This :code:<code>load</code> OP performs a gather operation by loading a tile of data from global memory into a result tile based on a tile of pointers provided by the :code:<code>source</code> operand.</p><p>The :code:<code>source</code> operand is a tile of pointers, which specifies the memory locations from which the data is gathered. The operation loads this data and returns it as the :code:<code>result</code> tile. When loading i1 values, each value is loaded from a full byte in memory. Any nonzero byte is canonicalized to 0x01, and zero bytes become 0x00.</p><p>Optionally, a :code:<code>mask</code> operand can be provided to control the gathering of elements. If present, only the elements specified by the :code:<code>mask</code> are loaded. The shape of the :code:<code>mask</code> must match the shape of the :code:<code>result</code>.</p><p>When :code:<code>mask</code> is present one :code:<code>paddingValue</code> can be optionally present as well. The :code:<code>paddingValue</code> must have the same shape of the :code:<code>source</code> tile. If it is not present, the value of masked elements are undefined.</p><p>Token-ordered operations are not constrained by program order. The compiler may reorder them (i.e. place them earlier or later in program order) unless further constrained by tokens.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L1688-L1712" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.load_view_tko" href="#Reactant.MLIR.Dialects.cuda_tile.load_view_tko"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.load_view_tko</span></a> <span class="VPBadge info jlObjectType jlFunction"><!--[-->Function<!--]--></span></summary><p><code>load_view_tko</code></p><p>The :code:<code>load_view_tko</code> operation loads a tile from a tile view.</p><p>A view is mapping from view-space indices to a particular element in the view, each view type has a defined mapping from view-space indices to tiles produced from elements of the view.</p><p>For example, the :ref:<code>type-partition_view</code> partitions a :ref:<code>type-tensor_view</code> into a grid of equally sized tiles. The view indices one of the partitioned tiles in the grid.</p><p>For a given view the rank of the indices must match the rank of the view&#39;s index space. The space of valid indices depends on which view is passed to the operation. For example the index space of a :ref:<code>type-partition_view</code> is equal to the rank of the partitioned tiles.</p><p>Out of bounds accesses are handling according to the semantics of the tile view.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L1758-L1776" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.log-Tuple{Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.log-Tuple{Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.log</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>log</code></p><p>The :code:<code>log</code> operation computes the element-wise natural logarithm of a floating-point tile.</p><p>.. math::</p><p>\text{log}(x)_i = \ln(x_i)</p><p>:suffix: This operation is emulated in :code:<code>f32</code> when executed on half-precision inputs (:code:<code>f16</code> and :code:<code>bf16</code>). See :ref:<code>op-group-floating-point</code> for more details.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L1846-L1857" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.log2-Tuple{Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.log2-Tuple{Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.log2</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>log2</code></p><p>The :code:<code>log2</code> operation computes the element-wise base-2 logarithm of a floating-point tile.</p><p>.. math::</p><p>\text{log2}(x)_i = \log_2(x_i)</p><p>:suffix: This operation is emulated in :code:<code>f32</code> when executed on half-precision inputs (:code:<code>f16</code> and :code:<code>bf16</code>). See :ref:<code>op-group-floating-point</code> for more details.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L1814-L1825" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.loop-Tuple{Vector{Reactant.MLIR.IR.Value}}" href="#Reactant.MLIR.Dialects.cuda_tile.loop-Tuple{Vector{Reactant.MLIR.IR.Value}}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.loop</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>loop</code></p><p>The :code:<code>loop</code> operation represents an, unstructured, infinite loop that executes until a :ref:<code>op-cuda_tile.break</code> is reached.</p><p>The loop consists of a (1) a set of loop-carried values which are initialized by :code:<code>initValues</code> and updated by each iteration of the loop, and (2) a region which represents the loop body.</p><p>The loop will execute the body of the loop until a :ref:<code>op-cuda_tile.break</code> is dynamically executed.</p><p>Each control path of the loop must be terminated by:</p><ul><li><p>a :ref:<code>op-cuda_tile.continue</code> that yields the next iteration&#39;s value for each loop carried variable.</p></li><li><p>a :ref:<code>op-cuda_tile.break</code> that terminates the loop and yields the final loop carried values.</p></li></ul><p>As long as each loop iteration is terminated by one of these operations they may be combined with other control flow operations to express different control flow patterns.</p><p>The loop operation produces one return value for each loop carried variable. The type of the :math:<code>i</code>-th return value is that of the :math:<code>i</code>-th loop carried variable and its value is the final value of the :math:<code>i</code>-th loop carried variable.</p><p>.. warning::</p><p>Loop operations have a set of additional restrictions today:</p><ul><li><p>Early returns from inside loops are not supported, a code generator must first terminate the loop and then return if they wish to end the function execution entirely.</p></li><li><p>Loop carried variables can not be a :tileirty:<code>tensor_view</code> or view type.</p></li></ul><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L1878-L1908" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.make_partition_view-Tuple{Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.make_partition_view-Tuple{Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.make_partition_view</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>make_partition_view</code></p><p>The :code:<code>make_partition_view</code> operation creates a :tileirty:<code>partition_view</code> from a :tileirty:<code>tensor_view</code>. For more details about partition views see :ref:<code>type-partition_view</code>.</p><p>The operation uses the type constraints of the input tensor view and the annotated return type to perform the partitioning. The tensor view&#39;s type contains its physical layout in the form of shapes and strides and the partition view containts the logical size of a single tile.</p><p>The resulting partition view can be loaded from using :ref:<code>op-cuda_tile.load_view_tko</code> and stored to using :ref:<code>op-cuda_tile.store_view_tko</code>.</p><p>The view memory options act on the computed index space of the partition view see :ref:<code>type-tensor_view</code> and :ref:<code>type-partition_view</code> for detailed semantics.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L1933-L1948" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.make_tensor_view-Tuple{Reactant.MLIR.IR.Value, Vector{Reactant.MLIR.IR.Value}, Vector{Reactant.MLIR.IR.Value}}" href="#Reactant.MLIR.Dialects.cuda_tile.make_tensor_view-Tuple{Reactant.MLIR.IR.Value, Vector{Reactant.MLIR.IR.Value}, Vector{Reactant.MLIR.IR.Value}}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.make_tensor_view</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>make_tensor_view</code></p><p>The :code:<code>make_tensor_view</code> operation constructs a :code:<code>tensor_view</code> from a global memory pointer, a dynamic shape and dynamic strides. See :ref:<code>type-tensor_view</code> for more details.</p><p>The constructor supports taking dynamic arrays for shapes and strides as part of the constructor enabling workloads to take global memory tensors of dynamic shape and strides. If these arguments are static they will be statically reflected in the type of the resulting :code:<code>tensor_view</code>, if they are dynamic they will appear as :code:<code>?</code> in the type. See below for concrete examples.</p><p>If shapes or strides are larger than the :code:<code>indexBitwidth</code> of the :code:<code>tensor_view</code>, behavior is undefined on the creation of the :code:<code>tensor_view</code>.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L1968-L1982" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.make_token-Tuple{}" href="#Reactant.MLIR.Dialects.cuda_tile.make_token-Tuple{}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.make_token</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>make_token</code></p><p>The :code:<code>make_token</code> operation creates a fresh token with no prior dependencies.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L2011-L2015" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.maxf-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.maxf-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.maxf</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>maxf</code></p><p>The :code:maxf` operation computes the element-wise maximum of two input tiles with floating-point element types.</p><p>The :code:<code>propagate_nan</code> controls how :code:<code>maxf</code> will interpret :code:<code>NaN</code>. If the :code:<code>propagate_nan</code> modifier is set, :code:<code>maxf</code> returns a canonical :code:<code>NaN</code> if either of the compared elements is :code:<code>NaN</code> (IEEE 754-2019&#39;s maximum). While if the :code:<code>propagate_nan</code> modifier is not set, :code:<code>maxf</code> returns a canonical :code:<code>NaN</code> only if both elements are :code:<code>NaN</code>; otherwise, it returns the non-:code:<code>NaN</code> element (IEEE 754-2019&#39;s maximumNumber).</p><p>If neither element is :code:<code>NaN</code>, :code:<code>maxf</code> will return the greater of the inputs. :code:<code>+0.0</code> is considered greater than :code:<code>-0.0</code>.</p><p>If the :code:<code>flush_to_zero</code> modifier is specified, denormal numbers are flushed to sign-preserving zero. The :code:<code>flush_to_zero</code> modifier applies only to the f32 data type.</p><p cases="">.. math:: \text{maxi}(x, y)_i = \begin{cases} x_i &amp; \text{if } x_i \geq y_i <br> y_i &amp; \text{if } x_i &lt; y_i \end</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L2036-L2061" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.maxi-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.maxi-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.maxi</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>maxi</code></p><p>The :code:<code>maxi</code> operation computes the element-wise maximum between two input integer tiles.</p><p cases="">.. math:: \text{maxi}(x, y)_i = \begin{cases} x_i &amp; \text{if } x_i \geq y_i <br> y_i &amp; \text{if } x_i &lt; y_i \end</p><p>:suffix: Element-wise integer arithmetic operations are performed by the target architecture&#39;s native integer instructions. The default semantics are wrap-around semantics on overflow or underflow. See :ref:<code>op-group-integer</code> for more details.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L2093-L2105" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.minf-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.minf-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.minf</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>minf</code></p><p>The :code:<code>minf</code> operation computes the element-wise minimum of two input tiles with floating-point element types.</p><p>The :code:<code>propagate_nan</code> controls how :code:<code>minf</code> will interpret :code:<code>NaN</code>. If the :code:<code>propagate_nan</code> modifier is set, :code:<code>minf</code> returns a canonical :code:<code>NaN</code> if either of the compared elements is :code:<code>NaN</code> (IEEE 754-2019&#39;s minimum). While if the :code:<code>propagate_nan</code> modifier is not set, :code:<code>minf</code> returns a canonical :code:<code>NaN</code> only if both elements are :code:<code>NaN</code>; otherwise, it returns the non-:code:<code>NaN</code> element (IEEE 754-2019&#39;s minimumNumber).</p><p>If neither element is :code:<code>NaN</code>, :code:<code>minf</code> will return the lowest of the inputs. :code:<code>-0.0</code> is considered less than :code:<code>+0.0</code>.</p><p>If the :code:<code>flush_to_zero</code> modifier is specified, denormal numbers are flushed to sign-preserving zero. The :code:<code>flush_to_zero</code> modifier applies only to the f32 data type.</p><p cases="">.. math:: \text{minf}(x, y)_i = \begin{cases} x_i &amp; \text{if } x_i \leq y_i <br> y_i &amp; \text{if } x_i &gt; y_i \end</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L2132-L2157" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.mini-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.mini-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.mini</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>mini</code></p><p>The :code:<code>mini</code> operation computes the element-wise minimum between the two input tiles with integer element types.</p><p cases="">.. math:: \text{mini}(x, y)_i = \begin{cases} x_i &amp; \text{if } x_i \leq y_i <br> y_i &amp; \text{if } x_i &gt; y_i \end</p><p>:suffix: Element-wise integer arithmetic operations are performed by the target architecture&#39;s native integer instructions. The default semantics are wrap-around semantics on overflow or underflow. See :ref:<code>op-group-integer</code> for more details.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L2189-L2202" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.mmaf-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.mmaf-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.mmaf</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>mmaf</code></p><p>The :code:<code>mmaf</code> operation implements an MMA (matrix-multiply-accumulate) operation for floating-point tiles. It performs matrix multiplication on the floating-point tiles :code:<code>lhs</code> and :code:<code>rhs</code>, then adds the tile :code:<code>acc</code> to the result. :code:<code>lhs</code>, :code:<code>rhs</code>, and :code:<code>acc</code> must be 2D tiles or 3D tiles. The latter case indicates a batched matrix multiplication.</p><p>The types of all operands must be a supported combination (see :ref:<code>table-cuda_tile.mmaf-0</code>).</p><p>Shapes must be a valid matrix multiplication configuration. Unbatched (2D) MMA expects the operands :code:<code>lhs</code>, :code:<code>rhs</code>, and :code:<code>acc</code> to have shapes :code:<code>M x K</code>, :code:<code>K x N</code>, and :code:<code>M x N</code> (respectively). Batched (3D) MMA expects the operands to have shapes :code:<code>B x M x K</code>, :code:<code>B x K x N</code>, and :code:<code>B x M x N</code> (respectively).</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L2229-L2243" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.mmai-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.mmai-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.mmai</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>mmai</code></p><p>The :code:<code>mmai</code> operation implements an MMA (matrix-multiply-accumulate) operation for integer tiles. It performs matrix multiplication on the integer tiles :code:<code>lhs</code> and :code:<code>rhs</code>, then adds the tile :code:<code>acc</code> to the result. :code:<code>lhs</code>, :code:<code>rhs</code>, and :code:<code>acc</code> must be 2D tiles or 3D tiles. The latter case indicates a batched matrix multiplication.</p><p>Input tiles :code:<code>lhs</code> and :code:<code>rhs</code> must be of integer type :code:<code>i8</code>. The signedness of :code:<code>lhs</code> and :code:<code>rhs</code> are specified separately by the :code:<code>signedness_lhs</code> and :code:<code>signedness_rhs</code> attributes, respectively. The accumulator tile :code:<code>acc</code> must be of type :code:<code>i32</code> and is always interpreted as signed. The output tile :code:<code>result</code> is of type :code:<code>i32</code> and is always interpreted as signed.</p><p>Shapes must be a valid matrix multiplication configuration. Unbatched (2D) MMA expects the operands :code:<code>lhs</code>, :code:<code>rhs</code>, and :code:<code>acc</code> to have shapes :code:<code>M x K</code>, :code:<code>K x N</code>, and :code:<code>M x N</code> (respectively). Batched (3D) MMA expects the operands to have shapes :code:<code>B x M x K</code>, :code:<code>B x K x N</code>, and :code:<code>B x M x N</code> (respectively).</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L2270-L2287" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.module_-Tuple{}" href="#Reactant.MLIR.Dialects.cuda_tile.module_-Tuple{}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.module_</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>module_</code></p><p>A :code:<code>module</code> operation represents a single compilation unit and contains zero or more items (global variables, functions, or kernels).</p><p>For detailed description of the semantics of modules, and the full definition of each item type see :ref:<code>sub_sec_modules</code>.</p><p>The :code:<code>module</code> operation is the top-level operation in a |cuda_tile| module and must contain only |cuda_tile| operations and no other dialects.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L2319-L2330" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.mulf-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.mulf-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.mulf</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>mulf</code></p><p>The :code:<code>mulf</code> operation computes the element-wise product between the two input tiles with with floating-point element types.</p><p>If the :code:<code>flush_to_zero</code> modifier is specified, denormal numbers are flushed to positive zero.</p><p>If the :code:<code>rounding</code> modifier is specified, the particular rounding mode will be applied to each element of the result.</p><p>.. math:: \text{mulf}(x, y)_i = x_i \times y_i</p><p>:suffix: Element-wise floating-point arithmetic operations are performed by the target architecture&#39;s native floating-point instructions. If the :code:<code>rounding</code> modifier is specified, the particular rounding mode will be applied to each element of the result. See :ref:<code>op-group-floating-point</code> for more details.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L2350-L2365" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.mulhii-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.mulhii-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.mulhii</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>mulhii</code></p><p>The :code:<code>mulhii</code> operation produces the most significant N bits of the 2N-bit product of two N-bit integer tiles. For :code:<code>i64</code>, this is the most significant 64 bits of the full 128-bit product; for :code:<code>i8</code>, it is the most significant 8 bits of the full 16-bit product; etc.</p><p>This is in contrast to :code:<code>muli</code>, which produces the lower N bits of the 2N-bit product.</p><p>The :code:<code>mulhii</code> operation is only defined for unsigned integers.</p><p>.. math:: \text{mulhii}(x_i, y_i) = x_i \times y_i &gt;&gt; \text{bitwidth}(\text{type}(x_i))</p><p>:suffix: Element-wise integer arithmetic operations are performed by the target architecture&#39;s native integer instructions. The default semantics are wrap-around semantics on overflow or underflow. See :ref:<code>op-group-integer</code> for more details.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L2433-L2450" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.muli-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.muli-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.muli</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>muli</code></p><p>The :code:<code>muli</code> operation computes the element-wise product between the two input tiles with integer element types.</p><p>.. math:: \text{muli}(x, y)_i = x_i \times y_i</p><p>:suffix: Element-wise integer arithmetic operations are performed by the target architecture&#39;s native integer instructions. The default semantics are wrap-around semantics on overflow or underflow. See :ref:<code>op-group-integer</code> for more details.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L2395-L2405" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.negf-Tuple{Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.negf-Tuple{Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.negf</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>negf</code></p><p>:code:<code>negf</code> is an element-wise operation that negates the sign of :code:<code>source</code>.</p><p>:suffix: Element-wise floating-point arithmetic operations are performed by the target architecture&#39;s native floating-point instructions. If the :code:<code>rounding</code> modifier is specified, the particular rounding mode will be applied to each element of the result. See :ref:<code>op-group-floating-point</code> for more details.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L2473-L2479" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.negi-Tuple{Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.negi-Tuple{Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.negi</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>negi</code></p><p>The :code:<code>negi</code> operation computes the element-wise negation of the input integer tile. The input and output tiles are always interpreted as signed integers.</p><p>.. math:: \text{negi}(x_i) = -x_i</p><p>:suffix: Element-wise integer arithmetic operations are performed by the target architecture&#39;s native integer instructions. The default semantics are wrap-around semantics on overflow or underflow. See :ref:<code>op-group-integer</code> for more details.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L2500-L2510" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.offset-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.offset-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.offset</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>offset</code></p><p>:code:<code>offset</code> advances a tile of pointers. It takes :code:<code>ptr</code> as base and :code:<code>offset</code> as increment, and performs element-wise addition of :code:<code>ptr</code> by :code:<code>offset</code>:</p><p>.. code-block:: mlir</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>result[i,j] = ptr[i,j] + offset[i,j] * bitwidth</span></span></code></pre></div><p>:code:<code>ptr</code> is interpreted as an unsigned integer. :code:<code>offset</code> is interpreted as a signed integer. :code:<code>bitwidth</code> is the storage bitwidth of the pointee type. The multiplication must not overflow (wrap-around) in a signed sense. The addition must not overflow (wrap-around) in an unsigned sense. In case of an overflow, the result is undefined.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L2531-L2547" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.ori-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.ori-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.ori</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>ori</code></p><p>The :code:<code>ori</code> operation computes the element-wise bitwise OR of two tiles with integer element types.</p><p>.. math:: \text{ori}(x, y)_i = x_i | y_i</p><p>:suffix: Element-wise integer arithmetic operations are performed by the target architecture&#39;s native integer instructions. The default semantics are wrap-around semantics on overflow or underflow. See :ref:<code>op-group-integer</code> for more details.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L2570-L2580" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.permute-Tuple{Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.permute-Tuple{Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.permute</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>permute</code></p><p>Permute the dimensions of the input tile :code:<code>source</code> according to the :code:<code>permutation</code> array. The :code:<code>permutation</code> array is a list of integers that specify the new order of the dimensions.</p><p>For example, if the input tile has shape :code:<code>[2, 4, 8]</code>, and the permutation is :code:<code>[2, 0, 1]</code>, the output tile will have shape :code:<code>[8, 2, 4]</code>.</p><p>This operation logically is a change in the indexing of the tile.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L2603-L2613" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.pow-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.pow-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.pow</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>pow</code></p><p>The :code:<code>pow</code> operation computes the element-wise exponentiation of the source floating-point tile raised to the power of the exponent floating-point tile.</p><p y_i="">.. math:: \text{pow}(x, y)_i = x_i^</p><p>:suffix: Element-wise floating-point arithmetic operations are performed by the target architecture&#39;s native floating-point instructions. If the :code:<code>rounding</code> modifier is specified, the particular rounding mode will be applied to each element of the result. See :ref:<code>op-group-floating-point</code> for more details.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L2633-L2643" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.print-Tuple{Vector{Reactant.MLIR.IR.Value}}" href="#Reactant.MLIR.Dialects.cuda_tile.print-Tuple{Vector{Reactant.MLIR.IR.Value}}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.print</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>print</code></p><p>The :code:<code>print</code> operation prints a C-printf-style format string, interleaved with the given operands. The number of format expressions (starting with the :code:<code>%</code> character) must match the number of operands. If a format expression is not applicable to its respective operand, then the output is undefined.</p><p>This operation is meant for debugging. Its implementation is not optimized for performance, so it should not be used in production mode. Moreover, prints may execute in an order that is different from the one in which they appear in the program.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L2669-L2682" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.ptr_to_int-Tuple{Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.ptr_to_int-Tuple{Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.ptr_to_int</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>ptr_to_int</code></p><p>The :code:<code>ptr_to_int</code> operation converts a tile of pointer-type elements to a tile of :code:<code>i64</code> elements.</p><p>The inverse of this operation is :ref:<code>op-cuda_tile.int_to_ptr</code>.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L2702-L2708" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.ptr_to_ptr-Tuple{Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.ptr_to_ptr-Tuple{Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.ptr_to_ptr</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>ptr_to_ptr</code></p><p>The :code:<code>ptr_to_ptr</code> operation casts a tile of pointers from a pointer of one element type to another element. Casts between pointer and non-pointer types are disallowed.</p><p>In order to perform those conversions, use :ref:<code>op-cuda_tile.ptr_to_int</code> or :ref:<code>op-cuda_tile.int_to_ptr</code>. These operations are distinct to enable future compiler reasoning about pointer provenance.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L2728-L2736" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.reduce-Tuple{Vector{Reactant.MLIR.IR.Value}}" href="#Reactant.MLIR.Dialects.cuda_tile.reduce-Tuple{Vector{Reactant.MLIR.IR.Value}}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.reduce</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>reduce</code></p><p>Applies a reduction function :code:<code>body</code> to :code:<code>operands</code> and :code:<code>identities</code> along dimensions :code:<code>dimensions</code> and produces new :code:<code>results</code> tile values. The order of reduction is implementation-defined but the result is deterministic.</p><p>Argument explained:</p><ul><li><p>:code:<code>operands</code> are the tiles to reduce.</p></li><li><p>:code:<code>identities</code> are the reduction identities for each operand. Identity at position i binds with the operand at the same position. Identities are properties of the reduction function in the :code:<code>body</code>. For example, the identity of a min reduction is +inf, while the identity of a sum is 0.</p></li><li><p>:code:<code>dim</code> is the index of the dimension to be reduced.</p></li><li><p>:code:<code>body</code> is a region carrying the reduction(s) semantics. Each operation within the region must be a cuda_tile operation with 0-rank cuda_tile tile types. Region arguments are bound to operands in the following way: [operand_0_current_iter, operand_0_prev_iter, operand_1_current_iter, operand_1_prev_iter...]. operand_i_current_iter is the current element to reduce from operand at index i. operand_i_prev_iter is the accumulator that might be an element of the same operand at index i, the result of the previous reduction step or the identity value associated with :code:<code>operand_i_current_iter</code>.</p></li></ul><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L2756-L2778" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.remf-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.remf-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.remf</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>remf</code></p><p>The :code:<code>remf</code> operation computes the element-wise floating-point remainder using truncated division (rounding towards zero).</p><p>.. math:: \text{remf}(x, y)_i = x_i - \text{trunc}(x_i / y_i) \times y_i</p><p>The result has the same sign as the dividend (:code:<code>lhs</code>) and its magnitude is less than the magnitude of divisor (:code:<code>rhs</code>).</p><p><strong>Special cases:</strong></p><ul><li><p>If :code:<code>y</code> is zero, returns :code:<code>NaN</code></p></li><li><p>If :code:<code>x</code> is infinite and :code:<code>y</code> is finite, returns :code:<code>NaN</code></p></li><li><p>If :code:<code>x</code> is finite and :code:<code>y</code> is infinite, returns :code:<code>x</code></p></li><li><p>If either argument is :code:<code>NaN</code>, returns :code:<code>NaN</code></p></li></ul><p>:suffix: Element-wise floating-point arithmetic operations are performed by the target architecture&#39;s native floating-point instructions. If the :code:<code>rounding</code> modifier is specified, the particular rounding mode will be applied to each element of the result. See :ref:<code>op-group-floating-point</code> for more details.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L2807-L2827" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.remi-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.remi-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.remi</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>remi</code></p><p>The :code:<code>remi</code> operation computes the element-wise remainder of the input tiles with integer element types using truncated division (rounding towards zero). Division by zero is undefined behavior.</p><p>.. math:: \text{remi}(x, y)_i = x_i - \text{trunc}(x_i / y_i) \times y_i</p><p>If the operation is signed, the sign of the result matches the sign of the dividend (:code:<code>lhs</code>). For example:</p><ul><li><p>:code:<code>remi(7, 3) = 1</code></p></li><li><p>:code:<code>remi(7, -3) = 1</code></p></li><li><p>:code:<code>remi(-7, 3) = -1</code></p></li><li><p>:code:<code>remi(-7, -3) = -1</code></p></li></ul><p>:suffix: Element-wise integer arithmetic operations are performed by the target architecture&#39;s native integer instructions. The default semantics are wrap-around semantics on overflow or underflow. See :ref:<code>op-group-integer</code> for more details.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L2850-L2870" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.reshape-Tuple{Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.reshape-Tuple{Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.reshape</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>reshape</code></p><p>The :code:<code>reshape</code> operation changes the shape of the :code:<code>source</code> operand. :code:<code>reshape</code> is only a change in the indexing of the tile. The number of elements and element type must remain unchanged.</p><p>0-d tiles (i.e., scalars) contain precisely one element and thus are the one exception where a 0-d tile can be reshaped to shape where the :code:<code>size(shape) == 1</code>.</p><p>Conceptually reshaping a tile is equivalent to first creating a 1-d tile from the data of the source assuming a row-major layout and then converting the 1-d tile into the new shape in a row-major layout.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L2897-L2909" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.return_-Tuple{Vector{Reactant.MLIR.IR.Value}}" href="#Reactant.MLIR.Dialects.cuda_tile.return_-Tuple{Vector{Reactant.MLIR.IR.Value}}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.return_</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>return_</code></p><p>The :code:<code>return</code> operation returns control to the caller of a function.</p><p>.. warning:: Today the :code:<code>return</code> operation has restricted semantics:</p><ul><li><p>:ref:<code>op-cuda_tile.entry</code> operations do not produce return value(s) and thus :code:<code>return</code> may be used to terminate the execution of the kernel by invoking the operation with no operands</p></li><li><p>:code:<code>return</code> can not be directly used inside of loop bodies to terminate the the execution of the kernel</p></li></ul><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L2929-L2941" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.rsqrt-Tuple{Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.rsqrt-Tuple{Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.rsqrt</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>rsqrt</code></p><p>The :code:<code>rsqrt</code> operation computes the element-wise reciprocal square root of the input floating-point tile.</p><p>This operation supports: :code:<code>flush_to_zero</code>: if set by the user, will flush subnormal inputs and results to sign-preserving zero.</p><p>.. math::</p><p>\text{rsqrt}(x)_i = \frac{1}{\sqrt{x_i}}</p><p>:suffix: This operation is emulated in :code:<code>f32</code> when executed on half-precision inputs (:code:<code>f16</code> and :code:<code>bf16</code>). See :ref:<code>op-group-floating-point</code> for more details.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L2961-L2975" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.scan-Tuple{Vector{Reactant.MLIR.IR.Value}}" href="#Reactant.MLIR.Dialects.cuda_tile.scan-Tuple{Vector{Reactant.MLIR.IR.Value}}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.scan</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>scan</code></p><p>Applies a scan function :code:<code>body</code> to :code:<code>operands</code> and :code:<code>identities</code> along dimension :code:<code>dim</code> and produces new :code:<code>results</code> tile values. The scan operation maintains a carry value that is updated as it processes elements along the specified dimension. For each element, the scan function combines the current element with the carry value to produce both a result and an updated carry. The order of scan is implementation-defined but the result is deterministic.</p><p>:code:<code>identities</code> are the scan identities for each operand. Identity at position i binds with the operand at the same position. Identities are properties of the scan function in the :code:<code>body</code>. For example, the identity of a min scan is +inf, while the identity of a sum is 0.</p><p>:code:<code>body</code> is a region carrying the scan semantics. Each operation within the region must be a cuda_tile operation with 0-rank cuda_tile tile types. Region arguments are bound to operands in the following way: :code:<code>[operand_0_current_iter, operand_0_prev_iter, operand_1_current_iter, operand_1_prev_iter...]</code>. :code:<code>operand_i_current_iter</code> is the current element to scan from operand at index :code:<code>i</code>. :code:<code>operand_i_prev_iter</code> is the accumulator that might be an element of the same operand at index :code:<code>i</code>, the result of the previous scan step or the identity value associated with :code:<code>operand_i_current_iter</code>.</p><p>.. warning::</p><p>The current implementation only supports single tile input.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L3003-L3030" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.select-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.select-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.select</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>select</code></p><p>The :code:<code>select</code> op chooses values based on the binary conditions supplied as the :code:<code>cond</code> operand. The :code:<code>val_if_true</code> operand contains the value(s) to use if the condition is 1. The :code:<code>val_if_false</code> operand contains the value(s) to use if the condition is 0. The choice is made element-wise according to the values in the condition tile.</p><p>All tiles must have the same shape. The tiles :code:<code>val_if_true</code>, :code:<code>val_if_false</code>, and the result must have the same element type. The :code:<code>cond</code> tile must be a tile of :code:<code>i1</code> values.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L3062-L3074" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.shli-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.shli-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.shli</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>shli</code></p><p>The :code:<code>shli</code> operation computes the element-wise left shift of the :code:<code>lhs</code> integer operand by the :code:<code>rhs</code> operand. The lower-order bits on the right are filled with zeros.</p><p>The :code:<code>rhs</code> operand is interpreted as an unsigned integer.</p><p>:suffix: Element-wise integer arithmetic operations are performed by the target architecture&#39;s native integer instructions. The default semantics are wrap-around semantics on overflow or underflow. See :ref:<code>op-group-integer</code> for more details.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L3101-L3110" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.shri-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.shri-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.shri</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>shri</code></p><p>The :code:<code>shri</code> operation computes the element-wise right shift of the :code:<code>lhs</code> integer operand by the value of the :code:<code>rhs</code> operand for tiles with integer element types.</p><p>When :code:<code>unsigned</code>, higher-order bits are zero-filled; when :code:<code>signed</code>, the higher-order bits are filled with the sign bit.</p><p>The :code:<code>rhs</code> operand is always interpreted as an unsigned integer.</p><p>:suffix: Element-wise integer arithmetic operations are performed by the target architecture&#39;s native integer instructions. The default semantics are wrap-around semantics on overflow or underflow. See :ref:<code>op-group-integer</code> for more details.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L3138-L3151" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.sin-Tuple{Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.sin-Tuple{Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.sin</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>sin</code></p><p>The :code:<code>sin</code> operation computes the element-wise sine of the input floating-point tile.</p><p>.. math::</p><p>\text{sin}(x)_i = \sin(x_i)</p><p>:suffix: This operation is emulated in :code:<code>f32</code> when executed on half-precision inputs (:code:<code>f16</code> and :code:<code>bf16</code>). See :ref:<code>op-group-floating-point</code> for more details.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L3210-L3220" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.sinh-Tuple{Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.sinh-Tuple{Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.sinh</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>sinh</code></p><p>The :code:<code>sinh</code> operation computes the element-wise hyperbolic sine of the input floating-point tile.</p><p>.. math::</p><p>\text{sinh}(x)_i = \sinh(x_i)</p><p>:suffix: This operation is emulated in :code:<code>f32</code> when executed on half-precision inputs (:code:<code>f16</code> and :code:<code>bf16</code>). See :ref:<code>op-group-floating-point</code> for more details.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L3178-L3189" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.sqrt-Tuple{Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.sqrt-Tuple{Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.sqrt</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>sqrt</code></p><p>The :code:<code>sqrt</code> operation computes the element-wise square root of a floating-point tile.</p><p>.. math::</p><p x_i="">\text{sqrt}(x)_i = \sqrt</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L3241-L3249" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.store_ptr_tko" href="#Reactant.MLIR.Dialects.cuda_tile.store_ptr_tko"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.store_ptr_tko</span></a> <span class="VPBadge info jlObjectType jlFunction"><!--[-->Function<!--]--></span></summary><p><code>store_ptr_tko</code></p><p>The :code:<code>store</code> operation performs a scatter by storing a tile of data from a tile into global memory.</p><p>The :code:<code>destination</code> operand is a tile of pointers indicating the global memory locations where data from the :code:<code>value</code> tile will be stored. When storing i1 values, each value occupies a full byte in memory. Any nonzero byte is canonicalized to 0x01, and zero bytes become 0x00.</p><p>Additionally, the operation supports an optional :code:<code>mask</code> operand, which allows selective scattering of elements. If provided, only the elements specified by the :code:<code>mask</code> are stored. The shape of the :code:<code>mask</code> must align with the shape of the :code:<code>value</code> tile.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L3278-L3293" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.store_view_tko" href="#Reactant.MLIR.Dialects.cuda_tile.store_view_tko"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.store_view_tko</span></a> <span class="VPBadge info jlObjectType jlFunction"><!--[-->Function<!--]--></span></summary><p><code>store_view_tko</code></p><p>The :code:<code>store_view_tko</code> operation stores a tile to a view indexing into a tile view.</p><p>A view is mapping from view-space indices to a particular element in the view, each view type has a defined mapping from view-space indices to tiles produced from elements of the view.</p><p>For example, the :ref:<code>type-partition_view</code> partitions a :ref:<code>type-tensor_view</code> into a grid of equally sized tiles. The view indices one of the partitioned tiles in the grid.</p><p>For a given view the rank of the indices must match the rank of the view&#39;s index space. The space of valid indices depends on which view is passed to the operation. For example the index space of a :ref:<code>type-partition_view</code> is equal to the rank of the partitioned tiles.</p><p>The index space of the view is computed a function of the requested tile size and the shape of the view.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L3336-L3356" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.subf-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.subf-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.subf</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>subf</code></p><p>The :code:<code>subf</code> operation computes the element-wise subtraction of the input floating-point tiles.</p><p>.. math:: \text{subf}(x, y)_i = x_i - y_i</p><p>:suffix: Element-wise floating-point arithmetic operations are performed by the target architecture&#39;s native floating-point instructions. If the :code:<code>rounding</code> modifier is specified, the particular rounding mode will be applied to each element of the result. See :ref:<code>op-group-floating-point</code> for more details.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L3395-L3404" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.subi-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.subi-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.subi</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>subi</code></p><p>The :code:<code>subi</code> operation computes the element-wise subtraction of two input integer tiles.</p><p>.. math:: \text{subi}(x, y)_i = x_i - y_i</p><p>:suffix: Element-wise integer arithmetic operations are performed by the target architecture&#39;s native integer instructions. The default semantics are wrap-around semantics on overflow or underflow. See :ref:<code>op-group-integer</code> for more details.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L3434-L3443" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.tan-Tuple{Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.tan-Tuple{Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.tan</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>tan</code></p><p>The :code:<code>tan</code> operation computes the element-wise tangent of the input floating-point tile.</p><p>.. math::</p><p>\text{tan}(x)_i = \tan(x_i)</p><p>:suffix: This operation is emulated in :code:<code>f32</code> when executed on half-precision inputs (:code:<code>f16</code> and :code:<code>bf16</code>). See :ref:<code>op-group-floating-point</code> for more details.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L3503-L3514" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.tanh-Tuple{Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.tanh-Tuple{Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.tanh</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>tanh</code></p><p>The :code:<code>tanh</code> operation computes the element-wise hyperbolic tangent of the input floating-point tile.</p><p>.. math::</p><p>\text{tanh}(x)_i = \tanh(x_i)</p><p>:suffix: This operation is emulated in :code:<code>f32</code> when executed on half-precision inputs (:code:<code>f16</code> and :code:<code>bf16</code>). See :ref:<code>op-group-floating-point</code> for more details.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L3471-L3482" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.trunci-Tuple{Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.trunci-Tuple{Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.trunci</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>trunci</code></p><p>The :code:<code>trunci</code> operation converts a tile of integers of a given element type to one with a strictly smaller width.</p><p>The optional <code>overflow</code> attribute specifies whether an overflow can occur when interpreting the operand as a signed and/or unsigned integer. In case of &quot;no signed wrap&quot;, all truncated bits must have the same value as the most significant bit of the truncated result. In case of &quot;no unsigned wrap&quot;, the truncated bits must be zero.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L3535-L3546" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.xori-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}" href="#Reactant.MLIR.Dialects.cuda_tile.xori-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.xori</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>xori</code></p><p>The :code:<code>xori</code> operation computes the element-wise bitwise exclusive or (XOR) of two tile values with integer element types.</p><p>.. math:: \text{xori}(x, y)_i = x_i \oplus y_i</p><p>:suffix: Element-wise integer arithmetic operations are performed by the target architecture&#39;s native integer instructions. The default semantics are wrap-around semantics on overflow or underflow. See :ref:<code>op-group-integer</code> for more details.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L3567-L3577" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block"><summary><a id="Reactant.MLIR.Dialects.cuda_tile.yield-Tuple{Vector{Reactant.MLIR.IR.Value}}" href="#Reactant.MLIR.Dialects.cuda_tile.yield-Tuple{Vector{Reactant.MLIR.IR.Value}}"><span class="jlbinding">Reactant.MLIR.Dialects.cuda_tile.yield</span></a> <span class="VPBadge info jlObjectType jlMethod"><!--[-->Method<!--]--></span></summary><p><code>yield</code></p><p>The :code:<code>yield</code> operation terminates a block that must yield control back to the parent operation such as :code:<code>if</code>, :code:<code>scan</code>, :code:<code>reduce</code>.</p><p>The operation may yield any number of :code:<code>$operands</code> to the parent upon termination. The number of values yielded and the execution semantics of how they are yielded are determined by the parent operation.</p><p>.. note::</p><p>Unlike standard MLIR control flow dialects :code:<code>yield</code> is not used for loop controlf low, see :ref:<code>op-cuda_tile.break</code> and :ref:<code>op-cuda_tile.continue</code> for loop control flow.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/EnzymeAD/Reactant.jl/blob/091fc3ce51e616a41e1e0c71acefb4bc998527c5/src/mlir/Dialects/CUDATile.jl#L3600-L3613" target="_blank" rel="noreferrer">source</a><!--]--></span></details></div></div></main><footer class="VPDocFooter" data-v-83890dd9 data-v-4f9813fa><!--[--><!--]--><div class="edit-info" data-v-4f9813fa><div class="edit-link" data-v-4f9813fa><a class="VPLink link vp-external-link-icon no-icon edit-link-button" href="https://github.com/EnzymeAD/Reactant.jl/edit/main/docs/src/api/dialects/cuda_tile.md" target="_blank" rel="noreferrer" data-v-4f9813fa><!--[--><span class="vpi-square-pen edit-link-icon" data-v-4f9813fa></span> Edit this page on GitHub<!--]--></a></div><!----></div><nav class="prev-next" aria-labelledby="doc-footer-aria-label" data-v-4f9813fa><span class="visually-hidden" id="doc-footer-aria-label" data-v-4f9813fa>Pager</span><div class="pager" data-v-4f9813fa><a class="VPLink link pager-link prev" href="/Reactant.jl/previews/PR2507/api/dialects/complex" data-v-4f9813fa><!--[--><span class="desc" data-v-4f9813fa>Previous page</span><span class="title" data-v-4f9813fa>Complex</span><!--]--></a></div><div class="pager" data-v-4f9813fa><a class="VPLink link pager-link next" href="/Reactant.jl/previews/PR2507/api/dialects/enzyme" data-v-4f9813fa><!--[--><span class="desc" data-v-4f9813fa>Next page</span><span class="title" data-v-4f9813fa>Enzyme</span><!--]--></a></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><footer class="VPFooter has-sidebar" data-v-a9a9e638 data-v-c970a860><div class="container" data-v-c970a860><p class="message" data-v-c970a860>Made with <a href="https://documenter.juliadocs.org/stable/" target="_blank"><strong>Documenter.jl</strong></a>, <a href="https://vitepress.dev" target="_blank"><strong>VitePress</strong></a> and <a href="https://luxdl.github.io/DocumenterVitepress.jl/stable" target="_blank"><strong>DocumenterVitepress.jl</strong></a><br>Released under the MIT License. Powered by the <a href="https://www.julialang.org">Julia Programming Language</a>.<br></p><p class="copyright" data-v-c970a860>© Copyright 2026 Reactant Development Team.</p></div></footer><!--[--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"api_api.md\":\"DAruptnZ\",\"api_config.md\":\"CtCXOAFB\",\"api_dialects_affine.md\":\"Cdy3Lk0e\",\"api_dialects_arith.md\":\"eOJwixZh\",\"api_dialects_builtin.md\":\"Cm3qIe3g\",\"api_dialects_chlo.md\":\"D8F1r0xV\",\"api_dialects_complex.md\":\"DARBXl7j\",\"api_dialects_cuda_tile.md\":\"BfG7BXTs\",\"api_dialects_enzyme.md\":\"DzZTahA_\",\"api_dialects_enzymexla.md\":\"BqvOl3LB\",\"api_dialects_func.md\":\"Do1m6bbM\",\"api_dialects_gpu.md\":\"DxBFJhNl\",\"api_dialects_llvm.md\":\"D7CZ5hgj\",\"api_dialects_memref.md\":\"DqLOtGlY\",\"api_dialects_mosaicgpu.md\":\"BVTqpem7\",\"api_dialects_mpi.md\":\"U-HsAWNr\",\"api_dialects_nvvm.md\":\"Cx9Z_11g\",\"api_dialects_shape.md\":\"T5F0OvZ_\",\"api_dialects_shardy.md\":\"Bi0GMKM3\",\"api_dialects_sparsetensor.md\":\"CK904tCg\",\"api_dialects_stablehlo.md\":\"CpinhsOl\",\"api_dialects_tensor.md\":\"BrrO6j34\",\"api_dialects_tpu.md\":\"B8ErXu8m\",\"api_dialects_triton.md\":\"CHYU2q4C\",\"api_dialects_tritonext.md\":\"BMsEEKHj\",\"api_dialects_vhlo.md\":\"CHcrZkBs\",\"api_internal.md\":\"CoPrFU4K\",\"api_mlirc.md\":\"BeIisBHT\",\"api_ops.md\":\"D-9chjPK\",\"api_serialization.md\":\"qDbvazUJ\",\"api_sharding.md\":\"a0fPi5pB\",\"api_xla.md\":\"BccqbVsB\",\"index.md\":\"DXKA7Igd\",\"introduction_configuration.md\":\"C-9iiCJK\",\"introduction_faqs.md\":\"6nVz9d1f\",\"introduction_index.md\":\"D_kL7hE9\",\"tutorials_automatic-differentiation.md\":\"pDm9lver\",\"tutorials_control-flow.md\":\"BeJkqDku\",\"tutorials_debugging.md\":\"Bpfd6uEC\",\"tutorials_index.md\":\"B6AXBUgQ\",\"tutorials_kernels.md\":\"BrozBo4v\",\"tutorials_local-build.md\":\"Dut3TiDj\",\"tutorials_multihost.md\":\"C2W3cbhz\",\"tutorials_partial-evaluation.md\":\"BUpd7E-W\",\"tutorials_persistent_compile_cache.md\":\"DLtj7G_q\",\"tutorials_profiling.md\":\"CKO3B17r\",\"tutorials_raising.md\":\"B6QfuNC1\",\"tutorials_sharding.md\":\"B8GmaMnR\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"en-US\",\"dir\":\"ltr\",\"title\":\"Reactant.jl\",\"description\":\"Documentation for Reactant.jl\",\"base\":\"/Reactant.jl/previews/PR2507/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"outline\":\"deep\",\"logo\":{\"light\":\"/logo.svg\",\"dark\":\"/logo.svg\"},\"search\":{\"provider\":\"local\",\"options\":{\"detailedView\":true}},\"nav\":[{\"text\":\"Home\",\"link\":\"/\"},{\"text\":\"Getting Started\",\"items\":[{\"text\":\"Introduction\",\"link\":\"/introduction\"},{\"text\":\"Configuration\",\"link\":\"/introduction/configuration\"},{\"text\":\"FAQs\",\"link\":\"/introduction/FAQs\"}]},{\"text\":\"Benchmarks\",\"link\":\"https://enzymead.github.io/Reactant.jl/benchmarks/\"},{\"text\":\"Tutorials\",\"items\":[{\"text\":\"Overview\",\"link\":\"/tutorials/\"},{\"text\":\"Partial Evaluation\",\"link\":\"/tutorials/partial-evaluation\"},{\"text\":\"Control Flow\",\"link\":\"/tutorials/control-flow\"},{\"text\":\"Automatic Differentiation\",\"link\":\"/tutorials/automatic-differentiation\"},{\"text\":\"Sharding\",\"link\":\"/tutorials/sharding\"},{\"text\":\"Profiling\",\"link\":\"/tutorials/profiling\"},{\"text\":\"Multi-Host Environments\",\"link\":\"/tutorials/multihost\"},{\"text\":\"Local build\",\"link\":\"/tutorials/local-build\"},{\"text\":\"Persistent Compilation Cache\",\"link\":\"/tutorials/persistent_compile_cache\"},{\"text\":\"Raising\",\"link\":\"/tutorials/raising\"},{\"text\":\"Computational kernels\",\"link\":\"/tutorials/kernels\"},{\"text\":\"Debugging compilation errors\",\"link\":\"/tutorials/debugging\"}]},{\"text\":\"API\",\"items\":[{\"text\":\"Core Reactant API\",\"link\":\"/api/api\"},{\"text\":\"Sharding\",\"link\":\"/api/sharding\"},{\"text\":\"Serialization\",\"link\":\"/api/serialization\"},{\"text\":\"Ops\",\"link\":\"/api/ops\"},{\"text\":\"Configuration\",\"link\":\"/api/config\"},{\"text\":\"MLIR Dialects\",\"items\":[{\"text\":\"ArithOps\",\"link\":\"/api/dialects/arith\"},{\"text\":\"Affine\",\"link\":\"/api/dialects/affine\"},{\"text\":\"Builtin\",\"link\":\"/api/dialects/builtin\"},{\"text\":\"Chlo\",\"link\":\"/api/dialects/chlo\"},{\"text\":\"Complex\",\"link\":\"/api/dialects/complex\"},{\"text\":\"CUDA Tile\",\"link\":\"/api/dialects/cuda_tile\"},{\"text\":\"Enzyme\",\"link\":\"/api/dialects/enzyme\"},{\"text\":\"EnzymeXLA\",\"link\":\"/api/dialects/enzymexla\"},{\"text\":\"Func\",\"link\":\"/api/dialects/func\"},{\"text\":\"GPU\",\"link\":\"/api/dialects/gpu\"},{\"text\":\"LLVM\",\"link\":\"/api/dialects/llvm\"},{\"text\":\"MPI\",\"link\":\"/api/dialects/mpi\"},{\"text\":\"MemRef\",\"link\":\"/api/dialects/memref\"},{\"text\":\"Mosaic GPU\",\"link\":\"/api/dialects/mosaicgpu\"},{\"text\":\"NVVM\",\"link\":\"/api/dialects/nvvm\"},{\"text\":\"Shape\",\"link\":\"/api/dialects/shape\"},{\"text\":\"Shardy\",\"link\":\"/api/dialects/shardy\"},{\"text\":\"SparseTensor\",\"link\":\"/api/dialects/sparsetensor\"},{\"text\":\"StableHLO\",\"link\":\"/api/dialects/stablehlo\"},{\"text\":\"Tensor\",\"link\":\"/api/dialects/tensor\"},{\"text\":\"Triton\",\"link\":\"/api/dialects/triton\"},{\"text\":\"TritonExt\",\"link\":\"/api/dialects/tritonext\"},{\"text\":\"TPU\",\"link\":\"/api/dialects/tpu\"},{\"text\":\"VHLO\",\"link\":\"/api/dialects/vhlo\"}]},{\"text\":\"Low-Level API\",\"items\":[{\"text\":\"MLIR API\",\"link\":\"/api/mlirc\"},{\"text\":\"XLA\",\"link\":\"/api/xla\"}]},{\"text\":\"Internal API\",\"link\":\"/api/internal\"}]},{\"component\":\"VersionPicker\"}],\"sidebar\":{\"/introduction/\":[{\"text\":\"Getting Started\",\"collapsed\":false,\"items\":[{\"text\":\"Introduction\",\"link\":\"/introduction\"},{\"text\":\"Configuration\",\"link\":\"/introduction/configuration\"},{\"text\":\"FAQs\",\"link\":\"/introduction/FAQs\"}]}],\"/tutorials/\":[{\"text\":\"Tutorials\",\"collapsed\":false,\"items\":[{\"text\":\"Overview\",\"link\":\"/tutorials/\"},{\"text\":\"Partial Evaluation\",\"link\":\"/tutorials/partial-evaluation\"},{\"text\":\"Control Flow\",\"link\":\"/tutorials/control-flow\"},{\"text\":\"Automatic Differentiation\",\"link\":\"/tutorials/automatic-differentiation\"},{\"text\":\"Sharding\",\"link\":\"/tutorials/sharding\"},{\"text\":\"Profiling\",\"link\":\"/tutorials/profiling\"},{\"text\":\"Multi-Host Environments\",\"link\":\"/tutorials/multihost\"},{\"text\":\"Local build\",\"link\":\"/tutorials/local-build\"},{\"text\":\"Persistent Compilation Cache\",\"link\":\"/tutorials/persistent_compile_cache\"},{\"text\":\"Raising\",\"link\":\"/tutorials/raising\"},{\"text\":\"Computational kernels\",\"link\":\"/tutorials/kernels\"},{\"text\":\"Debugging compilation errors\",\"link\":\"/tutorials/debugging\"}]}],\"/api/\":[{\"text\":\"API Reference\",\"collapsed\":false,\"items\":[{\"text\":\"Reactant API\",\"link\":\"/api/api\"},{\"text\":\"Sharding\",\"link\":\"/api/sharding\"},{\"text\":\"Serialization\",\"link\":\"/api/serialization\"},{\"text\":\"Ops\",\"link\":\"/api/ops\"},{\"text\":\"Configuration\",\"link\":\"/api/config\"},{\"text\":\"MLIR Dialects\",\"collapsed\":false,\"items\":[{\"text\":\"ArithOps\",\"link\":\"/api/dialects/arith\"},{\"text\":\"Affine\",\"link\":\"/api/dialects/affine\"},{\"text\":\"Builtin\",\"link\":\"/api/dialects/builtin\"},{\"text\":\"Chlo\",\"link\":\"/api/dialects/chlo\"},{\"text\":\"Complex\",\"link\":\"/api/dialects/complex\"},{\"text\":\"CUDA Tile\",\"link\":\"/api/dialects/cuda_tile\"},{\"text\":\"Enzyme\",\"link\":\"/api/dialects/enzyme\"},{\"text\":\"EnzymeXLA\",\"link\":\"/api/dialects/enzymexla\"},{\"text\":\"Func\",\"link\":\"/api/dialects/func\"},{\"text\":\"GPU\",\"link\":\"/api/dialects/gpu\"},{\"text\":\"LLVM\",\"link\":\"/api/dialects/llvm\"},{\"text\":\"MPI\",\"link\":\"/api/dialects/mpi\"},{\"text\":\"MemRef\",\"link\":\"/api/dialects/memref\"},{\"text\":\"Mosaic GPU\",\"link\":\"/api/dialects/mosaicgpu\"},{\"text\":\"NVVM\",\"link\":\"/api/dialects/nvvm\"},{\"text\":\"Shape\",\"link\":\"/api/dialects/shape\"},{\"text\":\"Shardy\",\"link\":\"/api/dialects/shardy\"},{\"text\":\"SparseTensor\",\"link\":\"/api/dialects/sparsetensor\"},{\"text\":\"StableHLO\",\"link\":\"/api/dialects/stablehlo\"},{\"text\":\"Tensor\",\"link\":\"/api/dialects/tensor\"},{\"text\":\"Triton\",\"link\":\"/api/dialects/triton\"},{\"text\":\"TritonExt\",\"link\":\"/api/dialects/tritonext\"},{\"text\":\"TPU\",\"link\":\"/api/dialects/tpu\"},{\"text\":\"VHLO\",\"link\":\"/api/dialects/vhlo\"}]},{\"text\":\"Low-Level API\",\"collapsed\":false,\"items\":[{\"text\":\"MLIR API\",\"link\":\"/api/mlirc\"},{\"text\":\"XLA\",\"link\":\"/api/xla\"}]},{\"text\":\"Internal API\",\"link\":\"/api/internal\"}]}]},\"editLink\":{\"pattern\":\"https://github.com/EnzymeAD/Reactant.jl/edit/main/docs/src/:path\",\"text\":\"Edit this page on GitHub\"},\"socialLinks\":[{\"icon\":\"slack\",\"link\":\"https://julialang.org/slack/\"}],\"footer\":{\"message\":\"Made with <a href=\\\"https://documenter.juliadocs.org/stable/\\\" target=\\\"_blank\\\"><strong>Documenter.jl</strong></a>, <a href=\\\"https://vitepress.dev\\\" target=\\\"_blank\\\"><strong>VitePress</strong></a> and <a href=\\\"https://luxdl.github.io/DocumenterVitepress.jl/stable\\\" target=\\\"_blank\\\"><strong>DocumenterVitepress.jl</strong></a><br>Released under the MIT License. Powered by the <a href=\\\"https://www.julialang.org\\\">Julia Programming Language</a>.<br>\",\"copyright\":\"© Copyright 2026 Reactant Development Team.\"},\"lastUpdated\":{\"text\":\"Updated at\",\"formatOptions\":{\"dateStyle\":\"full\",\"timeStyle\":\"medium\"}}},\"locales\":{},\"scrollOffset\":134,\"cleanUrls\":true}");</script>
    
  </body>
</html>