import{_ as c,C as d,c as r,o as i,j as t,a,G as s,w as l,a2 as o}from"./chunks/framework.ggWhhDUr.js";const de=JSON.parse('{"title":"NVVM Dialect","description":"","frontmatter":{},"headers":[],"relativePath":"api/dialects/nvvm.md","filePath":"api/dialects/nvvm.md","lastUpdated":null}'),p={name:"api/dialects/nvvm.md"},m={class:"jldocstring custom-block"},u={class:"jldocstring custom-block"},T={class:"jldocstring custom-block"},f={class:"jldocstring custom-block"},Q={class:"jldocstring custom-block"},h={class:"jldocstring custom-block"},b={class:"jldocstring custom-block"},g={class:"jldocstring custom-block"},v={class:"jldocstring custom-block"},y={class:"jldocstring custom-block"},k={class:"jldocstring custom-block"},R={class:"jldocstring custom-block"},x={class:"jldocstring custom-block"},_={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},M={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.464ex"},xmlns:"http://www.w3.org/2000/svg",width:"53.79ex",height:"2.059ex",role:"img",focusable:"false",viewBox:"0 -705 23775.1 910","aria-hidden":"true"},L={class:"jldocstring custom-block"},I={class:"jldocstring custom-block"},j={class:"jldocstring custom-block"},D={class:"jldocstring custom-block"},w={class:"jldocstring custom-block"},A={class:"jldocstring custom-block"},V={class:"jldocstring custom-block"},S={class:"jldocstring custom-block"},H={class:"jldocstring custom-block"},N={class:"jldocstring custom-block"},C={class:"jldocstring custom-block"},P={class:"jldocstring custom-block"},F={class:"jldocstring custom-block"},E={class:"jldocstring custom-block"},O={class:"jldocstring custom-block"},z={class:"jldocstring custom-block"},Z={class:"jldocstring custom-block"},X={class:"jldocstring custom-block"},q={class:"jldocstring custom-block"},B={class:"jldocstring custom-block"},$={class:"jldocstring custom-block"},W={class:"jldocstring custom-block"},G={class:"jldocstring custom-block"},J={class:"jldocstring custom-block"},K={class:"jldocstring custom-block"},U={class:"jldocstring custom-block"},Y={class:"jldocstring custom-block"},ee={class:"jldocstring custom-block"},te={class:"jldocstring custom-block"},ae={class:"jldocstring custom-block"};function ne(se,e,le,oe,re,ie){const n=d("Badge");return i(),r("div",null,[e[232]||(e[232]=t("h1",{id:"NVVM-Dialect",tabindex:"-1"},[a("NVVM Dialect "),t("a",{class:"header-anchor",href:"#NVVM-Dialect","aria-label":'Permalink to "NVVM Dialect {#NVVM-Dialect}"'},"​")],-1)),e[233]||(e[233]=t("p",null,[a("Refer to the "),t("a",{href:"https://mlir.llvm.org/docs/Dialects/NVVMDialect/",target:"_blank",rel:"noreferrer"},"official documentation"),a(" for more details.")],-1)),t("details",m,[t("summary",null,[e[0]||(e[0]=t("a",{id:"Reactant.MLIR.Dialects.nvvm.barrier_arrive",href:"#Reactant.MLIR.Dialects.nvvm.barrier_arrive"},[t("span",{class:"jlbinding"},"Reactant.MLIR.Dialects.nvvm.barrier_arrive")],-1)),e[1]||(e[1]=a()),s(n,{type:"info",class:"jlObjectType jlFunction",text:"Function"})]),e[3]||(e[3]=t("p",null,[t("code",null,"barrier_arrive")],-1)),e[4]||(e[4]=t("p",null,"Thread that executes this op announces their arrival at the barrier with given id and continue their execution.",-1)),e[5]||(e[5]=t("p",null,[a("The default barrier id is 0 that is similar to "),t("code",null,"nvvm.barrier"),a(" Op. When "),t("code",null,"barrierId"),a(" is not present, the default barrier id is used.")],-1)),e[6]||(e[6]=t("p",null,[t("a",{href:"https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#parallel-synchronization-and-communication-instructions-bar",target:"_blank",rel:"noreferrer"},"For more information, see PTX ISA")],-1)),s(n,{type:"info",class:"source-link",text:"source"},{default:l(()=>e[2]||(e[2]=[t("a",{href:"https://github.com/EnzymeAD/Reactant.jl/blob/f3e0d0f12705c284c2cafd6c4acfc87b112d9751/src/mlir/Dialects/Nvvm.jl#L35-L45",target:"_blank",rel:"noreferrer"},"source",-1)])),_:1})]),t("details",u,[t("summary",null,[e[7]||(e[7]=t("a",{id:"Reactant.MLIR.Dialects.nvvm.breakpoint-Tuple{}",href:"#Reactant.MLIR.Dialects.nvvm.breakpoint-Tuple{}"},[t("span",{class:"jlbinding"},"Reactant.MLIR.Dialects.nvvm.breakpoint")],-1)),e[8]||(e[8]=a()),s(n,{type:"info",class:"jlObjectType jlMethod",text:"Method"})]),e[10]||(e[10]=t("p",null,[t("code",null,"breakpoint")],-1)),e[11]||(e[11]=t("p",null,[a("Breakpoint suspends execution of the program for debugging. "),t("a",{href:"https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#miscellaneous-instructions-brkpt",target:"_blank",rel:"noreferrer"},"For more information, see PTX ISA")],-1)),s(n,{type:"info",class:"source-link",text:"source"},{default:l(()=>e[9]||(e[9]=[t("a",{href:"https://github.com/EnzymeAD/Reactant.jl/blob/f3e0d0f12705c284c2cafd6c4acfc87b112d9751/src/mlir/Dialects/Nvvm.jl#L282-L287",target:"_blank",rel:"noreferrer"},"source",-1)])),_:1})]),t("details",T,[t("summary",null,[e[12]||(e[12]=t("a",{id:"Reactant.MLIR.Dialects.nvvm.cluster_arrive-Tuple{}",href:"#Reactant.MLIR.Dialects.nvvm.cluster_arrive-Tuple{}"},[t("span",{class:"jlbinding"},"Reactant.MLIR.Dialects.nvvm.cluster_arrive")],-1)),e[13]||(e[13]=a()),s(n,{type:"info",class:"jlObjectType jlMethod",text:"Method"})]),e[15]||(e[15]=t("p",null,[t("code",null,"cluster_arrive")],-1)),e[16]||(e[16]=t("p",null,[a("The "),t("code",null,"cluster.arrive"),a(" can be used by the threads within the cluster for synchronization and communication. The "),t("code",null,"cluster.arrive"),a(" instruction marks the warps' arrival at the barrier without causing the executing thread to wait for other participating threads.")],-1)),e[17]||(e[17]=t("p",null,[a("The "),t("code",null,"aligned"),a(" attribute, when provided, generates the .aligned version of the PTX instruction.")],-1)),e[18]||(e[18]=t("p",null,[t("a",{href:"https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#parallel-synchronization-and-communication-instructions-barrier-cluster",target:"_blank",rel:"noreferrer"},"For more information, see PTX ISA")],-1)),s(n,{type:"info",class:"source-link",text:"source"},{default:l(()=>e[14]||(e[14]=[t("a",{href:"https://github.com/EnzymeAD/Reactant.jl/blob/f3e0d0f12705c284c2cafd6c4acfc87b112d9751/src/mlir/Dialects/Nvvm.jl#L345-L355",target:"_blank",rel:"noreferrer"},"source",-1)])),_:1})]),t("details",f,[t("summary",null,[e[19]||(e[19]=t("a",{id:"Reactant.MLIR.Dialects.nvvm.cluster_arrive_relaxed-Tuple{}",href:"#Reactant.MLIR.Dialects.nvvm.cluster_arrive_relaxed-Tuple{}"},[t("span",{class:"jlbinding"},"Reactant.MLIR.Dialects.nvvm.cluster_arrive_relaxed")],-1)),e[20]||(e[20]=a()),s(n,{type:"info",class:"jlObjectType jlMethod",text:"Method"})]),e[22]||(e[22]=o("",4)),s(n,{type:"info",class:"source-link",text:"source"},{default:l(()=>e[21]||(e[21]=[t("a",{href:"https://github.com/EnzymeAD/Reactant.jl/blob/f3e0d0f12705c284c2cafd6c4acfc87b112d9751/src/mlir/Dialects/Nvvm.jl#L376-L389",target:"_blank",rel:"noreferrer"},"source",-1)])),_:1})]),t("details",Q,[t("summary",null,[e[23]||(e[23]=t("a",{id:"Reactant.MLIR.Dialects.nvvm.cluster_wait-Tuple{}",href:"#Reactant.MLIR.Dialects.nvvm.cluster_wait-Tuple{}"},[t("span",{class:"jlbinding"},"Reactant.MLIR.Dialects.nvvm.cluster_wait")],-1)),e[24]||(e[24]=a()),s(n,{type:"info",class:"jlObjectType jlMethod",text:"Method"})]),e[26]||(e[26]=t("p",null,[t("code",null,"cluster_wait")],-1)),e[27]||(e[27]=t("p",null,[a("The "),t("code",null,"cluster.wait"),a(" causes the executing thread to wait for all non-exited threads of the cluster to perform "),t("code",null,"cluster.arrive"),a(". The "),t("code",null,"aligned"),a(" attribute, when provided, generates the .aligned version of the PTX instruction.")],-1)),e[28]||(e[28]=t("p",null,[t("a",{href:"https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#parallel-synchronization-and-communication-instructions-barrier-cluster",target:"_blank",rel:"noreferrer"},"For more information, see PTX ISA")],-1)),s(n,{type:"info",class:"source-link",text:"source"},{default:l(()=>e[25]||(e[25]=[t("a",{href:"https://github.com/EnzymeAD/Reactant.jl/blob/f3e0d0f12705c284c2cafd6c4acfc87b112d9751/src/mlir/Dialects/Nvvm.jl#L630-L638",target:"_blank",rel:"noreferrer"},"source",-1)])),_:1})]),t("details",h,[t("summary",null,[e[29]||(e[29]=t("a",{id:"Reactant.MLIR.Dialects.nvvm.cp_async_bulk_commit_group-Tuple{}",href:"#Reactant.MLIR.Dialects.nvvm.cp_async_bulk_commit_group-Tuple{}"},[t("span",{class:"jlbinding"},"Reactant.MLIR.Dialects.nvvm.cp_async_bulk_commit_group")],-1)),e[30]||(e[30]=a()),s(n,{type:"info",class:"jlObjectType jlMethod",text:"Method"})]),e[32]||(e[32]=t("p",null,[t("code",null,"cp_async_bulk_commit_group")],-1)),e[33]||(e[33]=t("p",null,"This Op commits all prior initiated but uncommitted cp.async.bulk instructions into a cp.async.bulk-group.",-1)),e[34]||(e[34]=t("p",null,[t("a",{href:"https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#data-movement-and-conversion-instructions-cp-async-bulk-commit-group",target:"_blank",rel:"noreferrer"},"For more information, see PTX ISA")],-1)),s(n,{type:"info",class:"source-link",text:"source"},{default:l(()=>e[31]||(e[31]=[t("a",{href:"https://github.com/EnzymeAD/Reactant.jl/blob/f3e0d0f12705c284c2cafd6c4acfc87b112d9751/src/mlir/Dialects/Nvvm.jl#L659-L666",target:"_blank",rel:"noreferrer"},"source",-1)])),_:1})]),t("details",b,[t("summary",null,[e[35]||(e[35]=t("a",{id:"Reactant.MLIR.Dialects.nvvm.cp_async_bulk_global_shared_cta",href:"#Reactant.MLIR.Dialects.nvvm.cp_async_bulk_global_shared_cta"},[t("span",{class:"jlbinding"},"Reactant.MLIR.Dialects.nvvm.cp_async_bulk_global_shared_cta")],-1)),e[36]||(e[36]=a()),s(n,{type:"info",class:"jlObjectType jlFunction",text:"Function"})]),e[38]||(e[38]=t("p",null,[t("code",null,"cp_async_bulk_global_shared_cta")],-1)),e[39]||(e[39]=t("p",null,"Initiates an asynchronous copy operation from Shared CTA memory to global memory.",-1)),e[40]||(e[40]=t("p",null,[a("The "),t("code",null,"l2CacheHint"),a(" operand is optional, and it is used to specify cache eviction policy that may be used during the memory access.")],-1)),e[41]||(e[41]=t("p",null,[t("a",{href:"https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#data-movement-and-conversion-instructions-cp-async-bulk",target:"_blank",rel:"noreferrer"},"For more information, see PTX ISA")],-1)),s(n,{type:"info",class:"source-link",text:"source"},{default:l(()=>e[37]||(e[37]=[t("a",{href:"https://github.com/EnzymeAD/Reactant.jl/blob/f3e0d0f12705c284c2cafd6c4acfc87b112d9751/src/mlir/Dialects/Nvvm.jl#L745-L755",target:"_blank",rel:"noreferrer"},"source",-1)])),_:1})]),t("details",g,[t("summary",null,[e[42]||(e[42]=t("a",{id:"Reactant.MLIR.Dialects.nvvm.cp_async_bulk_shared_cluster_global",href:"#Reactant.MLIR.Dialects.nvvm.cp_async_bulk_shared_cluster_global"},[t("span",{class:"jlbinding"},"Reactant.MLIR.Dialects.nvvm.cp_async_bulk_shared_cluster_global")],-1)),e[43]||(e[43]=a()),s(n,{type:"info",class:"jlObjectType jlFunction",text:"Function"})]),e[45]||(e[45]=o("",5)),s(n,{type:"info",class:"source-link",text:"source"},{default:l(()=>e[44]||(e[44]=[t("a",{href:"https://github.com/EnzymeAD/Reactant.jl/blob/f3e0d0f12705c284c2cafd6c4acfc87b112d9751/src/mlir/Dialects/Nvvm.jl#L686-L702",target:"_blank",rel:"noreferrer"},"source",-1)])),_:1})]),t("details",v,[t("summary",null,[e[46]||(e[46]=t("a",{id:"Reactant.MLIR.Dialects.nvvm.cp_async_bulk_shared_cluster_shared_cta-NTuple{4, Reactant.MLIR.IR.Value}",href:"#Reactant.MLIR.Dialects.nvvm.cp_async_bulk_shared_cluster_shared_cta-NTuple{4, Reactant.MLIR.IR.Value}"},[t("span",{class:"jlbinding"},"Reactant.MLIR.Dialects.nvvm.cp_async_bulk_shared_cluster_shared_cta")],-1)),e[47]||(e[47]=a()),s(n,{type:"info",class:"jlObjectType jlMethod",text:"Method"})]),e[49]||(e[49]=t("p",null,[t("code",null,"cp_async_bulk_shared_cluster_shared_cta")],-1)),e[50]||(e[50]=t("p",null,"Initiates an asynchronous copy operation from Shared CTA memory to Shared cluster memory.",-1)),e[51]||(e[51]=t("p",null,[t("a",{href:"https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#data-movement-and-conversion-instructions-cp-async-bulk",target:"_blank",rel:"noreferrer"},"For more information, see PTX ISA")],-1)),s(n,{type:"info",class:"source-link",text:"source"},{default:l(()=>e[48]||(e[48]=[t("a",{href:"https://github.com/EnzymeAD/Reactant.jl/blob/f3e0d0f12705c284c2cafd6c4acfc87b112d9751/src/mlir/Dialects/Nvvm.jl#L782-L789",target:"_blank",rel:"noreferrer"},"source",-1)])),_:1})]),t("details",y,[t("summary",null,[e[52]||(e[52]=t("a",{id:"Reactant.MLIR.Dialects.nvvm.cp_async_bulk_tensor_prefetch",href:"#Reactant.MLIR.Dialects.nvvm.cp_async_bulk_tensor_prefetch"},[t("span",{class:"jlbinding"},"Reactant.MLIR.Dialects.nvvm.cp_async_bulk_tensor_prefetch")],-1)),e[53]||(e[53]=a()),s(n,{type:"info",class:"jlObjectType jlFunction",text:"Function"})]),e[55]||(e[55]=o("",9)),s(n,{type:"info",class:"source-link",text:"source"},{default:l(()=>e[54]||(e[54]=[t("a",{href:"https://github.com/EnzymeAD/Reactant.jl/blob/f3e0d0f12705c284c2cafd6c4acfc87b112d9751/src/mlir/Dialects/Nvvm.jl#L888-L907",target:"_blank",rel:"noreferrer"},"source",-1)])),_:1})]),t("details",k,[t("summary",null,[e[56]||(e[56]=t("a",{id:"Reactant.MLIR.Dialects.nvvm.cp_async_bulk_tensor_reduce",href:"#Reactant.MLIR.Dialects.nvvm.cp_async_bulk_tensor_reduce"},[t("span",{class:"jlbinding"},"Reactant.MLIR.Dialects.nvvm.cp_async_bulk_tensor_reduce")],-1)),e[57]||(e[57]=a()),s(n,{type:"info",class:"jlObjectType jlFunction",text:"Function"})]),e[59]||(e[59]=t("p",null,[t("code",null,"cp_async_bulk_tensor_reduce")],-1)),e[60]||(e[60]=t("p",null,"Initiates an asynchronous reduction operation of tensor data in global memory with tensor data in shared memory.",-1)),e[61]||(e[61]=t("p",{"add,":"","min,":"","max,":"","inc,":"","dec,":"","and,":"","or,":"",xor:""},[a("The "),t("code",null,"mode"),a(" attribute indicates whether the copy mode is tile or im2col. The "),t("code",null,"redOp"),a(" attribute specifies the reduction operations applied. The supported reduction operations are:")],-1)),e[62]||(e[62]=t("p",null,[a("The "),t("code",null,"l2CacheHint"),a(" operand is optional, and it is used to specify cache eviction policy that may be used during the memory access.")],-1)),e[63]||(e[63]=t("p",null,[t("a",{href:"https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#data-movement-and-conversion-instructions-cp-reduce-async-bulk-tensor",target:"_blank",rel:"noreferrer"},"For more information, see PTX ISA")],-1)),s(n,{type:"info",class:"source-link",text:"source"},{default:l(()=>e[58]||(e[58]=[t("a",{href:"https://github.com/EnzymeAD/Reactant.jl/blob/f3e0d0f12705c284c2cafd6c4acfc87b112d9751/src/mlir/Dialects/Nvvm.jl#L940-L955",target:"_blank",rel:"noreferrer"},"source",-1)])),_:1})]),t("details",R,[t("summary",null,[e[64]||(e[64]=t("a",{id:"Reactant.MLIR.Dialects.nvvm.cp_async_bulk_tensor_shared_cluster_global",href:"#Reactant.MLIR.Dialects.nvvm.cp_async_bulk_tensor_shared_cluster_global"},[t("span",{class:"jlbinding"},"Reactant.MLIR.Dialects.nvvm.cp_async_bulk_tensor_shared_cluster_global")],-1)),e[65]||(e[65]=a()),s(n,{type:"info",class:"jlObjectType jlFunction",text:"Function"})]),e[67]||(e[67]=o("",10)),s(n,{type:"info",class:"source-link",text:"source"},{default:l(()=>e[66]||(e[66]=[t("a",{href:"https://github.com/EnzymeAD/Reactant.jl/blob/f3e0d0f12705c284c2cafd6c4acfc87b112d9751/src/mlir/Dialects/Nvvm.jl#L811-L836",target:"_blank",rel:"noreferrer"},"source",-1)])),_:1})]),t("details",x,[t("summary",null,[e[68]||(e[68]=t("a",{id:"Reactant.MLIR.Dialects.nvvm.cp_async_bulk_wait_group-Tuple{}",href:"#Reactant.MLIR.Dialects.nvvm.cp_async_bulk_wait_group-Tuple{}"},[t("span",{class:"jlbinding"},"Reactant.MLIR.Dialects.nvvm.cp_async_bulk_wait_group")],-1)),e[69]||(e[69]=a()),s(n,{type:"info",class:"jlObjectType jlMethod",text:"Method"})]),e[77]||(e[77]=t("p",null,[t("code",null,"cp_async_bulk_wait_group")],-1)),e[78]||(e[78]=t("p",null,"Op waits for completion of the most recent bulk async-groups.",-1)),t("p",null,[e[72]||(e[72]=a("The ")),e[73]||(e[73]=t("code",null,"$group",-1)),e[74]||(e[74]=a(" operand tells waiting has to be done until for ")),t("mjx-container",_,[(i(),r("svg",M,e[70]||(e[70]=[o("",1)]))),e[71]||(e[71]=t("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("mi",null,"g"),t("mi",null,"r"),t("mi",null,"o"),t("mi",null,"u"),t("mi",null,"p"),t("mi",null,"o"),t("mi",null,"r"),t("mi",null,"f"),t("mi",null,"e"),t("mi",null,"w"),t("mi",null,"e"),t("mi",null,"r"),t("mi",null,"o"),t("mi",null,"f"),t("mi",null,"t"),t("mi",null,"h"),t("mi",null,"e"),t("mi",null,"m"),t("mi",null,"o"),t("mi",null,"s"),t("mi",null,"t"),t("mi",null,"r"),t("mi",null,"e"),t("mi",null,"c"),t("mi",null,"e"),t("mi",null,"n"),t("mi",null,"t"),t("mi",null,"b"),t("mi",null,"u"),t("mi",null,"l"),t("mi",null,"k"),t("mi",null,"a"),t("mi",null,"s"),t("mi",null,"y"),t("mi",null,"n"),t("mi",null,"c"),t("mo",null,"−"),t("mi",null,"g"),t("mi",null,"r"),t("mi",null,"o"),t("mi",null,"u"),t("mi",null,"p"),t("mi",null,"s"),t("mo",null,"."),t("mi",null,"I"),t("mi",null,"f"),t("mo",{"data-mjx-pseudoscript":"true"},"‘")])],-1))]),e[75]||(e[75]=a("group` is 0, the op wait until all the most recent bulk async-groups have completed."))]),e[79]||(e[79]=t("p",null,[a("The "),t("code",null,"$read"),a(" indicates that the waiting has to be done until all the bulk async operations in the specified bulk async-group have completed reading from their source locations.")],-1)),e[80]||(e[80]=t("p",null,[t("a",{href:"https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#data-movement-and-conversion-instructions-cp-async-bulk-wait-group",target:"_blank",rel:"noreferrer"},"For more information, see PTX ISA")],-1)),s(n,{type:"info",class:"source-link",text:"source"},{default:l(()=>e[76]||(e[76]=[t("a",{href:"https://github.com/EnzymeAD/Reactant.jl/blob/f3e0d0f12705c284c2cafd6c4acfc87b112d9751/src/mlir/Dialects/Nvvm.jl#L1019-L1033",target:"_blank",rel:"noreferrer"},"source",-1)])),_:1})]),t("details",L,[t("summary",null,[e[81]||(e[81]=t("a",{id:"Reactant.MLIR.Dialects.nvvm.cp_async_mbarrier_arrive-Tuple{Reactant.MLIR.IR.Value}",href:"#Reactant.MLIR.Dialects.nvvm.cp_async_mbarrier_arrive-Tuple{Reactant.MLIR.IR.Value}"},[t("span",{class:"jlbinding"},"Reactant.MLIR.Dialects.nvvm.cp_async_mbarrier_arrive")],-1)),e[82]||(e[82]=a()),s(n,{type:"info",class:"jlObjectType jlMethod",text:"Method"})]),e[84]||(e[84]=t("p",null,[t("code",null,"cp_async_mbarrier_arrive")],-1)),e[85]||(e[85]=t("p",null,[a("The "),t("code",null,"cp.async.mbarrier.arrive"),a(" Op makes the mbarrier object track all prior cp.async operations initiated by the executing thread. The "),t("code",null,"addr"),a(" operand specifies the address of the mbarrier object in generic address space. The "),t("code",null,"noinc"),a(" attr impacts how the mbarrier's state is updated.")],-1)),e[86]||(e[86]=t("p",null,[t("a",{href:"https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#parallel-synchronization-and-communication-instructions-cp-async-mbarrier-arrive",target:"_blank",rel:"noreferrer"},"For more information, see PTX ISA")],-1)),s(n,{type:"info",class:"source-link",text:"source"},{default:l(()=>e[83]||(e[83]=[t("a",{href:"https://github.com/EnzymeAD/Reactant.jl/blob/f3e0d0f12705c284c2cafd6c4acfc87b112d9751/src/mlir/Dialects/Nvvm.jl#L1073-L1083",target:"_blank",rel:"noreferrer"},"source",-1)])),_:1})]),t("details",I,[t("summary",null,[e[87]||(e[87]=t("a",{id:"Reactant.MLIR.Dialects.nvvm.cp_async_mbarrier_arrive_shared-Tuple{Reactant.MLIR.IR.Value}",href:"#Reactant.MLIR.Dialects.nvvm.cp_async_mbarrier_arrive_shared-Tuple{Reactant.MLIR.IR.Value}"},[t("span",{class:"jlbinding"},"Reactant.MLIR.Dialects.nvvm.cp_async_mbarrier_arrive_shared")],-1)),e[88]||(e[88]=a()),s(n,{type:"info",class:"jlObjectType jlMethod",text:"Method"})]),e[90]||(e[90]=t("p",null,[t("code",null,"cp_async_mbarrier_arrive_shared")],-1)),e[91]||(e[91]=t("p",null,[a("The "),t("code",null,"cp.async.mbarrier.arrive.shared"),a(" Op makes the mbarrier object track all prior cp.async operations initiated by the executing thread. The "),t("code",null,"addr"),a(" operand specifies the address of the mbarrier object in shared memory. The "),t("code",null,"noinc"),a(" attr impacts how the mbarrier's state is updated.")],-1)),e[92]||(e[92]=t("p",null,[t("a",{href:"https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#parallel-synchronization-and-communication-instructions-cp-async-mbarrier-arrive",target:"_blank",rel:"noreferrer"},"For more information, see PTX ISA")],-1)),s(n,{type:"info",class:"source-link",text:"source"},{default:l(()=>e[89]||(e[89]=[t("a",{href:"https://github.com/EnzymeAD/Reactant.jl/blob/f3e0d0f12705c284c2cafd6c4acfc87b112d9751/src/mlir/Dialects/Nvvm.jl#L1104-L1114",target:"_blank",rel:"noreferrer"},"source",-1)])),_:1})]),t("details",j,[t("summary",null,[e[93]||(e[93]=t("a",{id:"Reactant.MLIR.Dialects.nvvm.cvt_float_to_tf32-Tuple{Reactant.MLIR.IR.Value}",href:"#Reactant.MLIR.Dialects.nvvm.cvt_float_to_tf32-Tuple{Reactant.MLIR.IR.Value}"},[t("span",{class:"jlbinding"},"Reactant.MLIR.Dialects.nvvm.cvt_float_to_tf32")],-1)),e[94]||(e[94]=a()),s(n,{type:"info",class:"jlObjectType jlMethod",text:"Method"})]),e[96]||(e[96]=o("",3)),s(n,{type:"info",class:"source-link",text:"source"},{default:l(()=>e[95]||(e[95]=[t("a",{href:"https://github.com/EnzymeAD/Reactant.jl/blob/f3e0d0f12705c284c2cafd6c4acfc87b112d9751/src/mlir/Dialects/Nvvm.jl#L1183-L1193",target:"_blank",rel:"noreferrer"},"source",-1)])),_:1})]),t("details",D,[t("summary",null,[e[97]||(e[97]=t("a",{id:"Reactant.MLIR.Dialects.nvvm.elect_sync-Tuple{}",href:"#Reactant.MLIR.Dialects.nvvm.elect_sync-Tuple{}"},[t("span",{class:"jlbinding"},"Reactant.MLIR.Dialects.nvvm.elect_sync")],-1)),e[98]||(e[98]=a()),s(n,{type:"info",class:"jlObjectType jlMethod",text:"Method"})]),e[100]||(e[100]=o("",3)),s(n,{type:"info",class:"source-link",text:"source"},{default:l(()=>e[99]||(e[99]=[t("a",{href:"https://github.com/EnzymeAD/Reactant.jl/blob/f3e0d0f12705c284c2cafd6c4acfc87b112d9751/src/mlir/Dialects/Nvvm.jl#L1218-L1228",target:"_blank",rel:"noreferrer"},"source",-1)])),_:1})]),t("details",w,[t("summary",null,[e[101]||(e[101]=t("a",{id:"Reactant.MLIR.Dialects.nvvm.exit-Tuple{}",href:"#Reactant.MLIR.Dialects.nvvm.exit-Tuple{}"},[t("span",{class:"jlbinding"},"Reactant.MLIR.Dialects.nvvm.exit")],-1)),e[102]||(e[102]=a()),s(n,{type:"info",class:"jlObjectType jlMethod",text:"Method"})]),e[104]||(e[104]=t("p",null,[t("code",null,"exit")],-1)),e[105]||(e[105]=t("p",null,[a("Ends execution of a thread. "),t("a",{href:"https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#control-flow-instructions-exit",target:"_blank",rel:"noreferrer"},"For more information, see PTX ISA")],-1)),s(n,{type:"info",class:"source-link",text:"source"},{default:l(()=>e[103]||(e[103]=[t("a",{href:"https://github.com/EnzymeAD/Reactant.jl/blob/f3e0d0f12705c284c2cafd6c4acfc87b112d9751/src/mlir/Dialects/Nvvm.jl#L1856-L1861",target:"_blank",rel:"noreferrer"},"source",-1)])),_:1})]),t("details",A,[t("summary",null,[e[106]||(e[106]=t("a",{id:"Reactant.MLIR.Dialects.nvvm.fence_mbarrier_init-Tuple{}",href:"#Reactant.MLIR.Dialects.nvvm.fence_mbarrier_init-Tuple{}"},[t("span",{class:"jlbinding"},"Reactant.MLIR.Dialects.nvvm.fence_mbarrier_init")],-1)),e[107]||(e[107]=a()),s(n,{type:"info",class:"jlObjectType jlMethod",text:"Method"})]),e[109]||(e[109]=t("p",null,[t("code",null,"fence_mbarrier_init")],-1)),e[110]||(e[110]=t("p",null,"Fence operation that applies on the prior nvvm.mbarrier.init",-1)),e[111]||(e[111]=t("p",null,[t("a",{href:"https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#parallel-synchronization-and-communication-instructions-membar",target:"_blank",rel:"noreferrer"},"For more information, see PTX ISA")],-1)),s(n,{type:"info",class:"source-link",text:"source"},{default:l(()=>e[108]||(e[108]=[t("a",{href:"https://github.com/EnzymeAD/Reactant.jl/blob/f3e0d0f12705c284c2cafd6c4acfc87b112d9751/src/mlir/Dialects/Nvvm.jl#L1881-L1887",target:"_blank",rel:"noreferrer"},"source",-1)])),_:1})]),t("details",V,[t("summary",null,[e[112]||(e[112]=t("a",{id:"Reactant.MLIR.Dialects.nvvm.fence_proxy-Tuple{}",href:"#Reactant.MLIR.Dialects.nvvm.fence_proxy-Tuple{}"},[t("span",{class:"jlbinding"},"Reactant.MLIR.Dialects.nvvm.fence_proxy")],-1)),e[113]||(e[113]=a()),s(n,{type:"info",class:"jlObjectType jlMethod",text:"Method"})]),e[115]||(e[115]=t("p",null,[t("code",null,"fence_proxy")],-1)),e[116]||(e[116]=t("p",null,"Fence operation with proxy to establish an ordering between memory accesses that may happen through different proxies.",-1)),e[117]||(e[117]=t("p",null,[t("a",{href:"https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#parallel-synchronization-and-communication-instructions-membar",target:"_blank",rel:"noreferrer"},"For more information, see PTX ISA")],-1)),s(n,{type:"info",class:"source-link",text:"source"},{default:l(()=>e[114]||(e[114]=[t("a",{href:"https://github.com/EnzymeAD/Reactant.jl/blob/f3e0d0f12705c284c2cafd6c4acfc87b112d9751/src/mlir/Dialects/Nvvm.jl#L1946-L1953",target:"_blank",rel:"noreferrer"},"source",-1)])),_:1})]),t("details",S,[t("summary",null,[e[118]||(e[118]=t("a",{id:"Reactant.MLIR.Dialects.nvvm.fence_proxy_acquire-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}",href:"#Reactant.MLIR.Dialects.nvvm.fence_proxy_acquire-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}"},[t("span",{class:"jlbinding"},"Reactant.MLIR.Dialects.nvvm.fence_proxy_acquire")],-1)),e[119]||(e[119]=a()),s(n,{type:"info",class:"jlObjectType jlMethod",text:"Method"})]),e[121]||(e[121]=o("",4)),s(n,{type:"info",class:"source-link",text:"source"},{default:l(()=>e[120]||(e[120]=[t("a",{href:"https://github.com/EnzymeAD/Reactant.jl/blob/f3e0d0f12705c284c2cafd6c4acfc87b112d9751/src/mlir/Dialects/Nvvm.jl#L1907-L1922",target:"_blank",rel:"noreferrer"},"source",-1)])),_:1})]),t("details",H,[t("summary",null,[e[122]||(e[122]=t("a",{id:"Reactant.MLIR.Dialects.nvvm.fence_proxy_release-Tuple{}",href:"#Reactant.MLIR.Dialects.nvvm.fence_proxy_release-Tuple{}"},[t("span",{class:"jlbinding"},"Reactant.MLIR.Dialects.nvvm.fence_proxy_release")],-1)),e[123]||(e[123]=a()),s(n,{type:"info",class:"jlObjectType jlMethod",text:"Method"})]),e[125]||(e[125]=t("p",null,[t("code",null,"fence_proxy_release")],-1)),e[126]||(e[126]=t("p",null,[t("code",null,"fence.proxy.release"),a(" is a uni-directional fence used to establish ordering between a prior memory access performed via the generic proxy and a subsequent memory access performed via the tensormap proxy. "),t("code",null,"fence.proxy.release"),a(" operation can form a release sequence that synchronizes with an acquire sequence that contains the fence.proxy.acquire proxy fence operation")],-1)),e[127]||(e[127]=t("p",null,[t("a",{href:"https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#parallel-synchronization-and-communication-instructions-membar",target:"_blank",rel:"noreferrer"},"For more information, see PTX ISA")],-1)),s(n,{type:"info",class:"source-link",text:"source"},{default:l(()=>e[124]||(e[124]=[t("a",{href:"https://github.com/EnzymeAD/Reactant.jl/blob/f3e0d0f12705c284c2cafd6c4acfc87b112d9751/src/mlir/Dialects/Nvvm.jl#L1974-L1984",target:"_blank",rel:"noreferrer"},"source",-1)])),_:1})]),t("details",N,[t("summary",null,[e[128]||(e[128]=t("a",{id:"Reactant.MLIR.Dialects.nvvm.griddepcontrol_launch_dependents-Tuple{}",href:"#Reactant.MLIR.Dialects.nvvm.griddepcontrol_launch_dependents-Tuple{}"},[t("span",{class:"jlbinding"},"Reactant.MLIR.Dialects.nvvm.griddepcontrol_launch_dependents")],-1)),e[129]||(e[129]=a()),s(n,{type:"info",class:"jlObjectType jlMethod",text:"Method"})]),e[131]||(e[131]=t("p",null,[t("code",null,"griddepcontrol_launch_dependents")],-1)),e[132]||(e[132]=t("p",null,"Signals that specific dependents the runtime system designated to react to this instruction can be scheduled as soon as all other CTAs in the grid issue the same instruction or have completed.",-1)),e[133]||(e[133]=t("p",null,[t("a",{href:"https://docs.nvidia.com/cuda/parallel-thread-execution/#parallel-synchronization-and-communication-instructions-griddepcontrol",target:"_blank",rel:"noreferrer"},"For more information, see PTX ISA")],-1)),s(n,{type:"info",class:"source-link",text:"source"},{default:l(()=>e[130]||(e[130]=[t("a",{href:"https://github.com/EnzymeAD/Reactant.jl/blob/f3e0d0f12705c284c2cafd6c4acfc87b112d9751/src/mlir/Dialects/Nvvm.jl#L2126-L2135",target:"_blank",rel:"noreferrer"},"source",-1)])),_:1})]),t("details",C,[t("summary",null,[e[134]||(e[134]=t("a",{id:"Reactant.MLIR.Dialects.nvvm.griddepcontrol_wait-Tuple{}",href:"#Reactant.MLIR.Dialects.nvvm.griddepcontrol_wait-Tuple{}"},[t("span",{class:"jlbinding"},"Reactant.MLIR.Dialects.nvvm.griddepcontrol_wait")],-1)),e[135]||(e[135]=a()),s(n,{type:"info",class:"jlObjectType jlMethod",text:"Method"})]),e[137]||(e[137]=t("p",null,[t("code",null,"griddepcontrol_wait")],-1)),e[138]||(e[138]=t("p",null,"Causes the executing thread to wait until all prerequisite grids in flight have completed and all the memory operations from the prerequisite grids are performed and made visible to the current grid.",-1)),e[139]||(e[139]=t("p",null,[t("a",{href:"https://docs.nvidia.com/cuda/parallel-thread-execution/#parallel-synchronization-and-communication-instructions-griddepcontrol",target:"_blank",rel:"noreferrer"},"For more information, see PTX ISA")],-1)),s(n,{type:"info",class:"source-link",text:"source"},{default:l(()=>e[136]||(e[136]=[t("a",{href:"https://github.com/EnzymeAD/Reactant.jl/blob/f3e0d0f12705c284c2cafd6c4acfc87b112d9751/src/mlir/Dialects/Nvvm.jl#L2155-L2164",target:"_blank",rel:"noreferrer"},"source",-1)])),_:1})]),t("details",P,[t("summary",null,[e[140]||(e[140]=t("a",{id:"Reactant.MLIR.Dialects.nvvm.match_sync-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}",href:"#Reactant.MLIR.Dialects.nvvm.match_sync-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}"},[t("span",{class:"jlbinding"},"Reactant.MLIR.Dialects.nvvm.match_sync")],-1)),e[141]||(e[141]=a()),s(n,{type:"info",class:"jlObjectType jlMethod",text:"Method"})]),e[143]||(e[143]=o("",8)),s(n,{type:"info",class:"source-link",text:"source"},{default:l(()=>e[142]||(e[142]=[t("a",{href:"https://github.com/EnzymeAD/Reactant.jl/blob/f3e0d0f12705c284c2cafd6c4acfc87b112d9751/src/mlir/Dialects/Nvvm.jl#L2633-L2649",target:"_blank",rel:"noreferrer"},"source",-1)])),_:1})]),t("details",F,[t("summary",null,[e[144]||(e[144]=t("a",{id:"Reactant.MLIR.Dialects.nvvm.mma_sync-Tuple{Vector{Reactant.MLIR.IR.Value}, Vector{Reactant.MLIR.IR.Value}, Vector{Reactant.MLIR.IR.Value}}",href:"#Reactant.MLIR.Dialects.nvvm.mma_sync-Tuple{Vector{Reactant.MLIR.IR.Value}, Vector{Reactant.MLIR.IR.Value}, Vector{Reactant.MLIR.IR.Value}}"},[t("span",{class:"jlbinding"},"Reactant.MLIR.Dialects.nvvm.mma_sync")],-1)),e[145]||(e[145]=a()),s(n,{type:"info",class:"jlObjectType jlMethod",text:"Method"})]),e[147]||(e[147]=o("",11)),s(n,{type:"info",class:"source-link",text:"source"},{default:l(()=>e[146]||(e[146]=[t("a",{href:"https://github.com/EnzymeAD/Reactant.jl/blob/f3e0d0f12705c284c2cafd6c4acfc87b112d9751/src/mlir/Dialects/Nvvm.jl#L2669-L2736",target:"_blank",rel:"noreferrer"},"source",-1)])),_:1})]),t("details",E,[t("summary",null,[e[148]||(e[148]=t("a",{id:"Reactant.MLIR.Dialects.nvvm.redux_sync-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}",href:"#Reactant.MLIR.Dialects.nvvm.redux_sync-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}"},[t("span",{class:"jlbinding"},"Reactant.MLIR.Dialects.nvvm.redux_sync")],-1)),e[149]||(e[149]=a()),s(n,{type:"info",class:"jlObjectType jlMethod",text:"Method"})]),e[151]||(e[151]=o("",4)),s(n,{type:"info",class:"source-link",text:"source"},{default:l(()=>e[150]||(e[150]=[t("a",{href:"https://github.com/EnzymeAD/Reactant.jl/blob/f3e0d0f12705c284c2cafd6c4acfc87b112d9751/src/mlir/Dialects/Nvvm.jl#L2825-L2838",target:"_blank",rel:"noreferrer"},"source",-1)])),_:1})]),t("details",O,[t("summary",null,[e[152]||(e[152]=t("a",{id:"Reactant.MLIR.Dialects.nvvm.shfl_sync-NTuple{4, Reactant.MLIR.IR.Value}",href:"#Reactant.MLIR.Dialects.nvvm.shfl_sync-NTuple{4, Reactant.MLIR.IR.Value}"},[t("span",{class:"jlbinding"},"Reactant.MLIR.Dialects.nvvm.shfl_sync")],-1)),e[153]||(e[153]=a()),s(n,{type:"info",class:"jlObjectType jlMethod",text:"Method"})]),e[155]||(e[155]=o("",3)),s(n,{type:"info",class:"source-link",text:"source"},{default:l(()=>e[154]||(e[154]=[t("a",{href:"https://github.com/EnzymeAD/Reactant.jl/blob/f3e0d0f12705c284c2cafd6c4acfc87b112d9751/src/mlir/Dialects/Nvvm.jl#L2889-L2902",target:"_blank",rel:"noreferrer"},"source",-1)])),_:1})]),t("details",z,[t("summary",null,[e[156]||(e[156]=t("a",{id:"Reactant.MLIR.Dialects.nvvm.stmatrix-Tuple{Reactant.MLIR.IR.Value, Vector{Reactant.MLIR.IR.Value}}",href:"#Reactant.MLIR.Dialects.nvvm.stmatrix-Tuple{Reactant.MLIR.IR.Value, Vector{Reactant.MLIR.IR.Value}}"},[t("span",{class:"jlbinding"},"Reactant.MLIR.Dialects.nvvm.stmatrix")],-1)),e[157]||(e[157]=a()),s(n,{type:"info",class:"jlObjectType jlMethod",text:"Method"})]),e[159]||(e[159]=t("p",null,[t("code",null,"stmatrix")],-1)),e[160]||(e[160]=t("p",null,"Collectively store one or more matrices across all threads in a warp to the location indicated by the address operand ptr in shared memory.",-1)),e[161]||(e[161]=t("p",null,[t("a",{href:"https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#warp-level-matrix-store-instruction-stmatrix",target:"_blank",rel:"noreferrer"},"For more information, see PTX ISA")],-1)),s(n,{type:"info",class:"source-link",text:"source"},{default:l(()=>e[158]||(e[158]=[t("a",{href:"https://github.com/EnzymeAD/Reactant.jl/blob/f3e0d0f12705c284c2cafd6c4acfc87b112d9751/src/mlir/Dialects/Nvvm.jl#L2975-L2982",target:"_blank",rel:"noreferrer"},"source",-1)])),_:1})]),t("details",Z,[t("summary",null,[e[162]||(e[162]=t("a",{id:"Reactant.MLIR.Dialects.nvvm.tcgen05_alloc-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}",href:"#Reactant.MLIR.Dialects.nvvm.tcgen05_alloc-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}"},[t("span",{class:"jlbinding"},"Reactant.MLIR.Dialects.nvvm.tcgen05_alloc")],-1)),e[163]||(e[163]=a()),s(n,{type:"info",class:"jlObjectType jlMethod",text:"Method"})]),e[165]||(e[165]=t("p",null,[t("code",null,"tcgen05_alloc")],-1)),e[166]||(e[166]=t("p",null,[a("The "),t("code",null,"tcgen05.alloc"),a(" Op allocates tensor core memory for the amount specified by "),t("code",null,"nCols"),a(" and writes the destination address to the "),t("code",null,"addr"),a(" argument. The "),t("code",null,"nCols"),a(" operand specifies the number of columns to be allocated and it must be a power-of-two. "),t("a",{href:"https://docs.nvidia.com/cuda/parallel-thread-execution/#tcgen05-memory-alloc-manage-instructions",target:"_blank",rel:"noreferrer"},"For more information, see PTX ISA")],-1)),s(n,{type:"info",class:"source-link",text:"source"},{default:l(()=>e[164]||(e[164]=[t("a",{href:"https://github.com/EnzymeAD/Reactant.jl/blob/f3e0d0f12705c284c2cafd6c4acfc87b112d9751/src/mlir/Dialects/Nvvm.jl#L3021-L3029",target:"_blank",rel:"noreferrer"},"source",-1)])),_:1})]),t("details",X,[t("summary",null,[e[167]||(e[167]=t("a",{id:"Reactant.MLIR.Dialects.nvvm.tcgen05_commit",href:"#Reactant.MLIR.Dialects.nvvm.tcgen05_commit"},[t("span",{class:"jlbinding"},"Reactant.MLIR.Dialects.nvvm.tcgen05_commit")],-1)),e[168]||(e[168]=a()),s(n,{type:"info",class:"jlObjectType jlFunction",text:"Function"})]),e[170]||(e[170]=o("",2)),s(n,{type:"info",class:"source-link",text:"source"},{default:l(()=>e[169]||(e[169]=[t("a",{href:"https://github.com/EnzymeAD/Reactant.jl/blob/f3e0d0f12705c284c2cafd6c4acfc87b112d9751/src/mlir/Dialects/Nvvm.jl#L3050-L3062",target:"_blank",rel:"noreferrer"},"source",-1)])),_:1})]),t("details",q,[t("summary",null,[e[171]||(e[171]=t("a",{id:"Reactant.MLIR.Dialects.nvvm.tcgen05_cp-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}",href:"#Reactant.MLIR.Dialects.nvvm.tcgen05_cp-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}"},[t("span",{class:"jlbinding"},"Reactant.MLIR.Dialects.nvvm.tcgen05_cp")],-1)),e[172]||(e[172]=a()),s(n,{type:"info",class:"jlObjectType jlMethod",text:"Method"})]),e[174]||(e[174]=o("",5)),s(n,{type:"info",class:"source-link",text:"source"},{default:l(()=>e[173]||(e[173]=[t("a",{href:"https://github.com/EnzymeAD/Reactant.jl/blob/f3e0d0f12705c284c2cafd6c4acfc87b112d9751/src/mlir/Dialects/Nvvm.jl#L3089-L3108",target:"_blank",rel:"noreferrer"},"source",-1)])),_:1})]),t("details",B,[t("summary",null,[e[175]||(e[175]=t("a",{id:"Reactant.MLIR.Dialects.nvvm.tcgen05_dealloc-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}",href:"#Reactant.MLIR.Dialects.nvvm.tcgen05_dealloc-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}"},[t("span",{class:"jlbinding"},"Reactant.MLIR.Dialects.nvvm.tcgen05_dealloc")],-1)),e[176]||(e[176]=a()),s(n,{type:"info",class:"jlObjectType jlMethod",text:"Method"})]),e[178]||(e[178]=t("p",null,[t("code",null,"tcgen05_dealloc")],-1)),e[179]||(e[179]=t("p",null,[a("The "),t("code",null,"tcgen05.dealloc"),a(" Op de-allocates the tensor core memory specified by "),t("code",null,"tmemAddr"),a(", which must be from a previous tensor memory allocation. The "),t("code",null,"nCols"),a(" operand specifies the number of columns to be de-allocated, and it must be a power-of-two. "),t("a",{href:"https://docs.nvidia.com/cuda/parallel-thread-execution/#tcgen05-memory-alloc-manage-instructions",target:"_blank",rel:"noreferrer"},"For more information, see PTX ISA")],-1)),s(n,{type:"info",class:"source-link",text:"source"},{default:l(()=>e[177]||(e[177]=[t("a",{href:"https://github.com/EnzymeAD/Reactant.jl/blob/f3e0d0f12705c284c2cafd6c4acfc87b112d9751/src/mlir/Dialects/Nvvm.jl#L3139-L3147",target:"_blank",rel:"noreferrer"},"source",-1)])),_:1})]),t("details",$,[t("summary",null,[e[180]||(e[180]=t("a",{id:"Reactant.MLIR.Dialects.nvvm.tcgen05_fence-Tuple{}",href:"#Reactant.MLIR.Dialects.nvvm.tcgen05_fence-Tuple{}"},[t("span",{class:"jlbinding"},"Reactant.MLIR.Dialects.nvvm.tcgen05_fence")],-1)),e[181]||(e[181]=a()),s(n,{type:"info",class:"jlObjectType jlMethod",text:"Method"})]),e[183]||(e[183]=t("p",null,[t("code",null,"tcgen05_fence")],-1)),e[184]||(e[184]=t("p",null,[a("The "),t("code",null,"tcgen05.fence<before>"),a(" orders all prior async tcgen05 operations with respect to the subsequent tcgen05 and execution ordering operations. The "),t("code",null,"tcgen05.fence<after>"),a(" orders all subsequent async tcgen05 operations with respect to the prior tcgen05 and execution ordering operations.")],-1)),e[185]||(e[185]=t("p",null,[t("a",{href:"https://docs.nvidia.com/cuda/parallel-thread-execution/#tensorcore-5th-generation-instructions-tcgen05-fence",target:"_blank",rel:"noreferrer"},"For more information, see PTX ISA")],-1)),s(n,{type:"info",class:"source-link",text:"source"},{default:l(()=>e[182]||(e[182]=[t("a",{href:"https://github.com/EnzymeAD/Reactant.jl/blob/f3e0d0f12705c284c2cafd6c4acfc87b112d9751/src/mlir/Dialects/Nvvm.jl#L3168-L3177",target:"_blank",rel:"noreferrer"},"source",-1)])),_:1})]),t("details",W,[t("summary",null,[e[186]||(e[186]=t("a",{id:"Reactant.MLIR.Dialects.nvvm.tcgen05_ld",href:"#Reactant.MLIR.Dialects.nvvm.tcgen05_ld"},[t("span",{class:"jlbinding"},"Reactant.MLIR.Dialects.nvvm.tcgen05_ld")],-1)),e[187]||(e[187]=a()),s(n,{type:"info",class:"jlObjectType jlFunction",text:"Function"})]),e[189]||(e[189]=o("",9)),s(n,{type:"info",class:"source-link",text:"source"},{default:l(()=>e[188]||(e[188]=[t("a",{href:"https://github.com/EnzymeAD/Reactant.jl/blob/f3e0d0f12705c284c2cafd6c4acfc87b112d9751/src/mlir/Dialects/Nvvm.jl#L3197-L3242",target:"_blank",rel:"noreferrer"},"source",-1)])),_:1})]),t("details",G,[t("summary",null,[e[190]||(e[190]=t("a",{id:"Reactant.MLIR.Dialects.nvvm.tcgen05_relinquish_alloc_permit-Tuple{}",href:"#Reactant.MLIR.Dialects.nvvm.tcgen05_relinquish_alloc_permit-Tuple{}"},[t("span",{class:"jlbinding"},"Reactant.MLIR.Dialects.nvvm.tcgen05_relinquish_alloc_permit")],-1)),e[191]||(e[191]=a()),s(n,{type:"info",class:"jlObjectType jlMethod",text:"Method"})]),e[193]||(e[193]=t("p",null,[t("code",null,"tcgen05_relinquish_alloc_permit")],-1)),e[194]||(e[194]=t("p",null,[a("The "),t("code",null,"tcgen05.relinquish_alloc_permit"),a(" Op specifies that the CTA of the executing thread is relinquishing the right to allocate Tensor Memory. So, it is illegal for a CTA to perform "),t("code",null,"tcgen05.alloc"),a(" after any of its constituent threads execute "),t("code",null,"tcgen05.relinquish_alloc_permit"),a(". "),t("a",{href:"https://docs.nvidia.com/cuda/parallel-thread-execution/#tcgen05-memory-alloc-manage-instructions",target:"_blank",rel:"noreferrer"},"For more information, see PTX ISA")],-1)),s(n,{type:"info",class:"source-link",text:"source"},{default:l(()=>e[192]||(e[192]=[t("a",{href:"https://github.com/EnzymeAD/Reactant.jl/blob/f3e0d0f12705c284c2cafd6c4acfc87b112d9751/src/mlir/Dialects/Nvvm.jl#L3271-L3279",target:"_blank",rel:"noreferrer"},"source",-1)])),_:1})]),t("details",J,[t("summary",null,[e[195]||(e[195]=t("a",{id:"Reactant.MLIR.Dialects.nvvm.tcgen05_shift-Tuple{Reactant.MLIR.IR.Value}",href:"#Reactant.MLIR.Dialects.nvvm.tcgen05_shift-Tuple{Reactant.MLIR.IR.Value}"},[t("span",{class:"jlbinding"},"Reactant.MLIR.Dialects.nvvm.tcgen05_shift")],-1)),e[196]||(e[196]=a()),s(n,{type:"info",class:"jlObjectType jlMethod",text:"Method"})]),e[198]||(e[198]=t("p",null,[t("code",null,"tcgen05_shift")],-1)),e[199]||(e[199]=t("p",null,[a("The "),t("code",null,"tcgen05.shift"),a(" is an asynchronous instruction which initiates the shifting of 32-byte elements downwards across all the rows, except the last, by one row. The operand "),t("code",null,"taddr"),a(" specifies the base address of the matrix in Tensor Memory whose rows must be down shifted.")],-1)),e[200]||(e[200]=t("p",null,[t("a",{href:"https://docs.nvidia.com/cuda/parallel-thread-execution/#tcgen05-instructions-tcgen05-shift",target:"_blank",rel:"noreferrer"},"For more information, see PTX ISA")],-1)),s(n,{type:"info",class:"source-link",text:"source"},{default:l(()=>e[197]||(e[197]=[t("a",{href:"https://github.com/EnzymeAD/Reactant.jl/blob/f3e0d0f12705c284c2cafd6c4acfc87b112d9751/src/mlir/Dialects/Nvvm.jl#L3300-L3309",target:"_blank",rel:"noreferrer"},"source",-1)])),_:1})]),t("details",K,[t("summary",null,[e[201]||(e[201]=t("a",{id:"Reactant.MLIR.Dialects.nvvm.tcgen05_st",href:"#Reactant.MLIR.Dialects.nvvm.tcgen05_st"},[t("span",{class:"jlbinding"},"Reactant.MLIR.Dialects.nvvm.tcgen05_st")],-1)),e[202]||(e[202]=a()),s(n,{type:"info",class:"jlObjectType jlFunction",text:"Function"})]),e[204]||(e[204]=o("",9)),s(n,{type:"info",class:"source-link",text:"source"},{default:l(()=>e[203]||(e[203]=[t("a",{href:"https://github.com/EnzymeAD/Reactant.jl/blob/f3e0d0f12705c284c2cafd6c4acfc87b112d9751/src/mlir/Dialects/Nvvm.jl#L3330-L3374",target:"_blank",rel:"noreferrer"},"source",-1)])),_:1})]),t("details",U,[t("summary",null,[e[205]||(e[205]=t("a",{id:"Reactant.MLIR.Dialects.nvvm.tcgen05_wait-Tuple{}",href:"#Reactant.MLIR.Dialects.nvvm.tcgen05_wait-Tuple{}"},[t("span",{class:"jlbinding"},"Reactant.MLIR.Dialects.nvvm.tcgen05_wait")],-1)),e[206]||(e[206]=a()),s(n,{type:"info",class:"jlObjectType jlMethod",text:"Method"})]),e[208]||(e[208]=t("p",null,[t("code",null,"tcgen05_wait")],-1)),e[209]||(e[209]=t("p",null,[a("The "),t("code",null,"tcgen05.wait<load>"),a(" causes the executing thread to block until all prior "),t("code",null,"tcgen05.ld"),a(" operations issued by the executing thread have completed. Similarly, the "),t("code",null,"tcgen05.wait<store>"),a(" causes the executing thread to block until all prior "),t("code",null,"tcgen05.st"),a(" operations issued by the executing thread have completed. "),t("a",{href:"https://docs.nvidia.com/cuda/parallel-thread-execution/#tcgen05-instructions-tcgen05-wait",target:"_blank",rel:"noreferrer"},"For more information, see PTX ISA")],-1)),s(n,{type:"info",class:"source-link",text:"source"},{default:l(()=>e[207]||(e[207]=[t("a",{href:"https://github.com/EnzymeAD/Reactant.jl/blob/f3e0d0f12705c284c2cafd6c4acfc87b112d9751/src/mlir/Dialects/Nvvm.jl#L3403-L3412",target:"_blank",rel:"noreferrer"},"source",-1)])),_:1})]),t("details",Y,[t("summary",null,[e[210]||(e[210]=t("a",{id:"Reactant.MLIR.Dialects.nvvm.wgmma_commit_group_sync_aligned-Tuple{}",href:"#Reactant.MLIR.Dialects.nvvm.wgmma_commit_group_sync_aligned-Tuple{}"},[t("span",{class:"jlbinding"},"Reactant.MLIR.Dialects.nvvm.wgmma_commit_group_sync_aligned")],-1)),e[211]||(e[211]=a()),s(n,{type:"info",class:"jlObjectType jlMethod",text:"Method"})]),e[213]||(e[213]=t("p",null,[t("code",null,"wgmma_commit_group_sync_aligned")],-1)),e[214]||(e[214]=t("p",null,"Commits all prior uncommitted warpgroup level matrix multiplication operations.",-1)),e[215]||(e[215]=t("p",null,[t("a",{href:"https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#asynchronous-warpgroup-level-matrix-instructions-wgmma-commit-group",target:"_blank",rel:"noreferrer"},"For more information, see PTX ISA")],-1)),s(n,{type:"info",class:"source-link",text:"source"},{default:l(()=>e[212]||(e[212]=[t("a",{href:"https://github.com/EnzymeAD/Reactant.jl/blob/f3e0d0f12705c284c2cafd6c4acfc87b112d9751/src/mlir/Dialects/Nvvm.jl#L3708-L3714",target:"_blank",rel:"noreferrer"},"source",-1)])),_:1})]),t("details",ee,[t("summary",null,[e[216]||(e[216]=t("a",{id:"Reactant.MLIR.Dialects.nvvm.wgmma_fence_aligned-Tuple{}",href:"#Reactant.MLIR.Dialects.nvvm.wgmma_fence_aligned-Tuple{}"},[t("span",{class:"jlbinding"},"Reactant.MLIR.Dialects.nvvm.wgmma_fence_aligned")],-1)),e[217]||(e[217]=a()),s(n,{type:"info",class:"jlObjectType jlMethod",text:"Method"})]),e[219]||(e[219]=t("p",null,[t("code",null,"wgmma_fence_aligned")],-1)),e[220]||(e[220]=t("p",null,"Enforce an ordering of register accesses between warpgroup level matrix multiplication and other operations.",-1)),e[221]||(e[221]=t("p",null,[t("a",{href:"https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#asynchronous-warpgroup-level-matrix-instructions-wgmma-fence",target:"_blank",rel:"noreferrer"},"For more information, see PTX ISA")],-1)),s(n,{type:"info",class:"source-link",text:"source"},{default:l(()=>e[218]||(e[218]=[t("a",{href:"https://github.com/EnzymeAD/Reactant.jl/blob/f3e0d0f12705c284c2cafd6c4acfc87b112d9751/src/mlir/Dialects/Nvvm.jl#L3681-L3688",target:"_blank",rel:"noreferrer"},"source",-1)])),_:1})]),t("details",te,[t("summary",null,[e[222]||(e[222]=t("a",{id:"Reactant.MLIR.Dialects.nvvm.wgmma_mma_async-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}",href:"#Reactant.MLIR.Dialects.nvvm.wgmma_mma_async-Tuple{Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value, Reactant.MLIR.IR.Value}"},[t("span",{class:"jlbinding"},"Reactant.MLIR.Dialects.nvvm.wgmma_mma_async")],-1)),e[223]||(e[223]=a()),s(n,{type:"info",class:"jlObjectType jlMethod",text:"Method"})]),e[225]||(e[225]=o("",5)),s(n,{type:"info",class:"source-link",text:"source"},{default:l(()=>e[224]||(e[224]=[t("a",{href:"https://github.com/EnzymeAD/Reactant.jl/blob/f3e0d0f12705c284c2cafd6c4acfc87b112d9751/src/mlir/Dialects/Nvvm.jl#L3734-L3792",target:"_blank",rel:"noreferrer"},"source",-1)])),_:1})]),t("details",ae,[t("summary",null,[e[226]||(e[226]=t("a",{id:"Reactant.MLIR.Dialects.nvvm.wgmma_wait_group_sync_aligned-Tuple{}",href:"#Reactant.MLIR.Dialects.nvvm.wgmma_wait_group_sync_aligned-Tuple{}"},[t("span",{class:"jlbinding"},"Reactant.MLIR.Dialects.nvvm.wgmma_wait_group_sync_aligned")],-1)),e[227]||(e[227]=a()),s(n,{type:"info",class:"jlObjectType jlMethod",text:"Method"})]),e[229]||(e[229]=t("p",null,[t("code",null,"wgmma_wait_group_sync_aligned")],-1)),e[230]||(e[230]=t("p",null,"Signal the completion of a preceding warpgroup operation.",-1)),e[231]||(e[231]=t("p",null,[t("a",{href:"https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#asynchronous-warpgroup-level-matrix-instructions-wgmma-wait-group",target:"_blank",rel:"noreferrer"},"For more information, see PTX ISA")],-1)),s(n,{type:"info",class:"source-link",text:"source"},{default:l(()=>e[228]||(e[228]=[t("a",{href:"https://github.com/EnzymeAD/Reactant.jl/blob/f3e0d0f12705c284c2cafd6c4acfc87b112d9751/src/mlir/Dialects/Nvvm.jl#L3839-L3845",target:"_blank",rel:"noreferrer"},"source",-1)])),_:1})])])}const pe=c(p,[["render",ne]]);export{de as __pageData,pe as default};
